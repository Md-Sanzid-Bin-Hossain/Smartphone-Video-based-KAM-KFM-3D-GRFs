{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Md-Sanzid-Bin-Hossain/Smartphone-Video-based-KAM-KFM-3D-GRFs/blob/main/SOTA_Smartphone_based_KAM_KFM_3D_GRFs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H__KTa0RNQDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f8924c-499c-4784-d8df-f7773426b855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy\n",
        "import statistics\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statistics import stdev\n",
        "import math\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from scipy.signal import butter,filtfilt\n",
        "import sys\n",
        "import numpy as np # linear algebra\n",
        "from scipy.stats import randint\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
        "import seaborn as sns # used for plot interactive graph.\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from tsf.model import TransformerForecaster\n",
        "\n",
        "\n",
        "# from tensorflow.keras.utils import np_utils\n",
        "import itertools\n",
        "###  Library for attention layers\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "#from tqdm import tqdm # Processing time measurement\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import statistics\n",
        "import gc\n",
        "import torch.nn.init as init\n",
        "\n",
        "############################################################################################################################################################################\n",
        "############################################################################################################################################################################\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.utils.weight_norm as weight_norm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrXnoV0Js5CO"
      },
      "source": [
        "# File path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mq0s3oBqlJ5"
      },
      "source": [
        "# Data loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_vel_acc(V):\n",
        "\n",
        "  velocity_all = []\n",
        "  acceleration_all = []\n",
        "\n",
        "  for i in range(44):\n",
        "      velocity, acceleration = calculate_velocity_acceleration(V[:,i])\n",
        "\n",
        "      velocity_all.append(velocity)\n",
        "      acceleration_all.append(acceleration)\n",
        "\n",
        "  return np.transpose(velocity_all), np.transpose(acceleration_all)"
      ],
      "metadata": {
        "id": "mPsuuqPdbpi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_velocity_acceleration(position_data):\n",
        "    n = len(position_data)\n",
        "\n",
        "    # Calculate velocity\n",
        "    velocity = []\n",
        "    for i in range(n):\n",
        "        if i == 0:\n",
        "            vel = 0.0  # Set initial velocity as 0\n",
        "        else:\n",
        "            displacement = position_data[i] - position_data[i-1]\n",
        "            time_interval = 0.01  # Assuming time intervals are uniform (e.g., 1 second)\n",
        "            vel = displacement / time_interval\n",
        "        velocity.append(vel)\n",
        "\n",
        "    # Calculate acceleration\n",
        "    acceleration = []\n",
        "    for i in range(n):\n",
        "        if i ==0:\n",
        "            accel = 0.0  # Set acceleration as 0 for the first and last points\n",
        "        else:\n",
        "            velocity_change = velocity[i] - velocity[i-1]\n",
        "            accel = velocity_change / time_interval\n",
        "        acceleration.append(accel)\n",
        "\n",
        "    return np.array(velocity), np.array(acceleration)"
      ],
      "metadata": {
        "id": "AUDuqhYA44ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP90JbQoR23t"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    with h5py.File('/content/drive/My Drive/public dataset/all_17_subjects.h5', 'r') as hf:\n",
        "        data_all_sub = {subject: subject_data[:] for subject, subject_data in hf.items()}\n",
        "        data_fields = json.loads(hf.attrs['columns'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1Rygjvcmq90"
      },
      "outputs": [],
      "source": [
        "def data_extraction(A):\n",
        "  for k in range(len(A)):\n",
        "    zero_index_1=np.all(A[k:k+1,:,:] == 0, axis=0)\n",
        "    zero_index = np.multiply(zero_index_1, 1)\n",
        "    zero_index=np.array(zero_index)\n",
        "\n",
        "    for i in range(len(zero_index)):\n",
        "      if (sum(zero_index[i])==256):\n",
        "        index=i\n",
        "        break;\n",
        "\n",
        "    # print(index)\n",
        "### Taking only the stance phase of the gait\n",
        "###################################################################################################################################################\n",
        "    B=A[k:k+1,0:index,:]  ### Taking only the stance phase of the gait\n",
        "    C_1=B.reshape((B.shape[0]*B.shape[1],B.shape[2]))\n",
        "    if (k==0):\n",
        "      C=C_1\n",
        "    else:\n",
        "      C=np.append(C,C_1,axis=0)\n",
        "\n",
        "  index_24 = data_fields.index('body weight')\n",
        "  index_25 = data_fields.index('body height')\n",
        "\n",
        "  BW=(C[0:1, index_24]*9.8)\n",
        "  BWH=(C[0:1, index_24]*9.8)*C[:, index_25]\n",
        "\n",
        "  V=C[:,110:154]\n",
        "  V=V.reshape(V.shape[0],11,4)\n",
        "\n",
        "  V=(V-V[:,2:3,:])\n",
        "\n",
        "  V=V.reshape(-1,44)\n",
        "\n",
        "  velocity_all, acceleration_all = extract_vel_acc(V)\n",
        "\n",
        "  V=V/C[0:1, index_25]\n",
        "\n",
        "\n",
        "      ### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "    ### 0:48- IMU, 48:92-2D body coordinate, 92:136 -2D velocity, 136:180 -2D acceleration, 180:185-- Target\n",
        "\n",
        "  D=np.hstack((C[:,71:77],C[:,58:64],C[:,19:25],C[:,32:38],C[:,45:51],C[:,6:12],C[:,84:90],C[:,97:103],V,velocity_all, acceleration_all, C[:,3:5],-C[:, 154:155]/BW,\n",
        "              -C[:, 156:157]/BW,-C[:, 155:156]/BW))\n",
        "\n",
        "\n",
        "\n",
        "  return D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_subject_01 = data_all_sub['subject_01']\n",
        "subject_1=data_extraction(data_subject_01)\n",
        "\n",
        "print(subject_1.shape)"
      ],
      "metadata": {
        "id": "xoVth3PxeCEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5331c312-93b7-4452-fa55-f290c8480373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(84490, 185)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwo6ALnFONNS"
      },
      "outputs": [],
      "source": [
        "data_subject_01 = data_all_sub['subject_01']\n",
        "data_subject_02 = data_all_sub['subject_02']\n",
        "data_subject_03 = data_all_sub['subject_03']\n",
        "data_subject_04 = data_all_sub['subject_04']\n",
        "data_subject_05 = data_all_sub['subject_05']\n",
        "data_subject_06 = data_all_sub['subject_06']\n",
        "data_subject_07 = data_all_sub['subject_07']\n",
        "data_subject_08 = data_all_sub['subject_08']\n",
        "data_subject_09 = data_all_sub['subject_09']\n",
        "data_subject_10 = data_all_sub['subject_10']\n",
        "data_subject_11 = data_all_sub['subject_11']\n",
        "data_subject_12 = data_all_sub['subject_12']\n",
        "data_subject_13 = data_all_sub['subject_13']\n",
        "data_subject_14 = data_all_sub['subject_14']\n",
        "data_subject_15 = data_all_sub['subject_15']\n",
        "data_subject_16 = data_all_sub['subject_16']\n",
        "data_subject_17 = data_all_sub['subject_17']\n",
        "\n",
        "\n",
        "subject_1=data_extraction(data_subject_01)\n",
        "subject_2=data_extraction(data_subject_02)\n",
        "subject_3=data_extraction(data_subject_03)\n",
        "subject_4=data_extraction(data_subject_04)\n",
        "subject_5=data_extraction(data_subject_05)\n",
        "subject_6=data_extraction(data_subject_06)\n",
        "subject_7=data_extraction(data_subject_07)\n",
        "subject_8=data_extraction(data_subject_08)\n",
        "subject_9=data_extraction(data_subject_09)\n",
        "subject_10=data_extraction(data_subject_10)\n",
        "subject_11=data_extraction(data_subject_11)\n",
        "subject_12=data_extraction(data_subject_12)\n",
        "subject_13=data_extraction(data_subject_13)\n",
        "subject_14=data_extraction(data_subject_14)\n",
        "subject_15=data_extraction(data_subject_15)\n",
        "subject_16=data_extraction(data_subject_16)\n",
        "subject_17=data_extraction(data_subject_17)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
        "\n",
        "adjacency_matrix=torch.from_numpy(adjacency_matrix.astype(np.float32))\n",
        "\n",
        "\n",
        "def graph_based_augmentation(joints, adjacency_matrix, max_rotation, max_translation):\n",
        "    num_joints = joints.shape[0]\n",
        "\n",
        "    # Apply random rotations\n",
        "    theta = torch.randn(num_joints, 1) * (max_rotation * np.pi / 180)  # Convert to radians\n",
        "    cos_theta = torch.cos(theta)\n",
        "    sin_theta = torch.sin(theta)\n",
        "\n",
        "    rotated_joints = torch.zeros_like(joints)\n",
        "    for i in range(num_joints):\n",
        "        neighbors = torch.nonzero(adjacency_matrix[i]).squeeze(1)\n",
        "        rotated_joints[i] = cos_theta[i] * joints[i] + torch.sum(sin_theta[i] * joints[neighbors], dim=0)\n",
        "\n",
        "    # Apply random translations\n",
        "    translation = torch.randn(2) * max_translation\n",
        "\n",
        "    augmented_joints = rotated_joints + translation\n",
        "\n",
        "    return augmented_joints\n",
        "\n",
        "\n",
        "def augmentation_all(V):\n",
        "\n",
        "    joints=V\n",
        "    augmented_joints_all=[]\n",
        "\n",
        "    for i in range(len(joints)):\n",
        "\n",
        "      joint_1=joints[i,:,0:2].squeeze(0)\n",
        "      augmented_joints_1 = graph_based_augmentation(joint_1, adjacency_matrix, max_rotation=2.0, max_translation=1.0)\n",
        "\n",
        "      joint_2=joints[i,:,2:4].squeeze(0)\n",
        "      augmented_joints_2 = graph_based_augmentation(joint_2, adjacency_matrix, max_rotation=2.0, max_translation=1.0)\n",
        "\n",
        "      augmented_joints_1=augmented_joints_1.unsqueeze(0)\n",
        "      augmented_joints_2=augmented_joints_2.unsqueeze(0)\n",
        "\n",
        "      augmented_joints=torch.cat((augmented_joints_1,augmented_joints_2),dim=-1)\n",
        "      augmented_joints_all.append(augmented_joints)\n",
        "\n",
        "    augmented_joints_all = torch.stack(augmented_joints_all, dim=0)\n",
        "    augmented_joints_all=augmented_joints_all.unsqueeze(1)\n",
        "\n",
        "    return augmented_joints_all\n",
        "\n"
      ],
      "metadata": {
        "id": "AxiJ4dX0cvzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_extraction_aug(A):\n",
        "  for k in range(len(A)):\n",
        "    zero_index_1=np.all(A[k:k+1,:,:] == 0, axis=0)\n",
        "    zero_index = np.multiply(zero_index_1, 1)\n",
        "    zero_index=np.array(zero_index)\n",
        "\n",
        "    for i in range(len(zero_index)):\n",
        "      if (sum(zero_index[i])==256):\n",
        "        index=i\n",
        "        break;\n",
        "\n",
        "    # print(index)\n",
        "### Ta2Dg only the stance phase of the gait\n",
        "###################################################################################################################################################\n",
        "    B=A[k:k+1,0:index,:]  ### Ta2Dg only the stance phase of the gait\n",
        "    C_1=B.reshape((B.shape[0]*B.shape[1],B.shape[2]))\n",
        "    if (k==0):\n",
        "      C=C_1\n",
        "    else:\n",
        "      C=np.append(C,C_1,axis=0)\n",
        "\n",
        "  index_24 = data_fields.index('body weight')\n",
        "  index_25 = data_fields.index('body height')\n",
        "\n",
        "  BW=(C[0:1, index_24]*9.8)\n",
        "  BWH=(C[0:1, index_24]*9.8)*C[:, index_25]\n",
        "\n",
        "  V=C[:,110:154]\n",
        "  V=V.reshape(V.shape[0],11,4)\n",
        "\n",
        "  V=(V-V[:,2:3,:])\n",
        "\n",
        "  V=augmentation_all(torch.from_numpy(V))\n",
        "  V=V.reshape(-1,44)\n",
        "  velocity_all, acceleration_all = extract_vel_acc(V)\n",
        "\n",
        "  V=V/C[0:1, index_25]\n",
        "\n",
        "\n",
        "      ### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "    ### 0:48- IMU, 48:92-2D body coordinate, 92:136 -2D velocity, 136:180 -2D acceleration, 180:185-- Target\n",
        "\n",
        "  D=np.hstack((C[:,71:77],C[:,58:64],C[:,19:25],C[:,32:38],C[:,45:51],C[:,6:12],C[:,84:90],C[:,97:103],V,velocity_all, acceleration_all, C[:,3:5],-C[:, 154:155]/BW,\n",
        "              -C[:, 156:157]/BW,-C[:, 155:156]/BW))\n",
        "\n",
        "  return D\n"
      ],
      "metadata": {
        "id": "Hk2t1FW-dwMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZIw9tIU2Q7H"
      },
      "outputs": [],
      "source": [
        "# data_subject_01 = data_all_sub['subject_01']\n",
        "# subject_1_aug=data_extraction_aug(data_subject_01)\n",
        "\n",
        "# print(subject_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsCxXC1B-JXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70e00f7-dc00-42f0-82db-6e5df18fa02c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84490, 185)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "subject_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9iGjQ6uXU-"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fTO4veYsyC7"
      },
      "outputs": [],
      "source": [
        "main_dir = \"/content/drive/My Drive/public dataset/Public_dataset_2/Subject01\"\n",
        "os.mkdir(main_dir)\n",
        "path=\"/content/\"\n",
        "subject='Subject_01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvt8kQG5iLMP"
      },
      "outputs": [],
      "source": [
        "train_dataset=np.concatenate((subject_1,subject_2,subject_3,subject_4,subject_5,subject_6,subject_7,subject_8,subject_9,subject_10,subject_11,\n",
        "                              subject_12,subject_14,subject_15,subject_16,subject_17),axis=0)\n",
        "\n",
        "test_dataset=subject_13\n",
        "\n",
        "encoder='LSTM'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7U-luFUh3gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c641a08a-c120-43c4-a19c-1fc3768c8fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]]\n",
            "(1241165, 185)\n",
            "(1241200, 5)\n",
            "(19859, 50, 180) (19859, 50, 5) (4965, 50, 180) (4965, 50, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Train features #\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "x_train=train_dataset[:,0:180]\n",
        "\n",
        "\n",
        "scale= StandardScaler()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_X_1_1=x_train\n",
        "\n",
        "# # Test features #\n",
        "\n",
        "\n",
        "x_test=test_dataset[:,0:180]\n",
        "\n",
        "test_X_1_1=x_test\n",
        "\n",
        "m1=180\n",
        "m2=185\n",
        "\n",
        "\n",
        "  ### Label ###\n",
        "\n",
        "train_y_1_1=train_dataset[:,m1:m2]\n",
        "test_y_1_1=test_dataset[:,m1:m2]\n",
        "\n",
        "train_dataset_1=np.concatenate((train_X_1_1,train_y_1_1),axis=1)\n",
        "test_dataset_1=np.concatenate((test_X_1_1,test_y_1_1),axis=1)\n",
        "\n",
        "train_dataset_1=pd.DataFrame(train_dataset_1)\n",
        "test_dataset_1=pd.DataFrame(test_dataset_1)\n",
        "\n",
        "train_dataset_1.dropna(axis=0,inplace=True)\n",
        "test_dataset_1.dropna(axis=0,inplace=True)\n",
        "\n",
        "train_dataset_1=np.array(train_dataset_1)\n",
        "test_dataset_1=np.array(test_dataset_1)\n",
        "\n",
        "train_dataset_sum = np. sum(train_dataset_1)\n",
        "array_has_nan = np. isinf(train_dataset_1[:,48:180])\n",
        "\n",
        "print(array_has_nan)\n",
        "\n",
        "print(train_dataset_1.shape)\n",
        "\n",
        "\n",
        "\n",
        "train_X_1=train_dataset_1[:,0:m1]\n",
        "test_X_1=test_dataset_1[:,0:m1]\n",
        "\n",
        "train_y_1=train_dataset_1[:,m1:m2]\n",
        "test_y_1=test_dataset_1[:,m1:m2]\n",
        "\n",
        "\n",
        "\n",
        "L1=len(train_X_1)\n",
        "L2=len(test_X_1)\n",
        "\n",
        "\n",
        "w=50\n",
        "\n",
        "\n",
        "\n",
        "a1=L1//w\n",
        "b1=L1%w\n",
        "\n",
        "a2=L2//w\n",
        "b2=L2%w\n",
        "\n",
        "# a3=L3//w\n",
        "# b3=L3%w\n",
        "\n",
        "     #### Features ####\n",
        "train_X_2=train_X_1[L1-w+b1:L1,:]\n",
        "test_X_2=test_X_1[L2-w+b2:L2,:]\n",
        "# validation_X_2=validation_X_1[L3-w+b3:L3,:]\n",
        "\n",
        "\n",
        "    #### Output ####\n",
        "\n",
        "train_y_2=train_y_1[L1-w+b1:L1,:]\n",
        "test_y_2=test_y_1[L2-w+b2:L2,:]\n",
        "# validation_y_2=validation_y_1[L3-w+b3:L3,:]\n",
        "\n",
        "\n",
        "\n",
        "     #### Features ####\n",
        "\n",
        "train_X=np.concatenate((train_X_1,train_X_2),axis=0)\n",
        "test_X=np.concatenate((test_X_1,test_X_2),axis=0)\n",
        "# validation_X=np.concatenate((validation_X_1,validation_X_2),axis=0)\n",
        "\n",
        "\n",
        "    #### Output ####\n",
        "\n",
        "train_y=np.concatenate((train_y_1,train_y_2),axis=0)\n",
        "test_y=np.concatenate((test_y_1,test_y_2),axis=0)\n",
        "# validation_y=np.concatenate((validation_y_1,validation_y_2),axis=0)\n",
        "\n",
        "\n",
        "print(train_y.shape)\n",
        "    #### Reshaping ####\n",
        "train_X_3_p= train_X.reshape((a1+1,w,train_X.shape[1]))\n",
        "test_X = test_X.reshape((a2+1,w,test_X.shape[1]))\n",
        "\n",
        "\n",
        "train_y_3_p= train_y.reshape((a1+1,w,5))\n",
        "test_y= test_y.reshape((a2+1,w,5))\n",
        "\n",
        "\n",
        "\n",
        "# train_X_1D=train_X_3\n",
        "test_X_1D=test_X\n",
        "\n",
        "train_X_3=train_X_3_p\n",
        "train_y_3=train_y_3_p\n",
        "# print(train_X_4.shape,train_y_3.shape)\n",
        "\n",
        "\n",
        "train_X_1D, X_validation_1D, train_y_5, Y_validation = train_test_split(train_X_3,train_y_3, test_size=0.20, random_state=True)\n",
        "#train_X_1D, X_validation_1D_ridge, train_y, Y_validation_ridge = train_test_split(train_X_1D_m,train_y_m, test_size=0.10, random_state=True)   [0:2668,:,:]\n",
        "\n",
        "print(train_X_1D.shape,train_y_5.shape,X_validation_1D.shape,Y_validation.shape)\n",
        "\n",
        "\n",
        "s=test_X_1D.shape[0]*w\n",
        "\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_y[0:10,:,0].reshape(500,1))"
      ],
      "metadata": {
        "id": "ZEq-YZ1CDN_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "94953fa9-7cc4-452a-c15d-49a1f18cdac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7b02ffaf26b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4C97S-PeeXd"
      },
      "outputs": [],
      "source": [
        "# from numpy import savetxt\n",
        "# savetxt('train_data_check.csv', train_dataset_1[:,48:92], delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjRHNe1ckRoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173f703c-a3ab-411a-bf18-c5fca3cdb47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19859, 50, 44])\n",
            "torch.Size([19859, 50, 22, 2])\n"
          ]
        }
      ],
      "source": [
        "### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "### 0:48- IMU, 48:92-2D body coordinate, 92:97-- Target\n",
        "\n",
        "\n",
        "### Data Processing\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "val_targets = torch.Tensor(Y_validation)\n",
        "test_features = torch.Tensor(test_X_1D)\n",
        "test_targets = torch.Tensor(test_y)\n",
        "\n",
        "\n",
        "## all Modality Features\n",
        "\n",
        "train_features = torch.Tensor(train_X_1D)\n",
        "train_targets = torch.Tensor(train_y_5)\n",
        "val_features = torch.Tensor(X_validation_1D)\n",
        "\n",
        "\n",
        "train_features_acc_8=torch.cat((train_features[:,:,0:3],train_features[:,:,6:9],train_features[:,:,12:15],train_features[:,:,18:21],train_features[:,:,24:27]\\\n",
        "                             ,train_features[:,:,30:33],train_features[:,:,36:39],train_features[:,:,42:45]),axis=-1)\n",
        "test_features_acc_8=torch.cat((test_features[:,:,0:3],test_features[:,:,6:9],test_features[:,:,12:15],test_features[:,:,18:21],test_features[:,:,24:27]\\\n",
        "                             ,test_features[:,:,30:33],test_features[:,:,36:39],test_features[:,:,42:45]),axis=-1)\n",
        "val_features_acc_8=torch.cat((val_features[:,:,0:3],val_features[:,:,6:9],val_features[:,:,12:15],val_features[:,:,18:21],val_features[:,:,24:27]\\\n",
        "                             ,val_features[:,:,30:33],val_features[:,:,36:39],val_features[:,:,42:45]),axis=-1)\n",
        "\n",
        "\n",
        "train_features_gyr_8=torch.cat((train_features[:,:,3:6],train_features[:,:,9:12],train_features[:,:,15:18],train_features[:,:,21:24],train_features[:,:,27:30]\\\n",
        "                             ,train_features[:,:,33:36],train_features[:,:,39:42],train_features[:,:,45:48]),axis=-1)\n",
        "test_features_gyr_8=torch.cat((test_features[:,:,3:6],test_features[:,:,9:12],test_features[:,:,15:18],test_features[:,:,21:24],test_features[:,:,27:30]\\\n",
        "                             ,test_features[:,:,33:36],test_features[:,:,39:42],test_features[:,:,45:48]),axis=-1)\n",
        "val_features_gyr_8=torch.cat((val_features[:,:,3:6],val_features[:,:,9:12],val_features[:,:,15:18],val_features[:,:,21:24],val_features[:,:,27:30]\\\n",
        "                             ,val_features[:,:,33:36],val_features[:,:,39:42],val_features[:,:,45:48]),axis=-1)\n",
        "\n",
        "\n",
        "train_features_2D_point=train_features[:,:,48:92]\n",
        "test_features_2D_point=test_features[:,:,48:92]\n",
        "val_features_2D_point=val_features[:,:,48:92]\n",
        "\n",
        "print(train_features_2D_point.shape)\n",
        "\n",
        "sequence = [0, 2, 1, 3]\n",
        "\n",
        "train_features_2D_point_2D_1=train_features_2D_point.view(train_features_2D_point.shape[0],train_features_2D_point.shape[1],11,4)[:,:,:,sequence]\n",
        "test_features_2D_point_2D_1=test_features_2D_point.view(test_features_2D_point.shape[0],test_features_2D_point.shape[1],11,4)[:,:,:,sequence]\n",
        "val_features_2D_point_2D_1=val_features_2D_point.view(val_features_2D_point.shape[0],val_features_2D_point.shape[1],11,4)[:,:,:,sequence]\n",
        "\n",
        "\n",
        "train_features_2D_point_2D=train_features_2D_point_2D_1.reshape(train_features_2D_point.shape[0],train_features_2D_point.shape[1],22,2)\n",
        "test_features_2D_point_2D=test_features_2D_point_2D_1.reshape(test_features_2D_point.shape[0],test_features_2D_point.shape[1],22,2)\n",
        "val_features_2D_point_2D=val_features_2D_point_2D_1.reshape(val_features_2D_point.shape[0],val_features_2D_point.shape[1],22,2)\n",
        "\n",
        "\n",
        "\n",
        "print(train_features_2D_point_2D.shape)\n",
        "\n",
        "\n",
        "train_features_2D_velocity=train_features[:,:,92:136]\n",
        "test_features_2D_velocity=test_features[:,:,92:136]\n",
        "val_features_2D_velocity=val_features[:,:,92:136]\n",
        "\n",
        "\n",
        "train_features_2D_acceleration=train_features[:,:,136:180]\n",
        "test_features_2D_acceleration=test_features[:,:,136:180]\n",
        "val_features_2D_acceleration=val_features[:,:,136:180]\n",
        "\n",
        "\n",
        "train = TensorDataset(train_features, train_features_acc_8,train_features_gyr_8, train_features_2D_point,train_features_2D_point_2D,train_features_2D_velocity,train_features_2D_acceleration, train_targets)\n",
        "val = TensorDataset(val_features, val_features_acc_8, val_features_gyr_8, val_features_2D_point,val_features_2D_point_2D, val_features_2D_velocity, val_features_2D_acceleration, val_targets)\n",
        "test = TensorDataset(test_features, test_features_acc_8, test_features_gyr_8, test_features_2D_point, test_features_2D_point_2D, test_features_2D_velocity,test_features_2D_acceleration, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP_eDnJwrKCC"
      },
      "source": [
        "# Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdVunLKprSkv"
      },
      "outputs": [],
      "source": [
        "def RMSE_prediction(yhat_4,test_y,s):\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,5))\n",
        "  yhat=yhat_4.reshape((s1,5))\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  y_4=y_4_no\n",
        "  y_5=y_5_no\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "\n",
        "\n",
        "\n",
        "  Z_1=y_1\n",
        "  Z_2=y_2\n",
        "  Z_3=y_3\n",
        "  Z_4=y_4\n",
        "  Z_5=y_5\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "\n",
        "  return rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "def PCC_prediction(yhat_4,test_y,s):\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,5))\n",
        "  yhat=yhat_4.reshape((s1,5))\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  y_4=y_4_no\n",
        "  y_5=y_5_no\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "\n",
        "\n",
        "\n",
        "  Y_1=y_1\n",
        "  Y_2=y_2\n",
        "  Y_3=y_3\n",
        "  Y_4=y_4\n",
        "  Y_5=y_5\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "  return rmse, p, Y_1,Y_2,Y_3,Y_4,Y_5\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "# def estimate_coef(x, y):\n",
        "#     # number of observations/points\n",
        "#     n = np.size(x)\n",
        "\n",
        "#     # mean of x and y vector\n",
        "#     m_x = np.mean(x)\n",
        "#     m_y = np.mean(y)\n",
        "\n",
        "#     # calculating cross-deviation and deviation about x\n",
        "#     SS_xy = np.sum(y*x) - n*m_y*m_x\n",
        "#     SS_xx = np.sum(x*x) - n*m_x*m_x\n",
        "\n",
        "#     # calculating regression coefficients\n",
        "#     b_1 = SS_xy / SS_xx\n",
        "#     b_0 = m_y - b_1*m_x\n",
        "\n",
        "#     return (b_0, b_1)\n",
        "\n",
        "def estimate_coef(x, y):\n",
        "    # Convert input data to PyTorch tensors\n",
        "    x_tensor = torch.tensor(x, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    # Calculate the number of observations/points\n",
        "    n = x_tensor.size(0)\n",
        "\n",
        "    # Calculate the mean of x and y tensors\n",
        "    m_x = torch.mean(x_tensor)\n",
        "    m_y = torch.mean(y_tensor)\n",
        "\n",
        "    # Calculate cross-deviation and deviation about x\n",
        "    SS_xy = torch.sum(y_tensor * x_tensor) - n * m_y * m_x\n",
        "    SS_xx = torch.sum(x_tensor * x_tensor) - n * m_x * m_x\n",
        "\n",
        "    # Calculate regression coefficients\n",
        "    b_1 = SS_xy / SS_xx\n",
        "    b_0 = m_y - b_1 * m_x\n",
        "\n",
        "    return (b_0.item(), b_1.item())\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "### Test dataset has to be without shuffle for this function to work properly\n",
        "\n",
        "\n",
        "def DLR_prediction(yhat_4,test_y,s,Y_1,Y_2,Y_3,Y_4,Y_5,Z_1,Z_2,Z_3,Z_4,Z_5):\n",
        "\n",
        "  a_1,b_1=estimate_coef(Y_1,Z_1)\n",
        "  a_2,b_2=estimate_coef(Y_2,Z_2)\n",
        "  a_3,b_3=estimate_coef(Y_3,Z_3)\n",
        "  a_4,b_4=estimate_coef(Y_4,Z_4)\n",
        "  a_5,b_5=estimate_coef(Y_5,Z_5)\n",
        "\n",
        "  # print(a_1,b_1)\n",
        "  # print(a_2,b_2)\n",
        "  # print(a_3,b_3)\n",
        "  # print(a_4,b_4)\n",
        "  # print(a_5,b_5)\n",
        "\n",
        "\n",
        "  #### All 16 angles prediction  ####\n",
        "\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,5))\n",
        "  yhat=yhat_4.reshape((s1,5))\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  y_4=y_4_no\n",
        "  y_5=y_5_no\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "\n",
        "\n",
        "  y_1=y_1*b_1+a_1\n",
        "  y_2=y_2*b_2+a_2\n",
        "  y_3=y_3*b_3+a_3\n",
        "  y_4=y_4*b_4+a_4\n",
        "  y_5=y_5*b_5+a_5\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "\n",
        "\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "  return rmse, p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5Q-cJ2tK8Vb"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        mse = nn.MSELoss()(pred, target)\n",
        "        rmse = torch.sqrt(mse)\n",
        "        return rmse\n"
      ],
      "metadata": {
        "id": "wVzTJJzbjfn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HtJVDh1mEB-"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCrgBUvih7OD"
      },
      "outputs": [],
      "source": [
        "def train_2D_early(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_2D_early_2D(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_2D_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data_2D_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "5TDgV29Xjuy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mm_target_sota(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    criterion_2 =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            target_output= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss_1 = criterion_2(target_output, target.to(device).float())\n",
        "\n",
        "            loss = loss_1\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "PxeT5WSl5UoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOTA_Models"
      ],
      "metadata": {
        "id": "JU11NXkGUqCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. FFN"
      ],
      "metadata": {
        "id": "Hue48X4BS6mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, input_1D):\n",
        "        super(FFN, self).__init__()\n",
        "\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "\n",
        "        self.fc1 = nn.Linear(input_1D, 512)\n",
        "        self.dropout1 = nn.Dropout(0.05)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.dropout2 = nn.Dropout(0.05)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.dropout3 = nn.Dropout(0.05)\n",
        "\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "        self.fc_f=nn.Linear(128*50, 5*50)\n",
        "\n",
        "\n",
        "    def forward(self, inputs_1D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        x = F.relu(self.fc1(inputs_1D_N))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x=self.flatten(x)\n",
        "\n",
        "        x = self.fc_f(x).view(-1,50,5)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "l8ioaOg6TC0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = FFN(44)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "num_params = count_parameters(model)\n",
        "print(\"Number of parameters:\", num_params)\n",
        "\n",
        "mm_early_ffn = train_2D_early(train_loader, lr,40,model,path + encoder + '_ffn_video.pth')"
      ],
      "metadata": {
        "id": "chPlaJFSTQ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early_ffn= FFN(44)\n",
        "mm_early_ffn.load_state_dict(torch.load(path+encoder+'_ffn_video.pth'))\n",
        "mm_early_ffn.to(device)\n",
        "\n",
        "mm_early_ffn.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early_ffn(data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_1=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "SJIPae1rTQ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Bi-LSTM"
      ],
      "metadata": {
        "id": "TbKi4_MDkS0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 512, bidirectional=False, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(512, 256, bidirectional=False, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout(out_2)\n",
        "        out_2=self.flatten(out_2)\n",
        "\n",
        "\n",
        "        return out_2"
      ],
      "metadata": {
        "id": "n78guVL0kS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MM_early(nn.Module):\n",
        "\n",
        "    def __init__(self, input, drop_prob=0.35):\n",
        "        super(MM_early, self).__init__()\n",
        "        self.encoder_input=Encoder(input,drop_prob)\n",
        "        self.fc=nn.Linear(256*50, 5*50)\n",
        "        self.BN= nn.BatchNorm1d(input, affine=False)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "\n",
        "        input_x_1=input_x.view(input_x.size(0)*input_x.size(1),input_x.size(-1))\n",
        "        input_x_1=self.BN(input_x_1)\n",
        "        input_x_2=input_x_1.view(-1, 50, input_x_1.size(-1))\n",
        "        out=self.encoder_input(input_x_2)\n",
        "\n",
        "        out = self.fc(out).view(-1,50,5)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "El1oSRzwkS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = MM_early(44)\n",
        "\n",
        "mm_early = train_2D_early(train_loader, lr,40,model,path + encoder + '_lstm_video.pth')"
      ],
      "metadata": {
        "id": "Kb0Zs7n6kS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early= MM_early(44)\n",
        "mm_early.load_state_dict(torch.load(path+encoder+'_lstm_video.pth'))\n",
        "mm_early.to(device)\n",
        "\n",
        "mm_early.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early(data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_2=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "ULhTbgxWkS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Conv_2D"
      ],
      "metadata": {
        "id": "pdVcxRD4Y9cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_CNN_2D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=(3,5), stride=(1,1), padding=(1,2)):\n",
        "        super(Encoder_CNN_2D, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv2d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv2d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm2d(output_size)\n",
        "        self.BN_4= nn.BatchNorm2d(output_size)\n",
        "        self.pool_1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.transpose(1, 3)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool_2(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = x.transpose(1, 3)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # x = self.flatten(x)\n",
        "\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "NKUk40ZkY9cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class conv2d_model(nn.Module):\n",
        "    def __init__(self, input_2D):\n",
        "        super(conv2d_model, self).__init__()\n",
        "\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "        self.conv2d = Encoder_CNN_2D(input_2D,0.05)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc_f=nn.Linear(480, 5*50)\n",
        "\n",
        "    def forward(self, inputs_2D_N):\n",
        "\n",
        "        inputs_2D_N_1=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N_2=self.BN_2(inputs_2D_N_1)\n",
        "        inputs_2D_N_3=inputs_2D_N_2.transpose(1,3)\n",
        "\n",
        "        x=self.conv2d(inputs_2D_N_3)\n",
        "        x=self.flatten(x)\n",
        "\n",
        "        x = self.fc_f(x).view(-1,50,5)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "G9f_D7erY9cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = conv2d_model(2)\n",
        "\n",
        "mm_early = train_2D_early_2D(train_loader, lr,40,model,path + encoder + '_conv2d_video.pth')"
      ],
      "metadata": {
        "id": "CALTpdOWY9cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early= conv2d_model(2)\n",
        "mm_early.load_state_dict(torch.load(path+encoder+'_conv2d_video.pth'))\n",
        "mm_early.to(device)\n",
        "\n",
        "mm_early.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early(data_2D_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_3=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "-hb74LyfY9ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Kinetics-FM-DLR-Net"
      ],
      "metadata": {
        "id": "fdptyv1jWklC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function"
      ],
      "metadata": {
        "id": "nQZofbgO7cm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PearsonCorrLoss(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(PearsonCorrLoss, self).__init__()\n",
        "\n",
        "  def forward(self, y_true, y_pred):\n",
        "\n",
        "    # Calculate mean values\n",
        "    mx = torch.mean(y_true)\n",
        "    my = torch.mean(y_pred)\n",
        "\n",
        "    # Calculate differences from mean\n",
        "    xm, ym = y_true - mx, y_pred - my\n",
        "\n",
        "    # Calculate numerator and denominator of Pearson correlation coefficient\n",
        "    r_num = torch.sum(torch.mul(xm, ym))\n",
        "    r_den = torch.sqrt(torch.mul(torch.sum(torch.square(xm)), torch.sum(torch.square(ym))))\n",
        "\n",
        "    # Calculate Pearson correlation coefficient\n",
        "    r = r_num / r_den\n",
        "\n",
        "    # Clamp r between 0 and 1\n",
        "    r = torch.clamp(r, 0, 1.0)\n",
        "\n",
        "    # Calculate l2 loss\n",
        "    l2 = 1 - torch.square(r)\n",
        "\n",
        "\n",
        "\n",
        "    return l2"
      ],
      "metadata": {
        "id": "wms7jORR7cm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sota(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "    # criterion =correlation_coefficient_loss_joint_pytorch()\n",
        "\n",
        "    # criterion=PearsonCorrLoss()\n",
        "    optimizer= torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output_1, output_2, output_3, output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "                    # Compute the regularization loss for the custom linear layers\n",
        "            regularization_loss = 0.0\n",
        "            if hasattr(model.output_GRU, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_GRU.regularizer_loss()\n",
        "            if hasattr(model.output_C1, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_C1.regularizer_loss()\n",
        "            if hasattr(model.output_C2, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_C2.regularizer_loss()\n",
        "\n",
        "            # output= model(data_1D.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss=criterion(output_1, target.to(device).float())+criterion(output_2, target.to(device).float())+criterion(output_3, target.to(device).float())\\\n",
        "            +criterion(output, target.to(device).float())+regularization_loss\n",
        "            loss_1=criterion(output, target.to(device).float())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output_1, output_2, output_3, output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "                # output= model(data_1D.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "VQx-cOG97cm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sota_pcc(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    # criterion =RMSELoss()\n",
        "    # criterion =correlation_coefficient_loss_joint_pytorch()\n",
        "\n",
        "    criterion=PearsonCorrLoss()\n",
        "    optimizer= torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output_1, output_2, output_3, output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "                    # Compute the regularization loss for the custom linear layers\n",
        "            regularization_loss = 0.0\n",
        "            if hasattr(model.output_GRU, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_GRU.regularizer_loss()\n",
        "            if hasattr(model.output_C1, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_C1.regularizer_loss()\n",
        "            if hasattr(model.output_C2, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_C2.regularizer_loss()\n",
        "\n",
        "            # output= model(data_1D.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss=criterion(output_1, target.to(device).float())+criterion(output_2, target.to(device).float())+criterion(output_3, target.to(device).float())\\\n",
        "            +criterion(output, target.to(device).float())+regularization_loss\n",
        "            loss_1=criterion(output, target.to(device).float())\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "\n",
        "                output_1, output_2, output_3, output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "                # output= model(data_1D.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "y5EBam4o7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "A3GSoset7cm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_GRU(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_GRU, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 512, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(1024, 256, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "        out_2=self.flatten(out_2)\n",
        "\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "ndBtsOT-7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_CNN_1D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv1d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv1d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm1d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm1d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm1d(output_size)\n",
        "        self.BN_4= nn.BatchNorm1d(output_size)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.transpose(1, 2)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "splDuQJz7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_CNN_2D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=(3,5), stride=(1,1), padding=(1,2)):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv2d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv2d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm2d(output_size)\n",
        "        self.BN_4= nn.BatchNorm2d(output_size)\n",
        "        self.pool_1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 3)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool_2(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "\n",
        "        x = x.transpose(1, 3)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZRWgu_IV7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RegularizedLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, weight_decay=0.001):\n",
        "        super(RegularizedLinear, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.linear(input)\n",
        "\n",
        "    def regularizer_loss(self):\n",
        "        return self.weight_decay * torch.sum(self.linear.bias**2)\n"
      ],
      "metadata": {
        "id": "yEiozFUM7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Kinetics_FM_Net(nn.Module):\n",
        "    def __init__(self, input_1D,input_2D):\n",
        "        super(Kinetics_FM_Net, self).__init__()\n",
        "        self.w = w\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "\n",
        "        # 1D Models\n",
        "\n",
        "        self.model_1=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_2=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_3=Encoder_GRU(input_1D,0.30)\n",
        "\n",
        "        self.cnn_1D = Encoder_CNN_1D(input_1D,0.25)\n",
        "        self.cnn_2D = Encoder_CNN_2D(input_2D,0.25)\n",
        "\n",
        "        # Outputs\n",
        "        self.output_GRU = RegularizedLinear(w*512, 5*w)\n",
        "        self.output_C2 = RegularizedLinear(2*3*32+9*32+w*512, 5*w)\n",
        "        self.output_C1 = RegularizedLinear(3*32+w*512, 5*w)\n",
        "\n",
        "        self.l1=nn.Linear(5,128)\n",
        "        self.l2=nn.Linear(128,5)\n",
        "\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N=self.BN_2(inputs_2D_N)\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "\n",
        "\n",
        "        model_1_output = self.model_1(inputs_1D_N)\n",
        "        model_2_output = self.model_2(inputs_1D_N)\n",
        "        model_3_output = self.model_3(inputs_1D_N)\n",
        "\n",
        "        cnn_output_1D = self.cnn_1D(inputs_1D_N)\n",
        "        cnn_output_2D = self.cnn_2D(inputs_2D_N)\n",
        "\n",
        "\n",
        "        model_2_output = torch.cat([model_2_output, cnn_output_1D], dim=-1)\n",
        "        model_3_output = torch.cat([model_3_output, cnn_output_2D], dim=-1)\n",
        "\n",
        "\n",
        "        output_GRU = self.output_GRU(model_1_output)\n",
        "        output_GRU=output_GRU.view(-1,w,5)\n",
        "\n",
        "        output_C1 = self.output_C1(model_2_output)\n",
        "        output_C1=output_C1.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_C2 = self.output_C2(model_3_output)\n",
        "        output_C2=output_C2.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_GRU_1=F.relu(self.l1(output_GRU))\n",
        "        output_GRU_1=F.sigmoid(self.l2(output_GRU_1))\n",
        "        output_GRU_2=output_GRU*output_GRU_1\n",
        "\n",
        "        output_C1_1=F.relu(self.l1(output_C1))\n",
        "        output_C1_1=F.sigmoid(self.l2(output_C1_1))\n",
        "        output_C1_2=output_C1*output_C1_1\n",
        "\n",
        "        output_C2_1=F.relu(self.l1(output_C2))\n",
        "        output_C2_1=F.sigmoid(self.l2(output_C2_1))\n",
        "        output_C2_2=output_C2*output_C2_1\n",
        "\n",
        "\n",
        "        output = output_GRU_2+output_C1_2+output_C2_2\n",
        "\n",
        "\n",
        "        return output_GRU, output_C1, output_C2, output\n"
      ],
      "metadata": {
        "id": "CG1I-syK7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "VaCs8OtF7cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "qO7K-6Ee7cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = Kinetics_FM_Net(44,2)\n",
        "\n",
        "sota_1 = train_sota(train_loader, lr,10,model,path+'sota_4_video.pth')"
      ],
      "metadata": {
        "id": "ZkpM1Qgx7cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sota_1= Kinetics_FM_Net(44,2)\n",
        "sota_1.load_state_dict(torch.load(path+'sota_4_video.pth'))\n",
        "sota_1.to(device)\n",
        "\n",
        "sota_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "\n",
        "        output_1,output_2,output_3,output= sota_1(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "        # # Concatenate predictions and targets\n",
        "        if i == 0:\n",
        "            yhat_5 = output\n",
        "            test_target = target\n",
        "        else:\n",
        "            yhat_5 = torch.cat((yhat_5, output), dim=0)\n",
        "            test_target = torch.cat((test_target, target), dim=0)\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "# print(yhat_4.shape)\n",
        "# print(test_y.shape)\n",
        "\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_4=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "jH80hEp77cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Kinetics_FM_Net_pcc(nn.Module):\n",
        "    def __init__(self, input_1D,input_2D):\n",
        "        super(Kinetics_FM_Net_pcc, self).__init__()\n",
        "        self.w = w\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "\n",
        "        # 1D Models\n",
        "\n",
        "        self.model_1=Encoder_GRU(input_1D,0.25)\n",
        "        self.model_2=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_3=Encoder_GRU(input_1D,0.30)\n",
        "\n",
        "        self.cnn_1D = Encoder_CNN_1D(input_1D,0.25)\n",
        "        self.cnn_2D = Encoder_CNN_2D(input_2D,0.25)\n",
        "\n",
        "        # Outputs\n",
        "        self.output_GRU = RegularizedLinear(w*512, 5*w)\n",
        "        self.output_C2 = RegularizedLinear(2*3*32+9*32+w*512, 5*w)\n",
        "        self.output_C1 = RegularizedLinear(3*32+w*512, 5*w)\n",
        "\n",
        "        self.l1=nn.Linear(5,128)\n",
        "        self.l2=nn.Linear(128,5)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N=self.BN_2(inputs_2D_N)\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "\n",
        "\n",
        "        model_1_output = self.model_1(inputs_1D_N)\n",
        "        model_2_output = self.model_2(inputs_1D_N)\n",
        "        model_3_output = self.model_3(inputs_1D_N)\n",
        "\n",
        "        cnn_output_1D = self.cnn_1D(inputs_1D_N)\n",
        "        cnn_output_2D = self.cnn_2D(inputs_2D_N)\n",
        "\n",
        "\n",
        "        model_2_output = torch.cat([model_2_output, cnn_output_1D], dim=-1)\n",
        "        model_3_output = torch.cat([model_3_output, cnn_output_2D], dim=-1)\n",
        "\n",
        "\n",
        "        output_GRU = self.output_GRU(model_1_output)\n",
        "        output_GRU=output_GRU.view(-1,w,5)\n",
        "\n",
        "        output_C1 = self.output_C1(model_2_output)\n",
        "        output_C1=output_C1.view(-1,w,5)\n",
        "\n",
        "        output_C2 = self.output_C2(model_3_output)\n",
        "        output_C2=output_C2.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_GRU_1=F.relu(self.l1(output_GRU))\n",
        "        output_GRU_1=self.dropout(output_GRU_1)\n",
        "        output_GRU_1=F.sigmoid(self.l2(output_GRU_1))\n",
        "        output_GRU_2=output_GRU*output_GRU_1\n",
        "\n",
        "        output_C1_1=F.relu(self.l1(output_C1))\n",
        "        output_C1_1=self.dropout(output_C1_1)\n",
        "        output_C1_1=F.sigmoid(self.l2(output_C1_1))\n",
        "        output_C1_2=output_C1*output_C1_1\n",
        "\n",
        "        output_C2_1=F.relu(self.l1(output_C2))\n",
        "        output_C2_1=self.dropout(output_C2_1)\n",
        "        output_C2_1=F.sigmoid(self.l2(output_C2_1))\n",
        "        output_C2_2=output_C2*output_C2_1\n",
        "\n",
        "\n",
        "        output = output_GRU_2+output_C1_2+output_C2_2\n",
        "\n",
        "        return output_GRU, output_C1, output_C2, output\n"
      ],
      "metadata": {
        "id": "TxgrW1HC7cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "k-KDqppr7cnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = Kinetics_FM_Net_pcc(44,2)\n",
        "\n",
        "sota_1_pcc = train_sota_pcc(train_loader, lr,10,model,path+'sota_4_pcc_video.pth')"
      ],
      "metadata": {
        "id": "CD4b420XBex1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sota_1_pcc= Kinetics_FM_Net_pcc(44,2)\n",
        "sota_1_pcc.load_state_dict(torch.load(path+'sota_4_pcc_video.pth'))\n",
        "sota_1_pcc.to(device)\n",
        "\n",
        "sota_1_pcc.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output_1,output_2,output_3,output= sota_1_pcc(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "        # # Concatenate predictions and targets\n",
        "        if i == 0:\n",
        "            yhat_5 = output\n",
        "            test_target = target\n",
        "        else:\n",
        "            yhat_5 = torch.cat((yhat_5, output), dim=0)\n",
        "            test_target = torch.cat((test_target, target), dim=0)\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "\n",
        "rmse, p, Y_1,Y_2,Y_3,Y_4,Y_5=PCC_prediction(yhat_4,test_target,s)\n",
        "rmse,p=DLR_prediction(yhat_4,test_target,s,Y_1,Y_2,Y_3,Y_4,Y_5,Z_1,Z_2,Z_3,Z_4,Z_5)\n",
        "\n",
        "\n",
        "ablation_5=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "c0zs1Crt7cnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. DL-Kineitcs-FM-Net"
      ],
      "metadata": {
        "id": "LPKAAk5_TtPl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Ab-XOeT4fE"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PTHhS--T4fF"
      },
      "outputs": [],
      "source": [
        "class Encoder_GRU(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_GRU, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 512, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(1024, 256, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "        out_2=self.flatten(out_2)\n",
        "\n",
        "\n",
        "        return out_2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAeHpv2DT4fF"
      },
      "outputs": [],
      "source": [
        "class Encoder_CNN_1D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv1d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv1d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm1d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm1d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm1d(output_size)\n",
        "        self.BN_4= nn.BatchNorm1d(output_size)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.transpose(1, 2)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajKQtaILT4fF"
      },
      "outputs": [],
      "source": [
        "class Encoder_CNN_2D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=(3,5), stride=(1,1), padding=(1,2)):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv2d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv2d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm2d(output_size)\n",
        "        self.BN_4= nn.BatchNorm2d(output_size)\n",
        "        self.pool_1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 3)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool_2(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "        x = x.transpose(1, 3)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JLJF7hYT4fF"
      },
      "outputs": [],
      "source": [
        "class RegularizedLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, weight_decay=0.001):\n",
        "        super(RegularizedLinear, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.linear(input)\n",
        "\n",
        "    def regularizer_loss(self):\n",
        "        return self.weight_decay * torch.sum(self.linear.bias**2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqTCcQCkT4fF"
      },
      "outputs": [],
      "source": [
        "class Kinetics_FM_Net(nn.Module):\n",
        "    def __init__(self, input_1D,input_2D):\n",
        "        super(Kinetics_FM_Net, self).__init__()\n",
        "        self.w = w\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "\n",
        "        # 1D Models\n",
        "\n",
        "        self.model_1=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_2=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_3=Encoder_GRU(input_1D,0.30)\n",
        "\n",
        "        self.cnn_1D = Encoder_CNN_1D(input_1D,0.25)\n",
        "        self.cnn_2D = Encoder_CNN_2D(input_2D,0.25)\n",
        "\n",
        "        # Outputs\n",
        "        self.output_GRU = RegularizedLinear(w*512, 5*w)\n",
        "        self.output_C2 = RegularizedLinear(3*2*32+9*32+w*512, 5*w)\n",
        "        self.output_C1 = RegularizedLinear(3*32+w*512, 5*w)\n",
        "\n",
        "        self.l1=nn.Linear(5,128)\n",
        "        self.l2=nn.Linear(128,5)\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N=self.BN_2(inputs_2D_N)\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "\n",
        "\n",
        "        model_1_output = self.model_1(inputs_1D_N)\n",
        "        model_2_output = self.model_2(inputs_1D_N)\n",
        "        model_3_output = self.model_3(inputs_1D_N)\n",
        "\n",
        "        cnn_output_1D = self.cnn_1D(inputs_1D_N)\n",
        "        cnn_output_2D = self.cnn_2D(inputs_2D_N)\n",
        "\n",
        "\n",
        "        model_2_output = torch.cat([model_2_output, cnn_output_1D], dim=-1)\n",
        "        model_3_output = torch.cat([model_3_output, cnn_output_2D], dim=-1)\n",
        "\n",
        "\n",
        "        output_GRU = self.output_GRU(model_1_output)\n",
        "        output_GRU=output_GRU.view(-1,w,5)\n",
        "\n",
        "        output_C1 = self.output_C1(model_2_output)\n",
        "        output_C1=output_C1.view(-1,w,5)\n",
        "\n",
        "        output_C2 = self.output_C2(model_3_output)\n",
        "        output_C2=output_C2.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_GRU_1=F.relu(self.l1(output_GRU))\n",
        "        output_GRU_1=F.sigmoid(self.l2(output_GRU_1))\n",
        "        output_GRU_2=output_GRU*output_GRU_1\n",
        "\n",
        "        output_C1_1=F.relu(self.l1(output_C1))\n",
        "        output_C1_1=F.sigmoid(self.l2(output_C1_1))\n",
        "        output_C1_2=output_C1*output_C1_1\n",
        "\n",
        "        output_C2_1=F.relu(self.l1(output_C2))\n",
        "        output_C2_1=F.sigmoid(self.l2(output_C2_1))\n",
        "        output_C2_2=output_C2*output_C2_1\n",
        "\n",
        "\n",
        "        output = output_GRU_2+output_C1_2+output_C2_2\n",
        "\n",
        "\n",
        "        return output_GRU, output_C1, output_C2, output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ihQ9DeyWp_G"
      },
      "outputs": [],
      "source": [
        "class Kinetics_FM_Net_pcc(nn.Module):\n",
        "    def __init__(self, input_1D,input_2D):\n",
        "        super(Kinetics_FM_Net_pcc, self).__init__()\n",
        "        self.w = w\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "\n",
        "        # 1D Models\n",
        "\n",
        "        self.model_1=Encoder_GRU(input_1D,0.50)\n",
        "        self.model_2=Encoder_GRU(input_1D,0.50)\n",
        "        self.model_3=Encoder_GRU(input_1D,0.50)\n",
        "\n",
        "        self.cnn_1D = Encoder_CNN_1D(input_1D,0.25)\n",
        "        self.cnn_2D = Encoder_CNN_2D(input_2D,0.25)\n",
        "\n",
        "        # Outputs\n",
        "        self.output_GRU = RegularizedLinear(w*512, 5*w)\n",
        "        self.output_C2 = RegularizedLinear(3*2*32+9*32+w*512, 5*w)\n",
        "        self.output_C1 = RegularizedLinear(3*32+w*512, 5*w)\n",
        "\n",
        "        self.l1=nn.Linear(5,128)\n",
        "        self.l2=nn.Linear(128,5)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N=self.BN_2(inputs_2D_N)\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "\n",
        "\n",
        "        model_1_output = self.model_1(inputs_1D_N)\n",
        "        model_2_output = self.model_2(inputs_1D_N)\n",
        "        model_3_output = self.model_3(inputs_1D_N)\n",
        "\n",
        "        cnn_output_1D = self.cnn_1D(inputs_1D_N)\n",
        "        cnn_output_2D = self.cnn_2D(inputs_2D_N)\n",
        "\n",
        "\n",
        "        model_2_output = torch.cat([model_2_output, cnn_output_1D], dim=-1)\n",
        "        model_3_output = torch.cat([model_3_output, cnn_output_2D], dim=-1)\n",
        "\n",
        "\n",
        "        output_GRU = self.output_GRU(model_1_output)\n",
        "        output_GRU=output_GRU.view(-1,w,5)\n",
        "\n",
        "        output_C1 = self.output_C1(model_2_output)\n",
        "        output_C1=output_C1.view(-1,w,5)\n",
        "\n",
        "        output_C2 = self.output_C2(model_3_output)\n",
        "        output_C2=output_C2.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_GRU_1=F.relu(self.l1(output_GRU))\n",
        "        output_GRU_1=self.dropout(output_GRU_1)\n",
        "        output_GRU_1=F.sigmoid(self.l2(output_GRU_1))\n",
        "        output_GRU_2=output_GRU*output_GRU_1\n",
        "\n",
        "        output_C1_1=F.relu(self.l1(output_C1))\n",
        "        output_C1_1=self.dropout(output_C1_1)\n",
        "        output_C1_1=F.sigmoid(self.l2(output_C1_1))\n",
        "        output_C1_2=output_C1*output_C1_1\n",
        "\n",
        "        output_C2_1=F.relu(self.l1(output_C2))\n",
        "        output_C2_1=self.dropout(output_C2_1)\n",
        "        output_C2_1=F.sigmoid(self.l2(output_C2_1))\n",
        "        output_C2_2=output_C2*output_C2_1\n",
        "\n",
        "\n",
        "        output = output_GRU_2+output_C1_2+output_C2_2\n",
        "\n",
        "        return output_GRU, output_C1, output_C2, output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBAU6cjEUB2w"
      },
      "source": [
        "### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChD2kKnpUB2-"
      },
      "outputs": [],
      "source": [
        "def train_sota(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_1 =RMSELoss()\n",
        "    criterion_2 =PearsonCorrLoss()\n",
        "    optimizer= torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output_1, output_2, output_3, output_rmse,output_4, output_5, output_6, output_pcc,output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "                    # Compute the regularization loss for the custom linear layers\n",
        "            regularization_loss = 0.0\n",
        "            if hasattr(model.fm_net.output_GRU, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net.output_GRU.regularizer_loss()\n",
        "            if hasattr(model.fm_net.output_C1, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net.output_C1.regularizer_loss()\n",
        "            if hasattr(model.fm_net.output_C2, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net.output_C2.regularizer_loss()\n",
        "\n",
        "            if hasattr(model.fm_net_pcc.output_GRU, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net_pcc.output_GRU.regularizer_loss()\n",
        "            if hasattr(model.fm_net_pcc.output_C1, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net_pcc.output_C1.regularizer_loss()\n",
        "            if hasattr(model.fm_net_pcc.output_C2, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net_pcc.output_C2.regularizer_loss()\n",
        "\n",
        "            loss=criterion_1(output_1, target.to(device).float())+criterion_1(output_2, target.to(device).float())+criterion_1(output_3, target.to(device).float())\\\n",
        "            +criterion_2(output_4, target.to(device).float())+criterion_2(output_5, target.to(device).float())+criterion_2(output_6, target.to(device).float())\\\n",
        "            +criterion_1(output_rmse, target.to(device).float())+criterion_2(output_pcc, target.to(device).float())\\\n",
        "            +criterion_1(output, target.to(device).float())+regularization_loss\n",
        "\n",
        "            loss_1=criterion_1(output, target.to(device).float())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "\n",
        "                output_1, output_2, output_3, output_rmse,output_4, output_5, output_6, output_pcc,output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "                val_loss += criterion_1(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-c8xK3gX48t"
      },
      "outputs": [],
      "source": [
        "class DL_Kinetics_FM_Net(nn.Module):\n",
        "    def __init__(self,input_1D,input_2D):\n",
        "        super(DL_Kinetics_FM_Net, self).__init__()\n",
        "\n",
        "        # Instantiate the Kinetics_FM_Net and Kinetics_FM_Net_pcc models\n",
        "        self.fm_net = Kinetics_FM_Net(input_1D,input_2D)\n",
        "        self.fm_net_pcc = Kinetics_FM_Net_pcc(input_1D,input_2D)\n",
        "\n",
        "        # Define GRU and Dense layers\n",
        "        self.gru_rmse_1 = nn.GRU(5, 128, batch_first=True)\n",
        "        self.gru_pcc_1 = nn.GRU(5, 128, batch_first=True)\n",
        "\n",
        "        self.gru_rmse_2 = nn.GRU(5, 128, batch_first=True)\n",
        "        self.gru_pcc_2 = nn.GRU(5, 128, batch_first=True)\n",
        "\n",
        "        self.gru_gain = nn.GRU(256, 128, batch_first=True)\n",
        "        self.gru_offset = nn.GRU(256, 128, batch_first=True)\n",
        "\n",
        "        self.dense_gain = nn.Linear(128, 5)\n",
        "        self.dense_offset = nn.Linear(128, 5)\n",
        "\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        output_1, output_2, output_3, output_rmse = self.fm_net(inputs_1D_N, inputs_2D_N)\n",
        "        output_4, output_5, output_6, output_pcc = self.fm_net_pcc(inputs_1D_N, inputs_2D_N)\n",
        "\n",
        "        output_rmse_1, _ = self.gru_rmse_1(output_rmse)\n",
        "        output_pcc_1, _ = self.gru_pcc_1(output_pcc)\n",
        "        feat_1 = torch.cat((output_rmse_1, output_pcc_1), dim=2)\n",
        "\n",
        "        output_gain, _ = self.gru_gain(feat_1)\n",
        "        output_gain = F.sigmoid(self.dense_gain(output_gain))\n",
        "\n",
        "        output_rmse_2, _ = self.gru_rmse_2(output_rmse)\n",
        "        output_pcc_2, _ = self.gru_pcc_2(output_pcc)\n",
        "        feat_2 = torch.cat((output_rmse_2, output_pcc_2), dim=2)\n",
        "\n",
        "        output_offset, _ = self.gru_offset(feat_2)\n",
        "        output_offset = F.relu(self.dense_offset(output_offset))\n",
        "\n",
        "        output = output_pcc*output_gain + output_offset\n",
        "\n",
        "        return output_1, output_2, output_3, output_rmse, output_4, output_5, output_6, output_pcc, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4TkZBjIW-0g"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEYXl7CiW-0s"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFGXdQj6XBNe"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "model = DL_Kinetics_FM_Net(44,2)\n",
        "\n",
        "sota_1 = train_sota(train_loader, lr,10,model,path+'sota_5_video.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3G48UjCXBNf"
      },
      "outputs": [],
      "source": [
        "sota_1= DL_Kinetics_FM_Net(44,2)\n",
        "sota_1.load_state_dict(torch.load(path+'sota_5_video.pth'))\n",
        "sota_1.to(device)\n",
        "\n",
        "sota_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "\n",
        "        output_1, output_2, output_3, output_rmse,output_4, output_5, output_6, output_pcc,output= sota_1(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "        # # Concatenate predictions and targets\n",
        "        if i == 0:\n",
        "            yhat_5 = output\n",
        "            test_target = target\n",
        "        else:\n",
        "            yhat_5 = torch.cat((yhat_5, output), dim=0)\n",
        "            test_target = torch.cat((test_target, target), dim=0)\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_y,s)\n",
        "\n",
        "ablation_6=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gua9JczaDnG"
      },
      "source": [
        "## 6. Low Rank Multi-Modal Fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyyr-CfF4fE2"
      },
      "outputs": [],
      "source": [
        "class LMF(nn.Module):\n",
        "\n",
        "    def __init__(self, rank, input_modality_1, input_modality_2, input_modality_3, output_dim):\n",
        "\n",
        "        super(LMF, self).__init__()\n",
        "\n",
        "        self.modality_1=input_modality_1\n",
        "        self.modality_2=input_modality_2\n",
        "        self.modality_3=input_modality_3\n",
        "        self.output_dim=output_dim\n",
        "        self.rank=rank\n",
        "\n",
        "        data_type = torch.cuda.FloatTensor\n",
        "\n",
        "        self.modality_1_factor = Parameter(torch.Tensor(self.rank,1, self.modality_1 + 1, self.output_dim)).to(device)\n",
        "        self.modality_2_factor = Parameter(torch.Tensor(self.rank,1, self.modality_2 + 1, self.output_dim)).to(device)\n",
        "        self.modality_3_factor = Parameter(torch.Tensor(self.rank,1, self.modality_3 + 1, self.output_dim)).to(device)\n",
        "\n",
        "\n",
        "        self.fusion_weights = Parameter(torch.Tensor(1, self.rank)).to(device)\n",
        "        self.fusion_bias = Parameter(torch.Tensor(1, self.output_dim)).to(device)\n",
        "\n",
        "        init.xavier_normal_(self.modality_1_factor,self.rank)\n",
        "        init.xavier_normal_(self.modality_2_factor,self.rank)\n",
        "        init.xavier_normal_(self.modality_3_factor,self.rank)\n",
        "\n",
        "        init.xavier_normal_(self.fusion_weights)\n",
        "        self.fusion_bias.data.fill_(0)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x_vel, x_acc, x_2d):\n",
        "\n",
        "        batch_size = x_vel.shape[0]\n",
        "\n",
        "        data_type = torch.cuda.FloatTensor\n",
        "\n",
        "        # ones = torch.ones(batch_size, 50, 1, device=device)\n",
        "\n",
        "        # print(x_vel.shape)\n",
        "\n",
        "        x_vel = torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_vel), dim=2)\n",
        "        x_acc= torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_acc), dim=2)\n",
        "        x_2d = torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_2d), dim=2)\n",
        "\n",
        "\n",
        "        fusion_modality_1 = torch.matmul(x_vel, self.modality_1_factor)\n",
        "        fusion_modality_2 = torch.matmul(x_acc, self.modality_2_factor)\n",
        "        fusion_modality_3 = torch.matmul(x_2d, self.modality_3_factor)\n",
        "\n",
        "        output   = fusion_modality_1 * fusion_modality_2 * fusion_modality_3\n",
        "\n",
        "        # permute to make batch first\n",
        "        output = torch.matmul(self.fusion_weights, output .permute(1, 2, 0, 3)).squeeze(dim=2) + self.fusion_bias\n",
        "\n",
        "\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_MMF(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_MMF, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        # out_2, _ = self.lstm_2(out_1)\n",
        "        # out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_1\n"
      ],
      "metadata": {
        "id": "qtnZ1LIq46c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5afvJh-CaDnG"
      },
      "outputs": [],
      "source": [
        "class MM_lmf(nn.Module):\n",
        "    def __init__(self, input_vel, input_acc,input_2D, drop_prob=0.10):\n",
        "        super(MM_lmf, self).__init__()\n",
        "\n",
        "        self.encoder_vel=Encoder_MMF(input_vel, drop_prob)\n",
        "        self.encoder_acc=Encoder_MMF(input_acc, drop_prob)\n",
        "        self.encoder_2d=Encoder_MMF(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_vel= nn.BatchNorm1d(input_vel, affine=False)\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_2d= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(64, 5)\n",
        "        self.lmf=LMF(10,128,128,128,32)\n",
        "\n",
        "        self.fc1=nn.Linear(32,32)\n",
        "        self.fc2=nn.Linear(32,5)\n",
        "\n",
        "\n",
        "    def forward(self, x_vel, x_acc, x_2d):\n",
        "\n",
        "        x_vel_1=x_vel.view(x_vel.size(0)*x_vel.size(1),x_vel.size(-1))\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_2d_1=x_2d.view(x_2d.size(0)*x_2d.size(1),x_2d.size(-1))\n",
        "\n",
        "        x_vel_1=self.BN_vel(x_vel_1)\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_2d_1=self.BN_2d(x_2d_1)\n",
        "\n",
        "        x_vel_2=x_vel_1.view(-1, 50, x_vel_1.size(-1))\n",
        "        x_acc_2=x_acc_1.view(-1, 50, x_acc_1.size(-1))\n",
        "        x_2d_2=x_2d_1.view(-1, 50, x_2d_1.size(-1))\n",
        "\n",
        "        x_vel=self.encoder_vel(x_vel_2)\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_2d=self.encoder_2d(x_2d_2)\n",
        "\n",
        "        x=self.lmf(x_vel, x_acc,x_2d)\n",
        "\n",
        "        x=F.relu(self.fc1(x))\n",
        "        out=self.fc2(x)\n",
        "\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csTmV-hJaDnG",
        "outputId": "e5ff46c7-6133-4f75-c078-7390241f68ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 4.5254, Training Loss: 0.5042,  Validation loss: 0.3394\n",
            "Epoch: 2, time: 4.8717, Training Loss: 0.3322,  Validation loss: 0.2965\n",
            "Epoch: 3, time: 4.5197, Training Loss: 0.2988,  Validation loss: 0.2668\n",
            "Epoch: 4, time: 4.4644, Training Loss: 0.2806,  Validation loss: 0.2555\n",
            "Epoch: 5, time: 4.7504, Training Loss: 0.2689,  Validation loss: 0.2591\n",
            "Epoch: 6, time: 4.5099, Training Loss: 0.2602,  Validation loss: 0.2361\n",
            "Epoch: 7, time: 4.8811, Training Loss: 0.2518,  Validation loss: 0.2376\n",
            "Epoch: 8, time: 5.0567, Training Loss: 0.2482,  Validation loss: 0.2319\n",
            "Epoch: 9, time: 4.6725, Training Loss: 0.2425,  Validation loss: 0.2380\n",
            "Epoch: 10, time: 4.6390, Training Loss: 0.2384,  Validation loss: 0.2251\n",
            "Epoch: 11, time: 4.6874, Training Loss: 0.2336,  Validation loss: 0.2295\n",
            "Epoch: 12, time: 4.7124, Training Loss: 0.2299,  Validation loss: 0.2185\n",
            "Epoch: 13, time: 4.8841, Training Loss: 0.2267,  Validation loss: 0.2301\n",
            "Epoch: 14, time: 4.6441, Training Loss: 0.2242,  Validation loss: 0.2177\n",
            "Epoch: 15, time: 4.7765, Training Loss: 0.2224,  Validation loss: 0.2141\n",
            "Epoch: 16, time: 5.0267, Training Loss: 0.2187,  Validation loss: 0.2172\n",
            "Epoch: 17, time: 5.1684, Training Loss: 0.2160,  Validation loss: 0.2171\n",
            "Epoch: 18, time: 4.7195, Training Loss: 0.2143,  Validation loss: 0.2123\n",
            "Epoch: 19, time: 4.5236, Training Loss: 0.2133,  Validation loss: 0.2107\n",
            "Epoch: 20, time: 4.8038, Training Loss: 0.2111,  Validation loss: 0.2095\n",
            "Epoch: 21, time: 4.5693, Training Loss: 0.2087,  Validation loss: 0.2102\n",
            "Epoch: 22, time: 4.5212, Training Loss: 0.2069,  Validation loss: 0.2089\n",
            "Epoch: 23, time: 4.5405, Training Loss: 0.2059,  Validation loss: 0.2084\n",
            "Epoch: 24, time: 4.4832, Training Loss: 0.2044,  Validation loss: 0.2128\n",
            "Epoch: 25, time: 4.4958, Training Loss: 0.2019,  Validation loss: 0.2087\n",
            "Epoch: 26, time: 4.7196, Training Loss: 0.2011,  Validation loss: 0.2049\n",
            "Epoch: 27, time: 4.5537, Training Loss: 0.1996,  Validation loss: 0.2076\n",
            "Epoch: 28, time: 4.5745, Training Loss: 0.1983,  Validation loss: 0.2048\n",
            "Epoch: 29, time: 4.7259, Training Loss: 0.1973,  Validation loss: 0.2075\n",
            "Epoch: 30, time: 4.5085, Training Loss: 0.1963,  Validation loss: 0.2043\n",
            "Epoch: 31, time: 4.5551, Training Loss: 0.1950,  Validation loss: 0.2051\n",
            "Epoch: 32, time: 4.5809, Training Loss: 0.1935,  Validation loss: 0.2071\n",
            "Epoch: 33, time: 4.4357, Training Loss: 0.1920,  Validation loss: 0.2100\n",
            "Epoch: 34, time: 4.6727, Training Loss: 0.1914,  Validation loss: 0.2048\n",
            "Epoch: 35, time: 4.5666, Training Loss: 0.1909,  Validation loss: 0.2060\n",
            "Epoch: 36, time: 4.6387, Training Loss: 0.1903,  Validation loss: 0.2026\n",
            "Epoch: 37, time: 4.6792, Training Loss: 0.1886,  Validation loss: 0.2141\n",
            "Epoch: 38, time: 5.0885, Training Loss: 0.1873,  Validation loss: 0.2015\n",
            "Epoch: 39, time: 4.8851, Training Loss: 0.1871,  Validation loss: 0.2023\n",
            "Epoch: 40, time: 4.6832, Training Loss: 0.1864,  Validation loss: 0.2057\n",
            "Training time: 187.51496767997742 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_lmf(44,44,44)\n",
        "mm_lmf = train_mm_target_sota(train_loader, lr,40,model,path+ encoder+ '_lmf_IMU8_2D.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0cenDldaDnG",
        "outputId": "67a543a7-fc8a-49b1-f707-8d143fa8a373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "7.926440984010696\n",
            "4.468647018074989\n",
            "5.630387365818024\n",
            "4.560587182641029\n",
            "7.10790678858757\n",
            "\n",
            "\n",
            "0.8574322738127056\n",
            "0.9218040203986301\n",
            "0.9331588571124284\n",
            "0.989464089886316\n",
            "0.949509033844859\n",
            "Mean: 5.939 +/- 1.539\n",
            "Mean: 0.930 +/- 0.048\n"
          ]
        }
      ],
      "source": [
        "# mm_lmf= MM_lmf(44,44,44)\n",
        "# mm_lmf.load_state_dict(torch.load(path+encoder+'_lmf_IMU8_2D.pth'))\n",
        "# mm_lmf.to(device)\n",
        "\n",
        "mm_lmf.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output = mm_lmf(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_3=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMWrP25l8SXx"
      },
      "source": [
        "## 7. Tensor Fusion Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TFN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_modality_1, input_modality_2, input_modality_3):\n",
        "\n",
        "        super(TFN, self).__init__()\n",
        "\n",
        "        self.modality_1=input_modality_1\n",
        "        self.modality_2=input_modality_2\n",
        "        self.modality_3=input_modality_3\n",
        "\n",
        "\n",
        "    def forward(self, x_vel, x_acc, x_2d):\n",
        "\n",
        "        batch_size = x_vel.shape[0]\n",
        "\n",
        "        data_type = torch.cuda.FloatTensor\n",
        "\n",
        "        x_vel = torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_vel), dim=2)\n",
        "        x_acc= torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_acc), dim=2)\n",
        "        x_2d = torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_2d), dim=2)\n",
        "\n",
        "        x_vel=x_vel.view(-1,x_vel.size(-1))\n",
        "        x_acc=x_acc.view(-1,x_acc.size(-1))\n",
        "        x_2d=x_2d.view(-1,x_2d.size(-1))\n",
        "\n",
        "\n",
        "        fusion_tensor = torch.bmm(x_vel.unsqueeze(2), x_acc.unsqueeze(1))\n",
        "\n",
        "\n",
        "        fusion_tensor = fusion_tensor.view(-1, (self.modality_1 + 1) * (self.modality_2 + 1), 1)\n",
        "        fusion_tensor = torch.bmm(fusion_tensor, x_2d.unsqueeze(1)).view(batch_size, 50,-1)\n",
        "\n",
        "        return fusion_tensor\n"
      ],
      "metadata": {
        "id": "MvqTEy864l49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23UoQ9y28SXx"
      },
      "outputs": [],
      "source": [
        "class MM_tfn(nn.Module):\n",
        "    def __init__(self, input_vel, input_acc,input_2D, drop_prob=0.10):\n",
        "        super(MM_tfn, self).__init__()\n",
        "\n",
        "        self.encoder_vel=Encoder_MMF(input_vel, drop_prob)\n",
        "        self.encoder_acc=Encoder_MMF(input_acc, drop_prob)\n",
        "        self.encoder_2d=Encoder_MMF(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_vel= nn.BatchNorm1d(input_vel, affine=False)\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_2d= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(64, 5)\n",
        "        self.tfn=TFN(32,32,32)\n",
        "\n",
        "        # define the post_fusion layers\n",
        "        self.post_fusion_dropout = nn.Dropout(p=0.10)\n",
        "        self.post_fusion_layer_1 = nn.Linear((32 + 1)*(32 + 1)*(32+1) , 128)\n",
        "        self.post_fusion_layer_2 = nn.Linear(128, 128)\n",
        "        self.post_fusion_layer_3 = nn.Linear(128, 5)\n",
        "\n",
        "        self.l1 = nn.Linear(128,32)\n",
        "        self.l2 = nn.Linear(128,32)\n",
        "        self.l3 = nn.Linear(128,32)\n",
        "\n",
        "\n",
        "    def forward(self, x_vel, x_acc, x_2d):\n",
        "\n",
        "        x_vel_1=x_vel.view(x_vel.size(0)*x_vel.size(1),x_vel.size(-1))\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_2d_1=x_2d.view(x_2d.size(0)*x_2d.size(1),x_2d.size(-1))\n",
        "\n",
        "        x_vel_1=self.BN_vel(x_vel_1)\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_2d_1=self.BN_2d(x_2d_1)\n",
        "\n",
        "        x_vel_2=x_vel_1.view(-1, 50, x_vel_1.size(-1))\n",
        "        x_acc_2=x_acc_1.view(-1, 50, x_acc_1.size(-1))\n",
        "        x_2d_2=x_2d_1.view(-1, 50, x_2d_1.size(-1))\n",
        "\n",
        "\n",
        "        x_vel=self.encoder_vel(x_vel_2)\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_2d=self.encoder_2d(x_2d_2)\n",
        "\n",
        "        x_vel=self.l1(x_vel)\n",
        "        x_acc=self.l2(x_acc)\n",
        "        x_2d=self.l3(x_2d)\n",
        "\n",
        "\n",
        "        x=self.tfn(x_vel, x_acc,x_2d)\n",
        "\n",
        "        post_fusion_dropped = self.post_fusion_dropout(x)\n",
        "        post_fusion_y_1 = F.relu(self.post_fusion_layer_1(post_fusion_dropped))\n",
        "        post_fusion_y_2 = F.relu(self.post_fusion_layer_2(post_fusion_y_1))\n",
        "\n",
        "        out= self.post_fusion_layer_3(post_fusion_y_2)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4KeQ7LY8SXy",
        "outputId": "d9e6170c-534e-4a6f-cd8b-8ca5526a534f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 16.6876, Training Loss: 0.3959,  Validation loss: 0.2893\n",
            "Epoch: 2, time: 16.3280, Training Loss: 0.2867,  Validation loss: 0.2486\n",
            "Epoch: 3, time: 15.9888, Training Loss: 0.2611,  Validation loss: 0.2390\n",
            "Epoch: 4, time: 15.9269, Training Loss: 0.2430,  Validation loss: 0.2360\n",
            "Epoch: 5, time: 15.9586, Training Loss: 0.2307,  Validation loss: 0.2316\n",
            "Epoch: 6, time: 16.0782, Training Loss: 0.2239,  Validation loss: 0.2182\n",
            "Epoch: 7, time: 16.1339, Training Loss: 0.2127,  Validation loss: 0.2295\n",
            "Epoch: 8, time: 16.1121, Training Loss: 0.2064,  Validation loss: 0.2139\n",
            "Epoch: 9, time: 16.0218, Training Loss: 0.1993,  Validation loss: 0.2164\n",
            "Epoch: 10, time: 15.9996, Training Loss: 0.1940,  Validation loss: 0.2049\n",
            "Epoch: 11, time: 16.0488, Training Loss: 0.1876,  Validation loss: 0.2045\n",
            "Epoch: 12, time: 16.0606, Training Loss: 0.1832,  Validation loss: 0.2005\n",
            "Epoch: 13, time: 16.0532, Training Loss: 0.1778,  Validation loss: 0.2005\n",
            "Epoch: 14, time: 16.0488, Training Loss: 0.1750,  Validation loss: 0.2000\n",
            "Epoch: 15, time: 16.0499, Training Loss: 0.1684,  Validation loss: 0.2032\n",
            "Epoch: 16, time: 16.0189, Training Loss: 0.1641,  Validation loss: 0.1988\n",
            "Epoch: 17, time: 16.0281, Training Loss: 0.1619,  Validation loss: 0.2068\n",
            "Epoch: 18, time: 15.9989, Training Loss: 0.1594,  Validation loss: 0.1989\n",
            "Epoch: 19, time: 16.0044, Training Loss: 0.1534,  Validation loss: 0.2065\n",
            "Epoch: 20, time: 15.9887, Training Loss: 0.1506,  Validation loss: 0.2028\n",
            "Epoch: 21, time: 15.9699, Training Loss: 0.1484,  Validation loss: 0.2015\n",
            "Epoch: 22, time: 15.9706, Training Loss: 0.1458,  Validation loss: 0.1975\n",
            "Epoch: 23, time: 15.9925, Training Loss: 0.1412,  Validation loss: 0.1997\n",
            "Epoch: 24, time: 15.9755, Training Loss: 0.1393,  Validation loss: 0.1970\n",
            "Epoch: 25, time: 15.9764, Training Loss: 0.1383,  Validation loss: 0.1991\n",
            "Epoch: 26, time: 15.9786, Training Loss: 0.1362,  Validation loss: 0.2029\n",
            "Epoch: 27, time: 15.9690, Training Loss: 0.1327,  Validation loss: 0.1959\n",
            "Epoch: 28, time: 15.9836, Training Loss: 0.1323,  Validation loss: 0.1974\n",
            "Epoch: 29, time: 15.9787, Training Loss: 0.1298,  Validation loss: 0.1968\n",
            "Epoch: 30, time: 15.9878, Training Loss: 0.1282,  Validation loss: 0.1999\n",
            "Epoch: 31, time: 15.9991, Training Loss: 0.1247,  Validation loss: 0.1970\n",
            "Epoch: 32, time: 16.0113, Training Loss: 0.1244,  Validation loss: 0.2013\n",
            "Epoch: 33, time: 15.9898, Training Loss: 0.1226,  Validation loss: 0.1974\n",
            "Epoch: 34, time: 15.9950, Training Loss: 0.1212,  Validation loss: 0.1952\n",
            "Epoch: 35, time: 16.0042, Training Loss: 0.1215,  Validation loss: 0.1978\n",
            "Epoch: 36, time: 15.9939, Training Loss: 0.1190,  Validation loss: 0.1966\n",
            "Epoch: 37, time: 15.9824, Training Loss: 0.1182,  Validation loss: 0.1974\n",
            "Epoch: 38, time: 15.9935, Training Loss: 0.1163,  Validation loss: 0.1996\n",
            "Epoch: 39, time: 15.9773, Training Loss: 0.1164,  Validation loss: 0.1963\n",
            "Epoch: 40, time: 15.9799, Training Loss: 0.1150,  Validation loss: 0.1959\n",
            "Training time: 642.1244194507599 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_tfn(44,44,44)\n",
        "mm_tfn = train_mm_target_sota(train_loader, lr,40,model,path+ encoder+ '_tfn_IMU8_2D.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7noN01ql8SXy",
        "outputId": "e81181e4-9635-48e5-bcd5-813054355677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "9.424219280481339\n",
            "4.763882979750633\n",
            "4.74238321185112\n",
            "4.532795399427414\n",
            "6.25239685177803\n",
            "\n",
            "\n",
            "0.8330432193674382\n",
            "0.9096849246800512\n",
            "0.9512790432824981\n",
            "0.9900346303073282\n",
            "0.9562499377118076\n",
            "Mean: 5.943 +/- 2.064\n",
            "Mean: 0.928 +/- 0.060\n"
          ]
        }
      ],
      "source": [
        "mm_tfn= MM_tfn(44,44,44)\n",
        "mm_tfn.load_state_dict(torch.load(path+encoder+'_tfn_IMU8_2D.pth'))\n",
        "mm_tfn.to(device)\n",
        "\n",
        "mm_tfn.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output = mm_tfn(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_12=np.hstack([rmse,p])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TrXnoV0Js5CO",
        "3mq0s3oBqlJ5",
        "2HtJVDh1mEB-",
        "JU11NXkGUqCn",
        "Hue48X4BS6mG",
        "TbKi4_MDkS0W",
        "pdVcxRD4Y9cU",
        "fdptyv1jWklC",
        "nQZofbgO7cm-",
        "A3GSoset7cm_",
        "C7Ab-XOeT4fE",
        "7Gua9JczaDnG",
        "XMWrP25l8SXx"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
