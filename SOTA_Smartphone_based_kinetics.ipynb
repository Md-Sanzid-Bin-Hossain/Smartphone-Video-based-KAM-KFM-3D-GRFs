{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Md-Sanzid-Bin-Hossain/Smartphone-based-Kinetics-Estimation/blob/main/SOTA_Smartphone_based_kinetics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H__KTa0RNQDo"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy\n",
        "import statistics\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statistics import stdev\n",
        "import math\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from scipy.signal import butter,filtfilt\n",
        "import sys\n",
        "import numpy as np # linear algebra\n",
        "from scipy.stats import randint\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
        "import seaborn as sns # used for plot interactive graph.\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from tsf.model import TransformerForecaster\n",
        "\n",
        "\n",
        "# from tensorflow.keras.utils import np_utils\n",
        "import itertools\n",
        "###  Library for attention layers\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "#from tqdm import tqdm # Processing time measurement\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import statistics\n",
        "import gc\n",
        "import torch.nn.init as init\n",
        "\n",
        "############################################################################################################################################################################\n",
        "############################################################################################################################################################################\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.utils.weight_norm as weight_norm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrXnoV0Js5CO"
      },
      "source": [
        "# File path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mq0s3oBqlJ5"
      },
      "source": [
        "# Data loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_vel_acc(V):\n",
        "\n",
        "  velocity_all = []\n",
        "  acceleration_all = []\n",
        "\n",
        "  for i in range(44):\n",
        "      velocity, acceleration = calculate_velocity_acceleration(V[:,i])\n",
        "\n",
        "      velocity_all.append(velocity)\n",
        "      acceleration_all.append(velocity)\n",
        "\n",
        "  return np.transpose(velocity_all), np.transpose(acceleration_all)"
      ],
      "metadata": {
        "id": "mPsuuqPdbpi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def calculate_velocity_acceleration(position_data):\n",
        "#     n = len(position_data)\n",
        "\n",
        "#     # Calculate velocity\n",
        "#     velocity = []\n",
        "#     for i in range(n):\n",
        "#         if i == 0:\n",
        "#             vel = 0.0  # Set initial velocity as 0\n",
        "#         else:\n",
        "#             displacement = position_data[i] - position_data[i-1]\n",
        "#             time_interval = 0.01  # Assuming time intervals are uniform (e.g., 1 second)\n",
        "#             vel = displacement / time_interval\n",
        "#         velocity.append(vel)\n",
        "\n",
        "#     # Calculate acceleration\n",
        "#     acceleration = []\n",
        "#     for i in range(n):\n",
        "#         if i < 2 or i > n-2:\n",
        "#             accel = 0.0  # Set acceleration as 0 for the first and last points\n",
        "#         else:\n",
        "#             velocity_change = velocity[i] - velocity[i-1]\n",
        "#             accel = velocity_change / time_interval\n",
        "#         acceleration.append(accel)\n",
        "\n",
        "#     return np.array(velocity), np.array(acceleration)"
      ],
      "metadata": {
        "id": "KkNmHLQPTgup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_velocity_acceleration(position_data):\n",
        "    n = len(position_data)\n",
        "\n",
        "    # Calculate velocity\n",
        "    velocity = []\n",
        "    for i in range(n):\n",
        "        if i == 0:\n",
        "            vel = 0.0  # Set initial velocity as 0\n",
        "        else:\n",
        "            displacement = position_data[i] - position_data[i-1]\n",
        "            time_interval = 0.01  # Assuming time intervals are uniform (e.g., 1 second)\n",
        "            vel = displacement / time_interval\n",
        "        velocity.append(vel)\n",
        "\n",
        "    # Calculate acceleration\n",
        "    acceleration = []\n",
        "    for i in range(n):\n",
        "        if i ==0:\n",
        "            accel = 0.0  # Set acceleration as 0 for the first and last points\n",
        "        else:\n",
        "            velocity_change = velocity[i] - velocity[i-1]\n",
        "            accel = velocity_change / time_interval\n",
        "        acceleration.append(accel)\n",
        "\n",
        "    return np.array(velocity), np.array(acceleration)"
      ],
      "metadata": {
        "id": "AUDuqhYA44ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP90JbQoR23t"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    with h5py.File('/content/drive/My Drive/public dataset/all_17_subjects.h5', 'r') as hf:\n",
        "        data_all_sub = {subject: subject_data[:] for subject, subject_data in hf.items()}\n",
        "        data_fields = json.loads(hf.attrs['columns'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1Rygjvcmq90"
      },
      "outputs": [],
      "source": [
        "def data_extraction(A):\n",
        "  for k in range(len(A)):\n",
        "    zero_index_1=np.all(A[k:k+1,:,:] == 0, axis=0)\n",
        "    zero_index = np.multiply(zero_index_1, 1)\n",
        "    zero_index=np.array(zero_index)\n",
        "\n",
        "    for i in range(len(zero_index)):\n",
        "      if (sum(zero_index[i])==256):\n",
        "        index=i\n",
        "        break;\n",
        "\n",
        "    # print(index)\n",
        "### Taking only the stance phase of the gait\n",
        "###################################################################################################################################################\n",
        "    B=A[k:k+1,0:index,:]  ### Taking only the stance phase of the gait\n",
        "    C_1=B.reshape((B.shape[0]*B.shape[1],B.shape[2]))\n",
        "    if (k==0):\n",
        "      C=C_1\n",
        "    else:\n",
        "      C=np.append(C,C_1,axis=0)\n",
        "\n",
        "  index_24 = data_fields.index('body weight')\n",
        "  index_25 = data_fields.index('body height')\n",
        "\n",
        "  BW=(C[0:1, index_24]*9.8)\n",
        "  BWH=(C[0:1, index_24]*9.8)*C[:, index_25]\n",
        "\n",
        "  V=C[:,110:154]\n",
        "  V=V.reshape(V.shape[0],11,4)\n",
        "\n",
        "  V=(V-V[:,2:3,:])\n",
        "\n",
        "  V=V.reshape(-1,44)\n",
        "\n",
        "  velocity_all, acceleration_all = extract_vel_acc(V)\n",
        "\n",
        "  V=V/C[0:1, index_25]\n",
        "\n",
        "\n",
        "      ### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "    ### 0:48- IMU, 48:92-2D body coordinate, 92:136 -2D velocity, 136:180 -2D acceleration, 180:185-- Target\n",
        "\n",
        "  D=np.hstack((C[:,71:77],C[:,58:64],C[:,19:25],C[:,32:38],C[:,45:51],C[:,6:12],C[:,84:90],C[:,97:103],V,velocity_all, acceleration_all, C[:,3:5],-C[:, 154:155]/BW,\n",
        "              -C[:, 156:157]/BW,-C[:, 155:156]/BW))\n",
        "\n",
        "\n",
        "\n",
        "  return D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_subject_01 = data_all_sub['subject_01']\n",
        "subject_1=data_extraction(data_subject_01)\n",
        "\n",
        "print(subject_1.shape)"
      ],
      "metadata": {
        "id": "xoVth3PxeCEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d7CRzCoShWB"
      },
      "outputs": [],
      "source": [
        "  # index_21 = data_fields.index('plate_2_force_x')\n",
        "  # print(index_21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6sRqaUhw2S7"
      },
      "outputs": [],
      "source": [
        "# print(np.array(data_fields))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwo6ALnFONNS"
      },
      "outputs": [],
      "source": [
        "data_subject_01 = data_all_sub['subject_01']\n",
        "data_subject_02 = data_all_sub['subject_02']\n",
        "data_subject_03 = data_all_sub['subject_03']\n",
        "data_subject_04 = data_all_sub['subject_04']\n",
        "data_subject_05 = data_all_sub['subject_05']\n",
        "data_subject_06 = data_all_sub['subject_06']\n",
        "data_subject_07 = data_all_sub['subject_07']\n",
        "data_subject_08 = data_all_sub['subject_08']\n",
        "data_subject_09 = data_all_sub['subject_09']\n",
        "data_subject_10 = data_all_sub['subject_10']\n",
        "data_subject_11 = data_all_sub['subject_11']\n",
        "data_subject_12 = data_all_sub['subject_12']\n",
        "data_subject_13 = data_all_sub['subject_13']\n",
        "data_subject_14 = data_all_sub['subject_14']\n",
        "data_subject_15 = data_all_sub['subject_15']\n",
        "data_subject_16 = data_all_sub['subject_16']\n",
        "data_subject_17 = data_all_sub['subject_17']\n",
        "\n",
        "\n",
        "subject_1=data_extraction(data_subject_01)\n",
        "subject_2=data_extraction(data_subject_02)\n",
        "subject_3=data_extraction(data_subject_03)\n",
        "subject_4=data_extraction(data_subject_04)\n",
        "subject_5=data_extraction(data_subject_05)\n",
        "subject_6=data_extraction(data_subject_06)\n",
        "subject_7=data_extraction(data_subject_07)\n",
        "subject_8=data_extraction(data_subject_08)\n",
        "subject_9=data_extraction(data_subject_09)\n",
        "subject_10=data_extraction(data_subject_10)\n",
        "subject_11=data_extraction(data_subject_11)\n",
        "subject_12=data_extraction(data_subject_12)\n",
        "subject_13=data_extraction(data_subject_13)\n",
        "subject_14=data_extraction(data_subject_14)\n",
        "subject_15=data_extraction(data_subject_15)\n",
        "subject_16=data_extraction(data_subject_16)\n",
        "subject_17=data_extraction(data_subject_17)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
        "\n",
        "adjacency_matrix=torch.from_numpy(adjacency_matrix.astype(np.float32))\n",
        "\n",
        "\n",
        "def graph_based_augmentation(joints, adjacency_matrix, max_rotation, max_translation):\n",
        "    num_joints = joints.shape[0]\n",
        "\n",
        "    # Apply random rotations\n",
        "    theta = torch.randn(num_joints, 1) * (max_rotation * np.pi / 180)  # Convert to radians\n",
        "    cos_theta = torch.cos(theta)\n",
        "    sin_theta = torch.sin(theta)\n",
        "\n",
        "    rotated_joints = torch.zeros_like(joints)\n",
        "    for i in range(num_joints):\n",
        "        neighbors = torch.nonzero(adjacency_matrix[i]).squeeze(1)\n",
        "        rotated_joints[i] = cos_theta[i] * joints[i] + torch.sum(sin_theta[i] * joints[neighbors], dim=0)\n",
        "\n",
        "    # Apply random translations\n",
        "    translation = torch.randn(2) * max_translation\n",
        "\n",
        "    augmented_joints = rotated_joints + translation\n",
        "\n",
        "    return augmented_joints\n",
        "\n",
        "\n",
        "def augmentation_all(V):\n",
        "\n",
        "    joints=V\n",
        "    augmented_joints_all=[]\n",
        "\n",
        "    for i in range(len(joints)):\n",
        "\n",
        "      joint_1=joints[i,:,0:2].squeeze(0)\n",
        "      augmented_joints_1 = graph_based_augmentation(joint_1, adjacency_matrix, max_rotation=2.0, max_translation=1.0)\n",
        "\n",
        "      joint_2=joints[i,:,2:4].squeeze(0)\n",
        "      augmented_joints_2 = graph_based_augmentation(joint_2, adjacency_matrix, max_rotation=2.0, max_translation=1.0)\n",
        "\n",
        "      augmented_joints_1=augmented_joints_1.unsqueeze(0)\n",
        "      augmented_joints_2=augmented_joints_2.unsqueeze(0)\n",
        "\n",
        "      augmented_joints=torch.cat((augmented_joints_1,augmented_joints_2),dim=-1)\n",
        "      augmented_joints_all.append(augmented_joints)\n",
        "\n",
        "    augmented_joints_all = torch.stack(augmented_joints_all, dim=0)\n",
        "    augmented_joints_all=augmented_joints_all.unsqueeze(1)\n",
        "\n",
        "    return augmented_joints_all\n",
        "\n"
      ],
      "metadata": {
        "id": "AxiJ4dX0cvzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_extraction_aug(A):\n",
        "  for k in range(len(A)):\n",
        "    zero_index_1=np.all(A[k:k+1,:,:] == 0, axis=0)\n",
        "    zero_index = np.multiply(zero_index_1, 1)\n",
        "    zero_index=np.array(zero_index)\n",
        "\n",
        "    for i in range(len(zero_index)):\n",
        "      if (sum(zero_index[i])==256):\n",
        "        index=i\n",
        "        break;\n",
        "\n",
        "    # print(index)\n",
        "### Ta2Dg only the stance phase of the gait\n",
        "###################################################################################################################################################\n",
        "    B=A[k:k+1,0:index,:]  ### Ta2Dg only the stance phase of the gait\n",
        "    C_1=B.reshape((B.shape[0]*B.shape[1],B.shape[2]))\n",
        "    if (k==0):\n",
        "      C=C_1\n",
        "    else:\n",
        "      C=np.append(C,C_1,axis=0)\n",
        "\n",
        "  index_24 = data_fields.index('body weight')\n",
        "  index_25 = data_fields.index('body height')\n",
        "\n",
        "  BW=(C[0:1, index_24]*9.8)\n",
        "  BWH=(C[0:1, index_24]*9.8)*C[:, index_25]\n",
        "\n",
        "  V=C[:,110:154]\n",
        "  V=V.reshape(V.shape[0],11,4)\n",
        "\n",
        "  V=(V-V[:,2:3,:])\n",
        "\n",
        "  V=augmentation_all(torch.from_numpy(V))\n",
        "  V=V.reshape(-1,44)\n",
        "  velocity_all, acceleration_all = extract_vel_acc(V)\n",
        "\n",
        "  V=V/C[0:1, index_25]\n",
        "\n",
        "\n",
        "      ### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "    ### 0:48- IMU, 48:92-2D body coordinate, 92:136 -2D velocity, 136:180 -2D acceleration, 180:185-- Target\n",
        "\n",
        "  D=np.hstack((C[:,71:77],C[:,58:64],C[:,19:25],C[:,32:38],C[:,45:51],C[:,6:12],C[:,84:90],C[:,97:103],V,velocity_all, acceleration_all, C[:,3:5],-C[:, 154:155]/BW,\n",
        "              -C[:, 156:157]/BW,-C[:, 155:156]/BW))\n",
        "\n",
        "  return D\n"
      ],
      "metadata": {
        "id": "Hk2t1FW-dwMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZIw9tIU2Q7H"
      },
      "outputs": [],
      "source": [
        "# data_subject_01 = data_all_sub['subject_01']\n",
        "# subject_1_aug=data_extraction_aug(data_subject_01)\n",
        "\n",
        "# print(subject_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_subject_01 = data_all_sub['subject_01']\n",
        "# data_subject_02 = data_all_sub['subject_02']\n",
        "# data_subject_03 = data_all_sub['subject_03']\n",
        "# data_subject_04 = data_all_sub['subject_04']\n",
        "# data_subject_05 = data_all_sub['subject_05']\n",
        "# data_subject_06 = data_all_sub['subject_06']\n",
        "# data_subject_07 = data_all_sub['subject_07']\n",
        "# data_subject_08 = data_all_sub['subject_08']\n",
        "# data_subject_09 = data_all_sub['subject_09']\n",
        "# data_subject_10 = data_all_sub['subject_10']\n",
        "# data_subject_11 = data_all_sub['subject_11']\n",
        "# data_subject_12 = data_all_sub['subject_12']\n",
        "# data_subject_13 = data_all_sub['subject_13']\n",
        "# data_subject_14 = data_all_sub['subject_14']\n",
        "# data_subject_15 = data_all_sub['subject_15']\n",
        "# data_subject_16 = data_all_sub['subject_16']\n",
        "# data_subject_17 = data_all_sub['subject_17']\n",
        "\n",
        "\n",
        "# subject_1_aug=data_extraction(data_subject_01)\n",
        "# subject_2_aug=data_extraction(data_subject_02)\n",
        "# subject_3_aug=data_extraction(data_subject_03)\n",
        "# subject_4_aug=data_extraction(data_subject_04)\n",
        "# subject_5_aug=data_extraction(data_subject_05)\n",
        "# subject_6_aug=data_extraction(data_subject_06)\n",
        "# subject_7_aug=data_extraction(data_subject_07)\n",
        "# subject_8_aug=data_extraction(data_subject_08)\n",
        "# subject_9_aug=data_extraction(data_subject_09)\n",
        "# subject_10_aug=data_extraction(data_subject_10)\n",
        "# subject_11_aug=data_extraction(data_subject_11)\n",
        "# subject_12_aug=data_extraction(data_subject_12)\n",
        "# subject_13_aug=data_extraction(data_subject_13)\n",
        "# subject_14_aug=data_extraction(data_subject_14)\n",
        "# subject_15_aug=data_extraction(data_subject_15)\n",
        "# subject_16_aug=data_extraction(data_subject_16)\n",
        "# subject_17_aug=data_extraction(data_subject_17)"
      ],
      "metadata": {
        "id": "T74y5iizeTsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsCxXC1B-JXc"
      },
      "outputs": [],
      "source": [
        "subject_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9iGjQ6uXU-"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fTO4veYsyC7"
      },
      "outputs": [],
      "source": [
        "main_dir = \"/content/drive/My Drive/public dataset/Public_dataset_2/Subject01\"\n",
        "# os.mkdir(main_dir)\n",
        "path=\"/content/\"\n",
        "subject='Subject_01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvt8kQG5iLMP"
      },
      "outputs": [],
      "source": [
        "train_dataset=np.concatenate((subject_1,subject_2,subject_3,subject_4,subject_5,subject_6,subject_7,subject_8,subject_9,subject_10,subject_11,\n",
        "                              subject_12,subject_14,subject_15,subject_16,subject_17),axis=0)\n",
        "\n",
        "test_dataset=subject_13\n",
        "\n",
        "encoder='LSTM'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7U-luFUh3gy"
      },
      "outputs": [],
      "source": [
        "# Train features #\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# x_train_1=train_dataset[:,0:18]\n",
        "# x_train_2=train_dataset[:,23:67]\n",
        "\n",
        "# x_train=np.concatenate((x_train_1,x_train_2),axis=1)\n",
        "\n",
        "x_train=train_dataset[:,0:180]\n",
        "\n",
        "\n",
        "scale= StandardScaler()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_X_1_1=x_train\n",
        "\n",
        "# # Test features #\n",
        "# x_test_1=test_dataset[:,0:18]\n",
        "# x_test_2=test_dataset[:,23:67]\n",
        "\n",
        "# x_test=np.concatenate((x_test_1,x_test_2),axis=1)\n",
        "\n",
        "x_test=test_dataset[:,0:180]\n",
        "\n",
        "test_X_1_1=x_test\n",
        "\n",
        "m1=180\n",
        "m2=185\n",
        "\n",
        "\n",
        "  ### Label ###\n",
        "\n",
        "train_y_1_1=train_dataset[:,m1:m2]\n",
        "test_y_1_1=test_dataset[:,m1:m2]\n",
        "\n",
        "train_dataset_1=np.concatenate((train_X_1_1,train_y_1_1),axis=1)\n",
        "test_dataset_1=np.concatenate((test_X_1_1,test_y_1_1),axis=1)\n",
        "\n",
        "train_dataset_1=pd.DataFrame(train_dataset_1)\n",
        "test_dataset_1=pd.DataFrame(test_dataset_1)\n",
        "\n",
        "train_dataset_1.dropna(axis=0,inplace=True)\n",
        "test_dataset_1.dropna(axis=0,inplace=True)\n",
        "\n",
        "train_dataset_1=np.array(train_dataset_1)\n",
        "test_dataset_1=np.array(test_dataset_1)\n",
        "\n",
        "train_dataset_sum = np. sum(train_dataset_1)\n",
        "array_has_nan = np. isinf(train_dataset_1[:,48:180])\n",
        "\n",
        "print(array_has_nan)\n",
        "\n",
        "print(train_dataset_1.shape)\n",
        "\n",
        "\n",
        "\n",
        "train_X_1=train_dataset_1[:,0:m1]\n",
        "test_X_1=test_dataset_1[:,0:m1]\n",
        "\n",
        "train_y_1=train_dataset_1[:,m1:m2]\n",
        "test_y_1=test_dataset_1[:,m1:m2]\n",
        "\n",
        "\n",
        "\n",
        "L1=len(train_X_1)\n",
        "L2=len(test_X_1)\n",
        "\n",
        "\n",
        "w=50\n",
        "\n",
        "\n",
        "\n",
        "a1=L1//w\n",
        "b1=L1%w\n",
        "\n",
        "a2=L2//w\n",
        "b2=L2%w\n",
        "\n",
        "# a3=L3//w\n",
        "# b3=L3%w\n",
        "\n",
        "     #### Features ####\n",
        "train_X_2=train_X_1[L1-w+b1:L1,:]\n",
        "test_X_2=test_X_1[L2-w+b2:L2,:]\n",
        "# validation_X_2=validation_X_1[L3-w+b3:L3,:]\n",
        "\n",
        "\n",
        "    #### Output ####\n",
        "\n",
        "train_y_2=train_y_1[L1-w+b1:L1,:]\n",
        "test_y_2=test_y_1[L2-w+b2:L2,:]\n",
        "# validation_y_2=validation_y_1[L3-w+b3:L3,:]\n",
        "\n",
        "\n",
        "\n",
        "     #### Features ####\n",
        "\n",
        "train_X=np.concatenate((train_X_1,train_X_2),axis=0)\n",
        "test_X=np.concatenate((test_X_1,test_X_2),axis=0)\n",
        "# validation_X=np.concatenate((validation_X_1,validation_X_2),axis=0)\n",
        "\n",
        "\n",
        "    #### Output ####\n",
        "\n",
        "train_y=np.concatenate((train_y_1,train_y_2),axis=0)\n",
        "test_y=np.concatenate((test_y_1,test_y_2),axis=0)\n",
        "# validation_y=np.concatenate((validation_y_1,validation_y_2),axis=0)\n",
        "\n",
        "\n",
        "print(train_y.shape)\n",
        "    #### Reshaping ####\n",
        "train_X_3_p= train_X.reshape((a1+1,w,train_X.shape[1]))\n",
        "test_X = test_X.reshape((a2+1,w,test_X.shape[1]))\n",
        "\n",
        "\n",
        "train_y_3_p= train_y.reshape((a1+1,w,5))\n",
        "test_y= test_y.reshape((a2+1,w,5))\n",
        "\n",
        "\n",
        "\n",
        "# train_X_1D=train_X_3\n",
        "test_X_1D=test_X\n",
        "\n",
        "train_X_3=train_X_3_p\n",
        "train_y_3=train_y_3_p\n",
        "# print(train_X_4.shape,train_y_3.shape)\n",
        "\n",
        "\n",
        "train_X_1D, X_validation_1D, train_y_5, Y_validation = train_test_split(train_X_3,train_y_3, test_size=0.20, random_state=True)\n",
        "#train_X_1D, X_validation_1D_ridge, train_y, Y_validation_ridge = train_test_split(train_X_1D_m,train_y_m, test_size=0.10, random_state=True)   [0:2668,:,:]\n",
        "\n",
        "print(train_X_1D.shape,train_y_5.shape,X_validation_1D.shape,Y_validation.shape)\n",
        "\n",
        "\n",
        "s=test_X_1D.shape[0]*w\n",
        "\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_y[0:10,:,0].reshape(500,1))"
      ],
      "metadata": {
        "id": "ZEq-YZ1CDN_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4C97S-PeeXd"
      },
      "outputs": [],
      "source": [
        "# from numpy import savetxt\n",
        "# savetxt('train_data_check.csv', train_dataset_1[:,48:92], delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjRHNe1ckRoy"
      },
      "outputs": [],
      "source": [
        "### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "### 0:48- IMU, 48:92-2D body coordinate, 92:97-- Target\n",
        "\n",
        "\n",
        "### Data Processing\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "val_targets = torch.Tensor(Y_validation)\n",
        "test_features = torch.Tensor(test_X_1D)\n",
        "test_targets = torch.Tensor(test_y)\n",
        "\n",
        "\n",
        "## all Modality Features\n",
        "\n",
        "train_features = torch.Tensor(train_X_1D)\n",
        "train_targets = torch.Tensor(train_y_5)\n",
        "val_features = torch.Tensor(X_validation_1D)\n",
        "\n",
        "\n",
        "train_features_acc_8=torch.cat((train_features[:,:,0:3],train_features[:,:,6:9],train_features[:,:,12:15],train_features[:,:,18:21],train_features[:,:,24:27]\\\n",
        "                             ,train_features[:,:,30:33],train_features[:,:,36:39],train_features[:,:,42:45]),axis=-1)\n",
        "test_features_acc_8=torch.cat((test_features[:,:,0:3],test_features[:,:,6:9],test_features[:,:,12:15],test_features[:,:,18:21],test_features[:,:,24:27]\\\n",
        "                             ,test_features[:,:,30:33],test_features[:,:,36:39],test_features[:,:,42:45]),axis=-1)\n",
        "val_features_acc_8=torch.cat((val_features[:,:,0:3],val_features[:,:,6:9],val_features[:,:,12:15],val_features[:,:,18:21],val_features[:,:,24:27]\\\n",
        "                             ,val_features[:,:,30:33],val_features[:,:,36:39],val_features[:,:,42:45]),axis=-1)\n",
        "\n",
        "\n",
        "train_features_gyr_8=torch.cat((train_features[:,:,3:6],train_features[:,:,9:12],train_features[:,:,15:18],train_features[:,:,21:24],train_features[:,:,27:30]\\\n",
        "                             ,train_features[:,:,33:36],train_features[:,:,39:42],train_features[:,:,45:48]),axis=-1)\n",
        "test_features_gyr_8=torch.cat((test_features[:,:,3:6],test_features[:,:,9:12],test_features[:,:,15:18],test_features[:,:,21:24],test_features[:,:,27:30]\\\n",
        "                             ,test_features[:,:,33:36],test_features[:,:,39:42],test_features[:,:,45:48]),axis=-1)\n",
        "val_features_gyr_8=torch.cat((val_features[:,:,3:6],val_features[:,:,9:12],val_features[:,:,15:18],val_features[:,:,21:24],val_features[:,:,27:30]\\\n",
        "                             ,val_features[:,:,33:36],val_features[:,:,39:42],val_features[:,:,45:48]),axis=-1)\n",
        "\n",
        "\n",
        "train_features_2D_point=train_features[:,:,48:92]\n",
        "test_features_2D_point=test_features[:,:,48:92]\n",
        "val_features_2D_point=val_features[:,:,48:92]\n",
        "\n",
        "print(train_features_2D_point.shape)\n",
        "\n",
        "sequence = [0, 2, 1, 3]\n",
        "\n",
        "train_features_2D_point_2D_1=train_features_2D_point.view(train_features_2D_point.shape[0],train_features_2D_point.shape[1],11,4)[:,:,:,sequence]\n",
        "test_features_2D_point_2D_1=test_features_2D_point.view(test_features_2D_point.shape[0],test_features_2D_point.shape[1],11,4)[:,:,:,sequence]\n",
        "val_features_2D_point_2D_1=val_features_2D_point.view(val_features_2D_point.shape[0],val_features_2D_point.shape[1],11,4)[:,:,:,sequence]\n",
        "\n",
        "\n",
        "train_features_2D_point_2D=train_features_2D_point_2D_1.reshape(train_features_2D_point.shape[0],train_features_2D_point.shape[1],22,2)\n",
        "test_features_2D_point_2D=test_features_2D_point_2D_1.reshape(test_features_2D_point.shape[0],test_features_2D_point.shape[1],22,2)\n",
        "val_features_2D_point_2D=val_features_2D_point_2D_1.reshape(val_features_2D_point.shape[0],val_features_2D_point.shape[1],22,2)\n",
        "\n",
        "\n",
        "\n",
        "print(train_features_2D_point_2D.shape)\n",
        "\n",
        "\n",
        "train_features_2D_velocity=train_features[:,:,92:136]\n",
        "test_features_2D_velocity=test_features[:,:,92:136]\n",
        "val_features_2D_velocity=val_features[:,:,92:136]\n",
        "\n",
        "\n",
        "train_features_2D_acceleration=train_features[:,:,136:180]\n",
        "test_features_2D_acceleration=test_features[:,:,136:180]\n",
        "val_features_2D_acceleration=val_features[:,:,136:180]\n",
        "\n",
        "\n",
        "train = TensorDataset(train_features, train_features_acc_8,train_features_gyr_8, train_features_2D_point,train_features_2D_point_2D,train_features_2D_velocity,train_features_2D_acceleration, train_targets)\n",
        "val = TensorDataset(val_features, val_features_acc_8, val_features_gyr_8, val_features_2D_point,val_features_2D_point_2D, val_features_2D_velocity, val_features_2D_acceleration, val_targets)\n",
        "test = TensorDataset(test_features, test_features_acc_8, test_features_gyr_8, test_features_2D_point, test_features_2D_point_2D, test_features_2D_velocity,test_features_2D_acceleration, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP_eDnJwrKCC"
      },
      "source": [
        "# Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdVunLKprSkv"
      },
      "outputs": [],
      "source": [
        "def RMSE_prediction(yhat_4,test_y,s):\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,5))\n",
        "  yhat=yhat_4.reshape((s1,5))\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  y_4=y_4_no\n",
        "  y_5=y_5_no\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "\n",
        "\n",
        "\n",
        "  Z_1=y_1\n",
        "  Z_2=y_2\n",
        "  Z_3=y_3\n",
        "  Z_4=y_4\n",
        "  Z_5=y_5\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "\n",
        "  return rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "def PCC_prediction(yhat_4,test_y,s):\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,5))\n",
        "  yhat=yhat_4.reshape((s1,5))\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  y_4=y_4_no\n",
        "  y_5=y_5_no\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "\n",
        "\n",
        "\n",
        "  Y_1=y_1\n",
        "  Y_2=y_2\n",
        "  Y_3=y_3\n",
        "  Y_4=y_4\n",
        "  Y_5=y_5\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "  return rmse, p, Y_1,Y_2,Y_3,Y_4,Y_5\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "# def estimate_coef(x, y):\n",
        "#     # number of observations/points\n",
        "#     n = np.size(x)\n",
        "\n",
        "#     # mean of x and y vector\n",
        "#     m_x = np.mean(x)\n",
        "#     m_y = np.mean(y)\n",
        "\n",
        "#     # calculating cross-deviation and deviation about x\n",
        "#     SS_xy = np.sum(y*x) - n*m_y*m_x\n",
        "#     SS_xx = np.sum(x*x) - n*m_x*m_x\n",
        "\n",
        "#     # calculating regression coefficients\n",
        "#     b_1 = SS_xy / SS_xx\n",
        "#     b_0 = m_y - b_1*m_x\n",
        "\n",
        "#     return (b_0, b_1)\n",
        "\n",
        "def estimate_coef(x, y):\n",
        "    # Convert input data to PyTorch tensors\n",
        "    x_tensor = torch.tensor(x, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    # Calculate the number of observations/points\n",
        "    n = x_tensor.size(0)\n",
        "\n",
        "    # Calculate the mean of x and y tensors\n",
        "    m_x = torch.mean(x_tensor)\n",
        "    m_y = torch.mean(y_tensor)\n",
        "\n",
        "    # Calculate cross-deviation and deviation about x\n",
        "    SS_xy = torch.sum(y_tensor * x_tensor) - n * m_y * m_x\n",
        "    SS_xx = torch.sum(x_tensor * x_tensor) - n * m_x * m_x\n",
        "\n",
        "    # Calculate regression coefficients\n",
        "    b_1 = SS_xy / SS_xx\n",
        "    b_0 = m_y - b_1 * m_x\n",
        "\n",
        "    return (b_0.item(), b_1.item())\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "### Test dataset has to be without shuffle for this function to work properly\n",
        "\n",
        "\n",
        "def DLR_prediction(yhat_4,test_y,s,Y_1,Y_2,Y_3,Y_4,Y_5,Z_1,Z_2,Z_3,Z_4,Z_5):\n",
        "\n",
        "  a_1,b_1=estimate_coef(Y_1,Z_1)\n",
        "  a_2,b_2=estimate_coef(Y_2,Z_2)\n",
        "  a_3,b_3=estimate_coef(Y_3,Z_3)\n",
        "  a_4,b_4=estimate_coef(Y_4,Z_4)\n",
        "  a_5,b_5=estimate_coef(Y_5,Z_5)\n",
        "\n",
        "  # print(a_1,b_1)\n",
        "  # print(a_2,b_2)\n",
        "  # print(a_3,b_3)\n",
        "  # print(a_4,b_4)\n",
        "  # print(a_5,b_5)\n",
        "\n",
        "\n",
        "  #### All 16 angles prediction  ####\n",
        "\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,5))\n",
        "  yhat=yhat_4.reshape((s1,5))\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  y_4=y_4_no\n",
        "  y_5=y_5_no\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "\n",
        "\n",
        "  y_1=y_1*b_1+a_1\n",
        "  y_2=y_2*b_2+a_2\n",
        "  y_3=y_3*b_3+a_3\n",
        "  y_4=y_4*b_4+a_4\n",
        "  y_5=y_5*b_5+a_5\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "\n",
        "\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "  return rmse, p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5Q-cJ2tK8Vb"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        mse = nn.MSELoss()(pred, target)\n",
        "        rmse = torch.sqrt(mse)\n",
        "        return rmse\n"
      ],
      "metadata": {
        "id": "wVzTJJzbjfn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HtJVDh1mEB-"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCrgBUvih7OD"
      },
      "outputs": [],
      "source": [
        "def train_2D_early(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_2D_early_2D(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_2D_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data_2D_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "5TDgV29Xjuy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOTA_Models"
      ],
      "metadata": {
        "id": "JU11NXkGUqCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. FFN"
      ],
      "metadata": {
        "id": "Hue48X4BS6mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, input_1D):\n",
        "        super(FFN, self).__init__()\n",
        "\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "\n",
        "        self.fc1 = nn.Linear(input_1D, 512)\n",
        "        self.dropout1 = nn.Dropout(0.05)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.dropout2 = nn.Dropout(0.05)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.dropout3 = nn.Dropout(0.05)\n",
        "\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "        self.fc_f=nn.Linear(128*50, 5*50)\n",
        "\n",
        "\n",
        "    def forward(self, inputs_1D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        x = F.relu(self.fc1(inputs_1D_N))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x=self.flatten(x)\n",
        "\n",
        "        x = self.fc_f(x).view(-1,50,5)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "l8ioaOg6TC0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = FFN(44)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "num_params = count_parameters(model)\n",
        "print(\"Number of parameters:\", num_params)\n",
        "\n",
        "mm_early_ffn = train_2D_early(train_loader, lr,40,model,path + encoder + '_ffn_video.pth')"
      ],
      "metadata": {
        "id": "chPlaJFSTQ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early_ffn= FFN(44)\n",
        "mm_early_ffn.load_state_dict(torch.load(path+encoder+'_ffn_video.pth'))\n",
        "mm_early_ffn.to(device)\n",
        "\n",
        "mm_early_ffn.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early_ffn(data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_1=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "SJIPae1rTQ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Bi-LSTM"
      ],
      "metadata": {
        "id": "TbKi4_MDkS0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 512, bidirectional=False, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(512, 256, bidirectional=False, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout(out_2)\n",
        "        out_2=self.flatten(out_2)\n",
        "\n",
        "\n",
        "        return out_2"
      ],
      "metadata": {
        "id": "n78guVL0kS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MM_early(nn.Module):\n",
        "\n",
        "    def __init__(self, input, drop_prob=0.35):\n",
        "        super(MM_early, self).__init__()\n",
        "        self.encoder_input=Encoder(input,drop_prob)\n",
        "        self.fc=nn.Linear(256*50, 5*50)\n",
        "        self.BN= nn.BatchNorm1d(input, affine=False)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "\n",
        "        input_x_1=input_x.view(input_x.size(0)*input_x.size(1),input_x.size(-1))\n",
        "        input_x_1=self.BN(input_x_1)\n",
        "        input_x_2=input_x_1.view(-1, 50, input_x_1.size(-1))\n",
        "        out=self.encoder_input(input_x_2)\n",
        "\n",
        "        out = self.fc(out).view(-1,50,5)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "El1oSRzwkS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = MM_early(44)\n",
        "\n",
        "mm_early = train_2D_early(train_loader, lr,40,model,path + encoder + '_lstm_video.pth')"
      ],
      "metadata": {
        "id": "Kb0Zs7n6kS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early= MM_early(44)\n",
        "mm_early.load_state_dict(torch.load(path+encoder+'_lstm_video.pth'))\n",
        "mm_early.to(device)\n",
        "\n",
        "mm_early.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early(data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_2=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "ULhTbgxWkS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Conv_2D"
      ],
      "metadata": {
        "id": "pdVcxRD4Y9cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_CNN_2D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=(3,5), stride=(1,1), padding=(1,2)):\n",
        "        super(Encoder_CNN_2D, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv2d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv2d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm2d(output_size)\n",
        "        self.BN_4= nn.BatchNorm2d(output_size)\n",
        "        self.pool_1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.transpose(1, 3)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool_2(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = x.transpose(1, 3)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "        # x = self.flatten(x)\n",
        "\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "NKUk40ZkY9cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class conv2d_model(nn.Module):\n",
        "    def __init__(self, input_2D):\n",
        "        super(conv2d_model, self).__init__()\n",
        "\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "        self.conv2d = Encoder_CNN_2D(input_2D,0.05)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc_f=nn.Linear(480, 5*50)\n",
        "\n",
        "    def forward(self, inputs_2D_N):\n",
        "\n",
        "        inputs_2D_N_1=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N_2=self.BN_2(inputs_2D_N_1)\n",
        "        inputs_2D_N_3=inputs_2D_N_2.transpose(1,3)\n",
        "\n",
        "        x=self.conv2d(inputs_2D_N_3)\n",
        "        x=self.flatten(x)\n",
        "\n",
        "        x = self.fc_f(x).view(-1,50,5)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "G9f_D7erY9cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = conv2d_model(2)\n",
        "\n",
        "mm_early = train_2D_early_2D(train_loader, lr,40,model,path + encoder + '_conv2d_video.pth')"
      ],
      "metadata": {
        "id": "CALTpdOWY9cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early= conv2d_model(2)\n",
        "mm_early.load_state_dict(torch.load(path+encoder+'_conv2d_video.pth'))\n",
        "mm_early.to(device)\n",
        "\n",
        "mm_early.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early(data_2D_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_3=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "-hb74LyfY9ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Kinetics-FM-DLR-Net"
      ],
      "metadata": {
        "id": "fdptyv1jWklC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function"
      ],
      "metadata": {
        "id": "nQZofbgO7cm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PearsonCorrLoss(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(PearsonCorrLoss, self).__init__()\n",
        "\n",
        "  def forward(self, y_true, y_pred):\n",
        "\n",
        "    # Calculate mean values\n",
        "    mx = torch.mean(y_true)\n",
        "    my = torch.mean(y_pred)\n",
        "\n",
        "    # Calculate differences from mean\n",
        "    xm, ym = y_true - mx, y_pred - my\n",
        "\n",
        "    # Calculate numerator and denominator of Pearson correlation coefficient\n",
        "    r_num = torch.sum(torch.mul(xm, ym))\n",
        "    r_den = torch.sqrt(torch.mul(torch.sum(torch.square(xm)), torch.sum(torch.square(ym))))\n",
        "\n",
        "    # Calculate Pearson correlation coefficient\n",
        "    r = r_num / r_den\n",
        "\n",
        "    # Clamp r between 0 and 1\n",
        "    r = torch.clamp(r, 0, 1.0)\n",
        "\n",
        "    # Calculate l2 loss\n",
        "    l2 = 1 - torch.square(r)\n",
        "\n",
        "\n",
        "\n",
        "    return l2"
      ],
      "metadata": {
        "id": "wms7jORR7cm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sota(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "    # criterion =correlation_coefficient_loss_joint_pytorch()\n",
        "\n",
        "    # criterion=PearsonCorrLoss()\n",
        "    optimizer= torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output_1, output_2, output_3, output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "                    # Compute the regularization loss for the custom linear layers\n",
        "            regularization_loss = 0.0\n",
        "            if hasattr(model.output_GRU, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_GRU.regularizer_loss()\n",
        "            if hasattr(model.output_C1, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_C1.regularizer_loss()\n",
        "            if hasattr(model.output_C2, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_C2.regularizer_loss()\n",
        "\n",
        "            # output= model(data_1D.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss=criterion(output_1, target.to(device).float())+criterion(output_2, target.to(device).float())+criterion(output_3, target.to(device).float())\\\n",
        "            +criterion(output, target.to(device).float())+regularization_loss\n",
        "            loss_1=criterion(output, target.to(device).float())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output_1, output_2, output_3, output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "                # output= model(data_1D.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "VQx-cOG97cm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sota_pcc(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    # criterion =RMSELoss()\n",
        "    # criterion =correlation_coefficient_loss_joint_pytorch()\n",
        "\n",
        "    criterion=PearsonCorrLoss()\n",
        "    optimizer= torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output_1, output_2, output_3, output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "                    # Compute the regularization loss for the custom linear layers\n",
        "            regularization_loss = 0.0\n",
        "            if hasattr(model.output_GRU, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_GRU.regularizer_loss()\n",
        "            if hasattr(model.output_C1, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_C1.regularizer_loss()\n",
        "            if hasattr(model.output_C2, 'regularizer_loss'):\n",
        "                regularization_loss += model.output_C2.regularizer_loss()\n",
        "\n",
        "            # output= model(data_1D.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss=criterion(output_1, target.to(device).float())+criterion(output_2, target.to(device).float())+criterion(output_3, target.to(device).float())\\\n",
        "            +criterion(output, target.to(device).float())+regularization_loss\n",
        "            loss_1=criterion(output, target.to(device).float())\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "\n",
        "                output_1, output_2, output_3, output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "                # output= model(data_1D.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "y5EBam4o7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "A3GSoset7cm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_GRU(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_GRU, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 512, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(1024, 256, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "        out_2=self.flatten(out_2)\n",
        "\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "ndBtsOT-7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_CNN_1D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv1d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv1d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm1d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm1d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm1d(output_size)\n",
        "        self.BN_4= nn.BatchNorm1d(output_size)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.transpose(1, 2)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "splDuQJz7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_CNN_2D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=(3,5), stride=(1,1), padding=(1,2)):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv2d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv2d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm2d(output_size)\n",
        "        self.BN_4= nn.BatchNorm2d(output_size)\n",
        "        self.pool_1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 3)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool_2(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "\n",
        "        x = x.transpose(1, 3)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZRWgu_IV7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RegularizedLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, weight_decay=0.001):\n",
        "        super(RegularizedLinear, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.linear(input)\n",
        "\n",
        "    def regularizer_loss(self):\n",
        "        return self.weight_decay * torch.sum(self.linear.bias**2)\n"
      ],
      "metadata": {
        "id": "yEiozFUM7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Kinetics_FM_Net(nn.Module):\n",
        "    def __init__(self, input_1D,input_2D):\n",
        "        super(Kinetics_FM_Net, self).__init__()\n",
        "        self.w = w\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "\n",
        "        # 1D Models\n",
        "\n",
        "        self.model_1=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_2=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_3=Encoder_GRU(input_1D,0.30)\n",
        "\n",
        "        self.cnn_1D = Encoder_CNN_1D(input_1D,0.25)\n",
        "        self.cnn_2D = Encoder_CNN_2D(input_2D,0.25)\n",
        "\n",
        "        # Outputs\n",
        "        self.output_GRU = RegularizedLinear(w*512, 5*w)\n",
        "        self.output_C2 = RegularizedLinear(2*3*32+9*32+w*512, 5*w)\n",
        "        self.output_C1 = RegularizedLinear(3*32+w*512, 5*w)\n",
        "\n",
        "        self.l1=nn.Linear(5,128)\n",
        "        self.l2=nn.Linear(128,5)\n",
        "\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N=self.BN_2(inputs_2D_N)\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "\n",
        "\n",
        "        model_1_output = self.model_1(inputs_1D_N)\n",
        "        model_2_output = self.model_2(inputs_1D_N)\n",
        "        model_3_output = self.model_3(inputs_1D_N)\n",
        "\n",
        "        cnn_output_1D = self.cnn_1D(inputs_1D_N)\n",
        "        cnn_output_2D = self.cnn_2D(inputs_2D_N)\n",
        "\n",
        "\n",
        "        model_2_output = torch.cat([model_2_output, cnn_output_1D], dim=-1)\n",
        "        model_3_output = torch.cat([model_3_output, cnn_output_2D], dim=-1)\n",
        "\n",
        "\n",
        "        output_GRU = self.output_GRU(model_1_output)\n",
        "        output_GRU=output_GRU.view(-1,w,5)\n",
        "\n",
        "        output_C1 = self.output_C1(model_2_output)\n",
        "        output_C1=output_C1.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_C2 = self.output_C2(model_3_output)\n",
        "        output_C2=output_C2.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_GRU_1=F.relu(self.l1(output_GRU))\n",
        "        output_GRU_1=F.sigmoid(self.l2(output_GRU_1))\n",
        "        output_GRU_2=output_GRU*output_GRU_1\n",
        "\n",
        "        output_C1_1=F.relu(self.l1(output_C1))\n",
        "        output_C1_1=F.sigmoid(self.l2(output_C1_1))\n",
        "        output_C1_2=output_C1*output_C1_1\n",
        "\n",
        "        output_C2_1=F.relu(self.l1(output_C2))\n",
        "        output_C2_1=F.sigmoid(self.l2(output_C2_1))\n",
        "        output_C2_2=output_C2*output_C2_1\n",
        "\n",
        "\n",
        "        output = output_GRU_2+output_C1_2+output_C2_2\n",
        "\n",
        "\n",
        "        return output_GRU, output_C1, output_C2, output\n"
      ],
      "metadata": {
        "id": "CG1I-syK7cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "VaCs8OtF7cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "qO7K-6Ee7cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = Kinetics_FM_Net(44,2)\n",
        "\n",
        "sota_1 = train_sota(train_loader, lr,10,model,path+'sota_4_video.pth')"
      ],
      "metadata": {
        "id": "ZkpM1Qgx7cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sota_1= Kinetics_FM_Net(44,2)\n",
        "sota_1.load_state_dict(torch.load(path+'sota_4_video.pth'))\n",
        "sota_1.to(device)\n",
        "\n",
        "sota_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "\n",
        "        output_1,output_2,output_3,output= sota_1(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "        # # Concatenate predictions and targets\n",
        "        if i == 0:\n",
        "            yhat_5 = output\n",
        "            test_target = target\n",
        "        else:\n",
        "            yhat_5 = torch.cat((yhat_5, output), dim=0)\n",
        "            test_target = torch.cat((test_target, target), dim=0)\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "# print(yhat_4.shape)\n",
        "# print(test_y.shape)\n",
        "\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_4=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "jH80hEp77cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Kinetics_FM_Net_pcc(nn.Module):\n",
        "    def __init__(self, input_1D,input_2D):\n",
        "        super(Kinetics_FM_Net_pcc, self).__init__()\n",
        "        self.w = w\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "\n",
        "        # 1D Models\n",
        "\n",
        "        self.model_1=Encoder_GRU(input_1D,0.25)\n",
        "        self.model_2=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_3=Encoder_GRU(input_1D,0.30)\n",
        "\n",
        "        self.cnn_1D = Encoder_CNN_1D(input_1D,0.25)\n",
        "        self.cnn_2D = Encoder_CNN_2D(input_2D,0.25)\n",
        "\n",
        "        # Outputs\n",
        "        self.output_GRU = RegularizedLinear(w*512, 5*w)\n",
        "        self.output_C2 = RegularizedLinear(2*3*32+9*32+w*512, 5*w)\n",
        "        self.output_C1 = RegularizedLinear(3*32+w*512, 5*w)\n",
        "\n",
        "        self.l1=nn.Linear(5,128)\n",
        "        self.l2=nn.Linear(128,5)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N=self.BN_2(inputs_2D_N)\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "\n",
        "\n",
        "        model_1_output = self.model_1(inputs_1D_N)\n",
        "        model_2_output = self.model_2(inputs_1D_N)\n",
        "        model_3_output = self.model_3(inputs_1D_N)\n",
        "\n",
        "        cnn_output_1D = self.cnn_1D(inputs_1D_N)\n",
        "        cnn_output_2D = self.cnn_2D(inputs_2D_N)\n",
        "\n",
        "\n",
        "        model_2_output = torch.cat([model_2_output, cnn_output_1D], dim=-1)\n",
        "        model_3_output = torch.cat([model_3_output, cnn_output_2D], dim=-1)\n",
        "\n",
        "\n",
        "        output_GRU = self.output_GRU(model_1_output)\n",
        "        output_GRU=output_GRU.view(-1,w,5)\n",
        "\n",
        "        output_C1 = self.output_C1(model_2_output)\n",
        "        output_C1=output_C1.view(-1,w,5)\n",
        "\n",
        "        output_C2 = self.output_C2(model_3_output)\n",
        "        output_C2=output_C2.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_GRU_1=F.relu(self.l1(output_GRU))\n",
        "        output_GRU_1=self.dropout(output_GRU_1)\n",
        "        output_GRU_1=F.sigmoid(self.l2(output_GRU_1))\n",
        "        output_GRU_2=output_GRU*output_GRU_1\n",
        "\n",
        "        output_C1_1=F.relu(self.l1(output_C1))\n",
        "        output_C1_1=self.dropout(output_C1_1)\n",
        "        output_C1_1=F.sigmoid(self.l2(output_C1_1))\n",
        "        output_C1_2=output_C1*output_C1_1\n",
        "\n",
        "        output_C2_1=F.relu(self.l1(output_C2))\n",
        "        output_C2_1=self.dropout(output_C2_1)\n",
        "        output_C2_1=F.sigmoid(self.l2(output_C2_1))\n",
        "        output_C2_2=output_C2*output_C2_1\n",
        "\n",
        "\n",
        "        output = output_GRU_2+output_C1_2+output_C2_2\n",
        "\n",
        "        return output_GRU, output_C1, output_C2, output\n"
      ],
      "metadata": {
        "id": "TxgrW1HC7cnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "k-KDqppr7cnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = Kinetics_FM_Net_pcc(44,2)\n",
        "\n",
        "sota_1_pcc = train_sota_pcc(train_loader, lr,10,model,path+'sota_4_pcc_video.pth')"
      ],
      "metadata": {
        "id": "CD4b420XBex1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sota_1_pcc= Kinetics_FM_Net_pcc(44,2)\n",
        "sota_1_pcc.load_state_dict(torch.load(path+'sota_4_pcc_video.pth'))\n",
        "sota_1_pcc.to(device)\n",
        "\n",
        "sota_1_pcc.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output_1,output_2,output_3,output= sota_1_pcc(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "        # # Concatenate predictions and targets\n",
        "        if i == 0:\n",
        "            yhat_5 = output\n",
        "            test_target = target\n",
        "        else:\n",
        "            yhat_5 = torch.cat((yhat_5, output), dim=0)\n",
        "            test_target = torch.cat((test_target, target), dim=0)\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "\n",
        "rmse, p, Y_1,Y_2,Y_3,Y_4,Y_5=PCC_prediction(yhat_4,test_target,s)\n",
        "rmse,p=DLR_prediction(yhat_4,test_target,s,Y_1,Y_2,Y_3,Y_4,Y_5,Z_1,Z_2,Z_3,Z_4,Z_5)\n",
        "\n",
        "\n",
        "ablation_5=np.hstack([rmse,p])"
      ],
      "metadata": {
        "id": "c0zs1Crt7cnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. DL-Kineitcs-FM-Net"
      ],
      "metadata": {
        "id": "LPKAAk5_TtPl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Ab-XOeT4fE"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PTHhS--T4fF"
      },
      "outputs": [],
      "source": [
        "class Encoder_GRU(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_GRU, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 512, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(1024, 256, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "        out_2=self.flatten(out_2)\n",
        "\n",
        "\n",
        "        return out_2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAeHpv2DT4fF"
      },
      "outputs": [],
      "source": [
        "class Encoder_CNN_1D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv1d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv1d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm1d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm1d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm1d(output_size)\n",
        "        self.BN_4= nn.BatchNorm1d(output_size)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.transpose(1, 2)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajKQtaILT4fF"
      },
      "outputs": [],
      "source": [
        "class Encoder_CNN_2D(nn.Module):\n",
        "    def __init__(self, input_size, dropout, hidden_dim=256, output_size=512, kernel_size=(3,5), stride=(1,1), padding=(1,2)):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_size, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv2d(hidden_dim, output_size, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv2d(output_size, output_size, kernel_size, stride, padding)\n",
        "        self.BN_1= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_2= nn.BatchNorm2d(hidden_dim)\n",
        "        self.BN_3= nn.BatchNorm2d(output_size)\n",
        "        self.BN_4= nn.BatchNorm2d(output_size)\n",
        "        self.pool_1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.flatten=nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 3)  # reshape from (batch_size, seq_len, input_size) to (batch_size, input_size, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.BN_1(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.BN_2(x)\n",
        "        x = self.pool_1(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.BN_3(x)\n",
        "        x = self.pool_2(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.BN_4(x)\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "        x = x.transpose(1, 3)  # reshape back to (batch_size, seq_len, output_size)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JLJF7hYT4fF"
      },
      "outputs": [],
      "source": [
        "class RegularizedLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, weight_decay=0.001):\n",
        "        super(RegularizedLinear, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.linear(input)\n",
        "\n",
        "    def regularizer_loss(self):\n",
        "        return self.weight_decay * torch.sum(self.linear.bias**2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqTCcQCkT4fF"
      },
      "outputs": [],
      "source": [
        "class Kinetics_FM_Net(nn.Module):\n",
        "    def __init__(self, input_1D,input_2D):\n",
        "        super(Kinetics_FM_Net, self).__init__()\n",
        "        self.w = w\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "\n",
        "        # 1D Models\n",
        "\n",
        "        self.model_1=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_2=Encoder_GRU(input_1D,0.30)\n",
        "        self.model_3=Encoder_GRU(input_1D,0.30)\n",
        "\n",
        "        self.cnn_1D = Encoder_CNN_1D(input_1D,0.25)\n",
        "        self.cnn_2D = Encoder_CNN_2D(input_2D,0.25)\n",
        "\n",
        "        # Outputs\n",
        "        self.output_GRU = RegularizedLinear(w*512, 5*w)\n",
        "        self.output_C2 = RegularizedLinear(3*2*32+9*32+w*512, 5*w)\n",
        "        self.output_C1 = RegularizedLinear(3*32+w*512, 5*w)\n",
        "\n",
        "        self.l1=nn.Linear(5,128)\n",
        "        self.l2=nn.Linear(128,5)\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N=self.BN_2(inputs_2D_N)\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "\n",
        "\n",
        "        model_1_output = self.model_1(inputs_1D_N)\n",
        "        model_2_output = self.model_2(inputs_1D_N)\n",
        "        model_3_output = self.model_3(inputs_1D_N)\n",
        "\n",
        "        cnn_output_1D = self.cnn_1D(inputs_1D_N)\n",
        "        cnn_output_2D = self.cnn_2D(inputs_2D_N)\n",
        "\n",
        "\n",
        "        model_2_output = torch.cat([model_2_output, cnn_output_1D], dim=-1)\n",
        "        model_3_output = torch.cat([model_3_output, cnn_output_2D], dim=-1)\n",
        "\n",
        "\n",
        "        output_GRU = self.output_GRU(model_1_output)\n",
        "        output_GRU=output_GRU.view(-1,w,5)\n",
        "\n",
        "        output_C1 = self.output_C1(model_2_output)\n",
        "        output_C1=output_C1.view(-1,w,5)\n",
        "\n",
        "        output_C2 = self.output_C2(model_3_output)\n",
        "        output_C2=output_C2.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_GRU_1=F.relu(self.l1(output_GRU))\n",
        "        output_GRU_1=F.sigmoid(self.l2(output_GRU_1))\n",
        "        output_GRU_2=output_GRU*output_GRU_1\n",
        "\n",
        "        output_C1_1=F.relu(self.l1(output_C1))\n",
        "        output_C1_1=F.sigmoid(self.l2(output_C1_1))\n",
        "        output_C1_2=output_C1*output_C1_1\n",
        "\n",
        "        output_C2_1=F.relu(self.l1(output_C2))\n",
        "        output_C2_1=F.sigmoid(self.l2(output_C2_1))\n",
        "        output_C2_2=output_C2*output_C2_1\n",
        "\n",
        "\n",
        "        output = output_GRU_2+output_C1_2+output_C2_2\n",
        "\n",
        "\n",
        "        return output_GRU, output_C1, output_C2, output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ihQ9DeyWp_G"
      },
      "outputs": [],
      "source": [
        "class Kinetics_FM_Net_pcc(nn.Module):\n",
        "    def __init__(self, input_1D,input_2D):\n",
        "        super(Kinetics_FM_Net_pcc, self).__init__()\n",
        "        self.w = w\n",
        "        self.BN= nn.BatchNorm1d(input_1D, affine=False)\n",
        "        self.BN_2= nn.BatchNorm2d(input_2D, affine=False)\n",
        "\n",
        "        # 1D Models\n",
        "\n",
        "        self.model_1=Encoder_GRU(input_1D,0.50)\n",
        "        self.model_2=Encoder_GRU(input_1D,0.50)\n",
        "        self.model_3=Encoder_GRU(input_1D,0.50)\n",
        "\n",
        "        self.cnn_1D = Encoder_CNN_1D(input_1D,0.25)\n",
        "        self.cnn_2D = Encoder_CNN_2D(input_2D,0.25)\n",
        "\n",
        "        # Outputs\n",
        "        self.output_GRU = RegularizedLinear(w*512, 5*w)\n",
        "        self.output_C2 = RegularizedLinear(3*2*32+9*32+w*512, 5*w)\n",
        "        self.output_C1 = RegularizedLinear(3*32+w*512, 5*w)\n",
        "\n",
        "        self.l1=nn.Linear(5,128)\n",
        "        self.l2=nn.Linear(128,5)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        inputs_1D_N_1=inputs_1D_N.view(inputs_1D_N.size(0)*inputs_1D_N.size(1),inputs_1D_N.size(-1))\n",
        "        inputs_1D_N_1=self.BN(inputs_1D_N_1)\n",
        "        inputs_1D_N=inputs_1D_N_1.view(-1, 50, inputs_1D_N_1.size(-1))\n",
        "\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "        inputs_2D_N=self.BN_2(inputs_2D_N)\n",
        "        inputs_2D_N=inputs_2D_N.transpose(1,3)\n",
        "\n",
        "\n",
        "        model_1_output = self.model_1(inputs_1D_N)\n",
        "        model_2_output = self.model_2(inputs_1D_N)\n",
        "        model_3_output = self.model_3(inputs_1D_N)\n",
        "\n",
        "        cnn_output_1D = self.cnn_1D(inputs_1D_N)\n",
        "        cnn_output_2D = self.cnn_2D(inputs_2D_N)\n",
        "\n",
        "\n",
        "        model_2_output = torch.cat([model_2_output, cnn_output_1D], dim=-1)\n",
        "        model_3_output = torch.cat([model_3_output, cnn_output_2D], dim=-1)\n",
        "\n",
        "\n",
        "        output_GRU = self.output_GRU(model_1_output)\n",
        "        output_GRU=output_GRU.view(-1,w,5)\n",
        "\n",
        "        output_C1 = self.output_C1(model_2_output)\n",
        "        output_C1=output_C1.view(-1,w,5)\n",
        "\n",
        "        output_C2 = self.output_C2(model_3_output)\n",
        "        output_C2=output_C2.view(-1,w,5)\n",
        "\n",
        "\n",
        "        output_GRU_1=F.relu(self.l1(output_GRU))\n",
        "        output_GRU_1=self.dropout(output_GRU_1)\n",
        "        output_GRU_1=F.sigmoid(self.l2(output_GRU_1))\n",
        "        output_GRU_2=output_GRU*output_GRU_1\n",
        "\n",
        "        output_C1_1=F.relu(self.l1(output_C1))\n",
        "        output_C1_1=self.dropout(output_C1_1)\n",
        "        output_C1_1=F.sigmoid(self.l2(output_C1_1))\n",
        "        output_C1_2=output_C1*output_C1_1\n",
        "\n",
        "        output_C2_1=F.relu(self.l1(output_C2))\n",
        "        output_C2_1=self.dropout(output_C2_1)\n",
        "        output_C2_1=F.sigmoid(self.l2(output_C2_1))\n",
        "        output_C2_2=output_C2*output_C2_1\n",
        "\n",
        "\n",
        "        output = output_GRU_2+output_C1_2+output_C2_2\n",
        "\n",
        "        return output_GRU, output_C1, output_C2, output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBAU6cjEUB2w"
      },
      "source": [
        "### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChD2kKnpUB2-"
      },
      "outputs": [],
      "source": [
        "def train_sota(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_1 =RMSELoss()\n",
        "    criterion_2 =PearsonCorrLoss()\n",
        "    optimizer= torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output_1, output_2, output_3, output_rmse,output_4, output_5, output_6, output_pcc,output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "                    # Compute the regularization loss for the custom linear layers\n",
        "            regularization_loss = 0.0\n",
        "            if hasattr(model.fm_net.output_GRU, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net.output_GRU.regularizer_loss()\n",
        "            if hasattr(model.fm_net.output_C1, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net.output_C1.regularizer_loss()\n",
        "            if hasattr(model.fm_net.output_C2, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net.output_C2.regularizer_loss()\n",
        "\n",
        "            if hasattr(model.fm_net_pcc.output_GRU, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net_pcc.output_GRU.regularizer_loss()\n",
        "            if hasattr(model.fm_net_pcc.output_C1, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net_pcc.output_C1.regularizer_loss()\n",
        "            if hasattr(model.fm_net_pcc.output_C2, 'regularizer_loss'):\n",
        "                regularization_loss += model.fm_net_pcc.output_C2.regularizer_loss()\n",
        "\n",
        "            loss=criterion_1(output_1, target.to(device).float())+criterion_1(output_2, target.to(device).float())+criterion_1(output_3, target.to(device).float())\\\n",
        "            +criterion_2(output_4, target.to(device).float())+criterion_2(output_5, target.to(device).float())+criterion_2(output_6, target.to(device).float())\\\n",
        "            +criterion_1(output_rmse, target.to(device).float())+criterion_2(output_pcc, target.to(device).float())\\\n",
        "            +criterion_1(output, target.to(device).float())+regularization_loss\n",
        "\n",
        "            loss_1=criterion_1(output, target.to(device).float())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "\n",
        "                output_1, output_2, output_3, output_rmse,output_4, output_5, output_6, output_pcc,output= model(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "                val_loss += criterion_1(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-c8xK3gX48t"
      },
      "outputs": [],
      "source": [
        "class DL_Kinetics_FM_Net(nn.Module):\n",
        "    def __init__(self,input_1D,input_2D):\n",
        "        super(DL_Kinetics_FM_Net, self).__init__()\n",
        "\n",
        "        # Instantiate the Kinetics_FM_Net and Kinetics_FM_Net_pcc models\n",
        "        self.fm_net = Kinetics_FM_Net(input_1D,input_2D)\n",
        "        self.fm_net_pcc = Kinetics_FM_Net_pcc(input_1D,input_2D)\n",
        "\n",
        "        # Define GRU and Dense layers\n",
        "        self.gru_rmse_1 = nn.GRU(5, 128, batch_first=True)\n",
        "        self.gru_pcc_1 = nn.GRU(5, 128, batch_first=True)\n",
        "\n",
        "        self.gru_rmse_2 = nn.GRU(5, 128, batch_first=True)\n",
        "        self.gru_pcc_2 = nn.GRU(5, 128, batch_first=True)\n",
        "\n",
        "        self.gru_gain = nn.GRU(256, 128, batch_first=True)\n",
        "        self.gru_offset = nn.GRU(256, 128, batch_first=True)\n",
        "\n",
        "        self.dense_gain = nn.Linear(128, 5)\n",
        "        self.dense_offset = nn.Linear(128, 5)\n",
        "\n",
        "\n",
        "    def forward(self, inputs_1D_N, inputs_2D_N):\n",
        "\n",
        "        output_1, output_2, output_3, output_rmse = self.fm_net(inputs_1D_N, inputs_2D_N)\n",
        "        output_4, output_5, output_6, output_pcc = self.fm_net_pcc(inputs_1D_N, inputs_2D_N)\n",
        "\n",
        "        output_rmse_1, _ = self.gru_rmse_1(output_rmse)\n",
        "        output_pcc_1, _ = self.gru_pcc_1(output_pcc)\n",
        "        feat_1 = torch.cat((output_rmse_1, output_pcc_1), dim=2)\n",
        "\n",
        "        output_gain, _ = self.gru_gain(feat_1)\n",
        "        output_gain = F.sigmoid(self.dense_gain(output_gain))\n",
        "\n",
        "        output_rmse_2, _ = self.gru_rmse_2(output_rmse)\n",
        "        output_pcc_2, _ = self.gru_pcc_2(output_pcc)\n",
        "        feat_2 = torch.cat((output_rmse_2, output_pcc_2), dim=2)\n",
        "\n",
        "        output_offset, _ = self.gru_offset(feat_2)\n",
        "        output_offset = F.relu(self.dense_offset(output_offset))\n",
        "\n",
        "        output = output_pcc*output_gain + output_offset\n",
        "\n",
        "        return output_1, output_2, output_3, output_rmse, output_4, output_5, output_6, output_pcc, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4TkZBjIW-0g"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEYXl7CiW-0s"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFGXdQj6XBNe"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "model = DL_Kinetics_FM_Net(44,2)\n",
        "\n",
        "sota_1 = train_sota(train_loader, lr,10,model,path+'sota_5_video.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3G48UjCXBNf"
      },
      "outputs": [],
      "source": [
        "sota_1= DL_Kinetics_FM_Net(44,2)\n",
        "sota_1.load_state_dict(torch.load(path+'sota_5_video.pth'))\n",
        "sota_1.to(device)\n",
        "\n",
        "sota_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_2D_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "\n",
        "        output_1, output_2, output_3, output_rmse,output_4, output_5, output_6, output_pcc,output= sota_1(data_2D.to(device).float(),data_2D_2D.to(device).float())\n",
        "\n",
        "        # # Concatenate predictions and targets\n",
        "        if i == 0:\n",
        "            yhat_5 = output\n",
        "            test_target = target\n",
        "        else:\n",
        "            yhat_5 = torch.cat((yhat_5, output), dim=0)\n",
        "            test_target = torch.cat((test_target, target), dim=0)\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_y,s)\n",
        "\n",
        "ablation_6=np.hstack([rmse,p])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TrXnoV0Js5CO",
        "3mq0s3oBqlJ5",
        "zM9iGjQ6uXU-",
        "iP_eDnJwrKCC",
        "2HtJVDh1mEB-",
        "JU11NXkGUqCn",
        "TbKi4_MDkS0W",
        "pdVcxRD4Y9cU",
        "fdptyv1jWklC",
        "nQZofbgO7cm-",
        "A3GSoset7cm_",
        "LPKAAk5_TtPl"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNxy4M1p7L9B12m0+oloHCa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}