{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Md-Sanzid-Bin-Hossain/Smartphone-Video-based-KAM-KFM-3D-GRFs/blob/main/Video_based_KAM_KFM_3D_GRFs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H__KTa0RNQDo",
        "outputId": "ba9091e0-15e3-4e7c-af86-367c55f72375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy\n",
        "import statistics\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statistics import stdev\n",
        "import math\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from scipy.signal import butter,filtfilt\n",
        "import sys\n",
        "import numpy as np # linear algebra\n",
        "from scipy.stats import randint\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
        "import seaborn as sns # used for plot interactive graph.\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from tsf.model import TransformerForecaster\n",
        "\n",
        "\n",
        "# from tensorflow.keras.utils import np_utils\n",
        "import itertools\n",
        "###  Library for attention layers\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "#from tqdm import tqdm # Processing time measurement\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import statistics\n",
        "import gc\n",
        "import torch.nn.init as init\n",
        "\n",
        "############################################################################################################################################################################\n",
        "############################################################################################################################################################################\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.utils.weight_norm as weight_norm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrXnoV0Js5CO"
      },
      "source": [
        "# File path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mq0s3oBqlJ5"
      },
      "source": [
        "# Data loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_vel_acc(V):\n",
        "\n",
        "  velocity_all = []\n",
        "  acceleration_all = []\n",
        "\n",
        "  for i in range(44):\n",
        "      velocity, acceleration = calculate_velocity_acceleration(V[:,i])\n",
        "\n",
        "      velocity_all.append(velocity)\n",
        "      acceleration_all.append(velocity)\n",
        "\n",
        "  return np.transpose(velocity_all), np.transpose(acceleration_all)"
      ],
      "metadata": {
        "id": "mPsuuqPdbpi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_velocity_acceleration(position_data):\n",
        "    n = len(position_data)\n",
        "\n",
        "    # Calculate velocity\n",
        "    velocity = []\n",
        "    for i in range(n):\n",
        "        if i == 0:\n",
        "            vel = 0.0  # Set initial velocity as 0\n",
        "        else:\n",
        "            displacement = position_data[i] - position_data[i-1]\n",
        "            time_interval = 0.01  # Assuming time intervals are uniform (e.g., 1 second)\n",
        "            vel = displacement / time_interval\n",
        "        velocity.append(vel)\n",
        "\n",
        "    # Calculate acceleration\n",
        "    acceleration = []\n",
        "    for i in range(n):\n",
        "        if i ==0:\n",
        "            accel = 0.0  # Set acceleration as 0 for the first and last points\n",
        "        else:\n",
        "            velocity_change = velocity[i] - velocity[i-1]\n",
        "            accel = velocity_change / time_interval\n",
        "        acceleration.append(accel)\n",
        "\n",
        "    return np.array(velocity), np.array(acceleration)"
      ],
      "metadata": {
        "id": "AUDuqhYA44ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP90JbQoR23t"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    with h5py.File('/content/drive/My Drive/public dataset/all_17_subjects.h5', 'r') as hf:\n",
        "        data_all_sub = {subject: subject_data[:] for subject, subject_data in hf.items()}\n",
        "        data_fields = json.loads(hf.attrs['columns'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1Rygjvcmq90"
      },
      "outputs": [],
      "source": [
        "def data_extraction(A):\n",
        "  for k in range(len(A)):\n",
        "    zero_index_1=np.all(A[k:k+1,:,:] == 0, axis=0)\n",
        "    zero_index = np.multiply(zero_index_1, 1)\n",
        "    zero_index=np.array(zero_index)\n",
        "\n",
        "    for i in range(len(zero_index)):\n",
        "      if (sum(zero_index[i])==256):\n",
        "        index=i\n",
        "        break;\n",
        "\n",
        "    # print(index)\n",
        "### Taking only the stance phase of the gait\n",
        "###################################################################################################################################################\n",
        "    B=A[k:k+1,0:index,:]  ### Taking only the stance phase of the gait\n",
        "    C_1=B.reshape((B.shape[0]*B.shape[1],B.shape[2]))\n",
        "    if (k==0):\n",
        "      C=C_1\n",
        "    else:\n",
        "      C=np.append(C,C_1,axis=0)\n",
        "\n",
        "  index_24 = data_fields.index('body weight')\n",
        "  index_25 = data_fields.index('body height')\n",
        "\n",
        "  BW=(C[0:1, index_24]*9.8)\n",
        "  BWH=(C[0:1, index_24]*9.8)*C[:, index_25]\n",
        "\n",
        "  V=C[:,110:154]\n",
        "  V=V.reshape(V.shape[0],11,4)\n",
        "\n",
        "  V=(V-V[:,2:3,:])\n",
        "\n",
        "  V=V.reshape(-1,44)\n",
        "\n",
        "  velocity_all, acceleration_all = extract_vel_acc(V)\n",
        "\n",
        "  V=V/C[0:1, index_25]\n",
        "\n",
        "\n",
        "      ### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "    ### 0:48- IMU, 48:92-2D body coordinate, 92:136 -2D velocity, 136:180 -2D acceleration, 180:185-- Target\n",
        "\n",
        "  D=np.hstack((C[:,71:77],C[:,58:64],C[:,19:25],C[:,32:38],C[:,45:51],C[:,6:12],C[:,84:90],C[:,97:103],V,velocity_all, acceleration_all, C[:,3:5],-C[:, 154:155]/BW,\n",
        "              -C[:, 156:157]/BW,-C[:, 155:156]/BW))\n",
        "\n",
        "\n",
        "\n",
        "  return D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_subject_01 = data_all_sub['subject_01']\n",
        "subject_1=data_extraction(data_subject_01)\n",
        "\n",
        "print(subject_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoVth3PxeCEq",
        "outputId": "ec817782-db0e-42e7-f063-8ffe675e45fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(84490, 185)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d7CRzCoShWB"
      },
      "outputs": [],
      "source": [
        "  # index_21 = data_fields.index('plate_2_force_x')\n",
        "  # print(index_21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6sRqaUhw2S7"
      },
      "outputs": [],
      "source": [
        "# print(np.array(data_fields))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwo6ALnFONNS"
      },
      "outputs": [],
      "source": [
        "data_subject_01 = data_all_sub['subject_01']\n",
        "data_subject_02 = data_all_sub['subject_02']\n",
        "data_subject_03 = data_all_sub['subject_03']\n",
        "data_subject_04 = data_all_sub['subject_04']\n",
        "data_subject_05 = data_all_sub['subject_05']\n",
        "data_subject_06 = data_all_sub['subject_06']\n",
        "data_subject_07 = data_all_sub['subject_07']\n",
        "data_subject_08 = data_all_sub['subject_08']\n",
        "data_subject_09 = data_all_sub['subject_09']\n",
        "data_subject_10 = data_all_sub['subject_10']\n",
        "data_subject_11 = data_all_sub['subject_11']\n",
        "data_subject_12 = data_all_sub['subject_12']\n",
        "data_subject_13 = data_all_sub['subject_13']\n",
        "data_subject_14 = data_all_sub['subject_14']\n",
        "data_subject_15 = data_all_sub['subject_15']\n",
        "data_subject_16 = data_all_sub['subject_16']\n",
        "data_subject_17 = data_all_sub['subject_17']\n",
        "\n",
        "\n",
        "subject_1=data_extraction(data_subject_01)\n",
        "subject_2=data_extraction(data_subject_02)\n",
        "subject_3=data_extraction(data_subject_03)\n",
        "subject_4=data_extraction(data_subject_04)\n",
        "subject_5=data_extraction(data_subject_05)\n",
        "subject_6=data_extraction(data_subject_06)\n",
        "subject_7=data_extraction(data_subject_07)\n",
        "subject_8=data_extraction(data_subject_08)\n",
        "subject_9=data_extraction(data_subject_09)\n",
        "subject_10=data_extraction(data_subject_10)\n",
        "subject_11=data_extraction(data_subject_11)\n",
        "subject_12=data_extraction(data_subject_12)\n",
        "subject_13=data_extraction(data_subject_13)\n",
        "subject_14=data_extraction(data_subject_14)\n",
        "subject_15=data_extraction(data_subject_15)\n",
        "subject_16=data_extraction(data_subject_16)\n",
        "subject_17=data_extraction(data_subject_17)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
        "\n",
        "adjacency_matrix=torch.from_numpy(adjacency_matrix.astype(np.float32))\n",
        "\n",
        "\n",
        "def graph_based_augmentation(joints, adjacency_matrix, max_rotation, max_translation):\n",
        "    num_joints = joints.shape[0]\n",
        "\n",
        "    # Apply random rotations\n",
        "    theta = torch.randn(num_joints, 1) * (max_rotation * np.pi / 180)  # Convert to radians\n",
        "    cos_theta = torch.cos(theta)\n",
        "    sin_theta = torch.sin(theta)\n",
        "\n",
        "    rotated_joints = torch.zeros_like(joints)\n",
        "    for i in range(num_joints):\n",
        "        neighbors = torch.nonzero(adjacency_matrix[i]).squeeze(1)\n",
        "        rotated_joints[i] = cos_theta[i] * joints[i] + torch.sum(sin_theta[i] * joints[neighbors], dim=0)\n",
        "\n",
        "    # Apply random translations\n",
        "    translation = torch.randn(2) * max_translation\n",
        "\n",
        "    augmented_joints = rotated_joints + translation\n",
        "\n",
        "    return augmented_joints\n",
        "\n",
        "\n",
        "def augmentation_all(V):\n",
        "\n",
        "    joints=V\n",
        "    augmented_joints_all=[]\n",
        "\n",
        "    for i in range(len(joints)):\n",
        "\n",
        "      joint_1=joints[i,:,0:2].squeeze(0)\n",
        "      augmented_joints_1 = graph_based_augmentation(joint_1, adjacency_matrix, max_rotation=2.0, max_translation=1.0)\n",
        "\n",
        "      joint_2=joints[i,:,2:4].squeeze(0)\n",
        "      augmented_joints_2 = graph_based_augmentation(joint_2, adjacency_matrix, max_rotation=2.0, max_translation=1.0)\n",
        "\n",
        "      augmented_joints_1=augmented_joints_1.unsqueeze(0)\n",
        "      augmented_joints_2=augmented_joints_2.unsqueeze(0)\n",
        "\n",
        "      augmented_joints=torch.cat((augmented_joints_1,augmented_joints_2),dim=-1)\n",
        "      augmented_joints_all.append(augmented_joints)\n",
        "\n",
        "    augmented_joints_all = torch.stack(augmented_joints_all, dim=0)\n",
        "    augmented_joints_all=augmented_joints_all.unsqueeze(1)\n",
        "\n",
        "    return augmented_joints_all\n",
        "\n"
      ],
      "metadata": {
        "id": "AxiJ4dX0cvzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_extraction_aug(A):\n",
        "  for k in range(len(A)):\n",
        "    zero_index_1=np.all(A[k:k+1,:,:] == 0, axis=0)\n",
        "    zero_index = np.multiply(zero_index_1, 1)\n",
        "    zero_index=np.array(zero_index)\n",
        "\n",
        "    for i in range(len(zero_index)):\n",
        "      if (sum(zero_index[i])==256):\n",
        "        index=i\n",
        "        break;\n",
        "\n",
        "    # print(index)\n",
        "### Ta2Dg only the stance phase of the gait\n",
        "###################################################################################################################################################\n",
        "    B=A[k:k+1,0:index,:]  ### Ta2Dg only the stance phase of the gait\n",
        "    C_1=B.reshape((B.shape[0]*B.shape[1],B.shape[2]))\n",
        "    if (k==0):\n",
        "      C=C_1\n",
        "    else:\n",
        "      C=np.append(C,C_1,axis=0)\n",
        "\n",
        "  index_24 = data_fields.index('body weight')\n",
        "  index_25 = data_fields.index('body height')\n",
        "\n",
        "  BW=(C[0:1, index_24]*9.8)\n",
        "  BWH=(C[0:1, index_24]*9.8)*C[:, index_25]\n",
        "\n",
        "  V=C[:,110:154]\n",
        "  V=V.reshape(V.shape[0],11,4)\n",
        "\n",
        "  V=(V-V[:,2:3,:])\n",
        "\n",
        "  V=augmentation_all(torch.from_numpy(V))\n",
        "  V=V.reshape(-1,44)\n",
        "  velocity_all, acceleration_all = extract_vel_acc(V)\n",
        "\n",
        "  V=V/C[0:1, index_25]\n",
        "\n",
        "\n",
        "      ### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "    ### 0:48- IMU, 48:92-2D body coordinate, 92:136 -2D velocity, 136:180 -2D acceleration, 180:185-- Target\n",
        "\n",
        "  D=np.hstack((C[:,71:77],C[:,58:64],C[:,19:25],C[:,32:38],C[:,45:51],C[:,6:12],C[:,84:90],C[:,97:103],V,velocity_all, acceleration_all, C[:,3:5],-C[:, 154:155]/BW,\n",
        "              -C[:, 156:157]/BW,-C[:, 155:156]/BW))\n",
        "\n",
        "  return D\n"
      ],
      "metadata": {
        "id": "Hk2t1FW-dwMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZIw9tIU2Q7H",
        "outputId": "19e25435-5d11-46c8-bc4f-8989d837b8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(84490, 185)\n"
          ]
        }
      ],
      "source": [
        "data_subject_01 = data_all_sub['subject_01']\n",
        "subject_1_aug=data_extraction_aug(data_subject_01)\n",
        "\n",
        "print(subject_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsCxXC1B-JXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e455fe-901f-45e8-bbb6-2f5495b9c343"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84490, 185)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "subject_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9iGjQ6uXU-"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fTO4veYsyC7"
      },
      "outputs": [],
      "source": [
        "main_dir = \"/content/drive/My Drive/public dataset/Public_dataset_2/Subject01\"\n",
        "os.mkdir(main_dir)\n",
        "path=\"/content/\"\n",
        "subject='Subject_01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvt8kQG5iLMP"
      },
      "outputs": [],
      "source": [
        "train_dataset=np.concatenate((subject_1,subject_2,subject_3,subject_4,subject_5,subject_6,subject_7,subject_8,subject_9,subject_10,subject_11,\n",
        "                              subject_12,subject_13,subject_15,subject_16,subject_17),axis=0)\n",
        "\n",
        "test_dataset=subject_14\n",
        "\n",
        "encoder='LSTM'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7U-luFUh3gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f45684-a43f-4818-f7e5-83489cba5c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]]\n",
            "(1245808, 185)\n",
            "(1245850, 5)\n",
            "(19933, 50, 180) (19933, 50, 5) (4984, 50, 180) (4984, 50, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Train features #\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# x_train_1=train_dataset[:,0:18]\n",
        "# x_train_2=train_dataset[:,23:67]\n",
        "\n",
        "# x_train=np.concatenate((x_train_1,x_train_2),axis=1)\n",
        "\n",
        "x_train=train_dataset[:,0:180]\n",
        "\n",
        "\n",
        "scale= StandardScaler()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_X_1_1=x_train\n",
        "\n",
        "# # Test features #\n",
        "# x_test_1=test_dataset[:,0:18]\n",
        "# x_test_2=test_dataset[:,23:67]\n",
        "\n",
        "# x_test=np.concatenate((x_test_1,x_test_2),axis=1)\n",
        "\n",
        "x_test=test_dataset[:,0:180]\n",
        "\n",
        "test_X_1_1=x_test\n",
        "\n",
        "m1=180\n",
        "m2=185\n",
        "\n",
        "\n",
        "  ### Label ###\n",
        "\n",
        "train_y_1_1=train_dataset[:,m1:m2]\n",
        "test_y_1_1=test_dataset[:,m1:m2]\n",
        "\n",
        "train_dataset_1=np.concatenate((train_X_1_1,train_y_1_1),axis=1)\n",
        "test_dataset_1=np.concatenate((test_X_1_1,test_y_1_1),axis=1)\n",
        "\n",
        "train_dataset_1=pd.DataFrame(train_dataset_1)\n",
        "test_dataset_1=pd.DataFrame(test_dataset_1)\n",
        "\n",
        "train_dataset_1.dropna(axis=0,inplace=True)\n",
        "test_dataset_1.dropna(axis=0,inplace=True)\n",
        "\n",
        "train_dataset_1=np.array(train_dataset_1)\n",
        "test_dataset_1=np.array(test_dataset_1)\n",
        "\n",
        "train_dataset_sum = np. sum(train_dataset_1)\n",
        "array_has_nan = np. isinf(train_dataset_1[:,48:180])\n",
        "\n",
        "print(array_has_nan)\n",
        "\n",
        "print(train_dataset_1.shape)\n",
        "\n",
        "\n",
        "\n",
        "train_X_1=train_dataset_1[:,0:m1]\n",
        "test_X_1=test_dataset_1[:,0:m1]\n",
        "\n",
        "train_y_1=train_dataset_1[:,m1:m2]\n",
        "test_y_1=test_dataset_1[:,m1:m2]\n",
        "\n",
        "\n",
        "\n",
        "L1=len(train_X_1)\n",
        "L2=len(test_X_1)\n",
        "\n",
        "\n",
        "w=50\n",
        "\n",
        "\n",
        "\n",
        "a1=L1//w\n",
        "b1=L1%w\n",
        "\n",
        "a2=L2//w\n",
        "b2=L2%w\n",
        "\n",
        "# a3=L3//w\n",
        "# b3=L3%w\n",
        "\n",
        "     #### Features ####\n",
        "train_X_2=train_X_1[L1-w+b1:L1,:]\n",
        "test_X_2=test_X_1[L2-w+b2:L2,:]\n",
        "# validation_X_2=validation_X_1[L3-w+b3:L3,:]\n",
        "\n",
        "\n",
        "    #### Output ####\n",
        "\n",
        "train_y_2=train_y_1[L1-w+b1:L1,:]\n",
        "test_y_2=test_y_1[L2-w+b2:L2,:]\n",
        "# validation_y_2=validation_y_1[L3-w+b3:L3,:]\n",
        "\n",
        "\n",
        "\n",
        "     #### Features ####\n",
        "\n",
        "train_X=np.concatenate((train_X_1,train_X_2),axis=0)\n",
        "test_X=np.concatenate((test_X_1,test_X_2),axis=0)\n",
        "# validation_X=np.concatenate((validation_X_1,validation_X_2),axis=0)\n",
        "\n",
        "\n",
        "    #### Output ####\n",
        "\n",
        "train_y=np.concatenate((train_y_1,train_y_2),axis=0)\n",
        "test_y=np.concatenate((test_y_1,test_y_2),axis=0)\n",
        "# validation_y=np.concatenate((validation_y_1,validation_y_2),axis=0)\n",
        "\n",
        "\n",
        "print(train_y.shape)\n",
        "    #### Reshaping ####\n",
        "train_X_3_p= train_X.reshape((a1+1,w,train_X.shape[1]))\n",
        "test_X = test_X.reshape((a2+1,w,test_X.shape[1]))\n",
        "\n",
        "\n",
        "train_y_3_p= train_y.reshape((a1+1,w,5))\n",
        "test_y= test_y.reshape((a2+1,w,5))\n",
        "\n",
        "\n",
        "\n",
        "# train_X_1D=train_X_3\n",
        "test_X_1D=test_X\n",
        "\n",
        "train_X_3=train_X_3_p\n",
        "train_y_3=train_y_3_p\n",
        "# print(train_X_4.shape,train_y_3.shape)\n",
        "\n",
        "\n",
        "train_X_1D, X_validation_1D, train_y_5, Y_validation = train_test_split(train_X_3,train_y_3, test_size=0.20, random_state=True)\n",
        "#train_X_1D, X_validation_1D_ridge, train_y, Y_validation_ridge = train_test_split(train_X_1D_m,train_y_m, test_size=0.10, random_state=True)   [0:2668,:,:]\n",
        "\n",
        "print(train_X_1D.shape,train_y_5.shape,X_validation_1D.shape,Y_validation.shape)\n",
        "\n",
        "\n",
        "s=test_X_1D.shape[0]*w\n",
        "\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_y[0:10,:,0].reshape(500,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEq-YZ1CDN_O",
        "outputId": "db04b64b-b07e-4a8c-a024-69e24f8f9f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7b8a906a2a70>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACFb0lEQVR4nO29eXgc1ZX3/61etW+WZEm2vG9sNmDAGJIAgQSSTAiZ7EMmgWSYhEAmC5MMnnkTkt8krzPvMJnJZMg2WchkJiErZLIR9iUsBoyNMd6NF3mRZEvWLnWru+v3R/W9fbu6ulVVXbfqtnw+z+MHW2qk0lX1rXPP+Z7v0XRd10EQBEEQBBEAoaAvgCAIgiCI0xcKRAiCIAiCCAwKRAiCIAiCCAwKRAiCIAiCCAwKRAiCIAiCCAwKRAiCIAiCCAwKRAiCIAiCCAwKRAiCIAiCCIxI0BdQikwmg2PHjqG+vh6apgV9OQRBEARB2EDXdYyOjqKrqwuhUOmch9KByLFjx9Dd3R30ZRAEQRAE4YKenh7Mnz+/5GuUDkTq6+sBGD9IQ0NDwFdDEARBEIQdRkZG0N3dzZ/jpVA6EGHlmIaGBgpECIIgCKLCsCOrILEqQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIQRAEQRCBQYEIYcmju/px35ajQV8GQRAEMctRevouEQyZjI4b734eALBuSQs6G6sDvqLZxeB4EvVVEUTDdA4gCIKgnZAoYHQqxf8+nkiVeCXhlJ7BCZz/jw/ivd95NuhLIQiCUAIKRIgCTk0k+d8zeoAXMgv57bbjAIDNh04FfCUEQRBqQIEIUYAYiExNpwO8ktlHNKzxv2coyvOMoYkkPvXTrXhm/0DQl0IQ0kimMtD12bdvUCBCFDA0Mc3/PjWdCfBKZh+iLmRkarrEKwkn/PDpQ7h3y1G87z+fxSitKzELmUim8Nr/9wiu/+6moC/FcygQIQoYHKeMiCzE9RwQ1pkojz19o/zvP3z6YHAXQhCS2NM3hr6RBJ7eP4CjQ5NBX46nUCBCFEClGXmIQuCBMQpEvGJvfy4Q2Xl8tMQrCaIySQh78VP7TgZ4Jd5DgQhRQF5pJkWlGS8RywaD44kAr2T2MDWdxv4T4/zfx4dn12mRIABgTOhgpEDEARs3bsSFF16I+vp6tLe347rrrsPu3btlfkvCA8SMSIIyIq559cQYvv7wXpwSSjB5GREqzXjC7t5RpAXhb98IBXjE7EMMRF45NhLglXiP1EDk8ccfxy233IJnn30WDz74IKanp/HGN74R4+PjM//PRGBQRsQb/v3hvfiXB/fg8jsfQzK7jqJAdZBKM55weHACADC/2TDe6xuZoo4kYtYxIhxiEqnZdUCU6qx6//335/377rvvRnt7OzZv3ozXve51Mr81UQaUEfGGF7JeIcOT03h8zwm84cy5eZsJZUS84cSokQE5q6sBR4cmkcroGBhPoq0+HvCVEYR3jAl7x3RqdgXavmpEhoeHAQAtLS1+flvCIafy2ncpEHFLTSzM/96b1S1QacZ7To4ZgUhnYzVa64zgo29kCoBx/24+NIj+0anAru90YOfxEdz+y204Nsu6OVRiLJHbl5Pp2ZWp9m3WTCaTwSc/+UlceumlOPvssy1fk0gkkEjk6rsjI7OrDlYpDOd1zcyuG95PBsdzGwcLOkis6j0sI9JWH0dHQxVOjCbQOzyFs+c14s+/8TR2HB9BZ2MVnvq71yMU0mb4aoQb3vS1JwEYZd1v/eXagK9mdpKfEZld+7JvGZFbbrkF27dvxz333FP0NRs3bkRjYyP/093d7dflEQITQhaEMiLuyGT0vBLXIA9EhDovBXmecCKbEWmri2NuQxUAoHdkCtPpDHYcNw4zx4enkJhlm7eK9JyaCPoSZhWii2re3jHLMiK+BCK33norfvvb3+LRRx/F/Pnzi75uw4YNGB4e5n96enr8uDzChBh8TM0yUZRfjE6l8jo5BsaT0HU9T/k+TYJKT8jLiDQapZn+kSmMTOY7rCYpEJGCuF8smlMb4JXMHjIZHV/431ew5osP4KWeIQDAqLh3pGeX1bvU0oyu6/j4xz+Oe++9F4899hgWL15c8vXxeBzxOAnMgkTX9bxyDJVm3DE4ka//GBxLYiKZzgtOZlt6NSjEQKSlJgbA0DkNmwIRo9Mg6vflzXr29Y/xvzdU0/p6wf9sOoS7sw7BT+49gTXdTXmlGV0H0hkdkfDsKDVKzYjccsst+O///m/8+Mc/Rn19PXp7e9Hb24vJSRI0qcLAWAIf/8kWPHdgEAAK0tdUmnHHoEmIOjiezEutAkAqQ4FIuWSyHTIA0FoXR3OtEYgMTiQtAhFaby8wn8R39+acbKnLzhteOjLM/96fDbRHE6YM3ywqz0gNRL75zW9ieHgYl19+OTo7O/mfn/70pzK/LeGAW3+8Bb956Rje851nABTqFmjzdgcLRGLZIXcD48mCYWyp9OxJrQbFqYkkzzLNqYuhOZsRGbIIRGbTxh0U6YyOt/7Hn/Cmrz2JVHY9Dw7kfKGolOsNogli77DR8TVmOsjMphZe6aUZQm2eedUYm85+VZOmEw1lRNzBNpKl7XXYeXwEpywejNOUESkbJlRtrokiGg7lMiLjFqUZKjOWzc7jI9h+1BAAHzk1iUWttXmZvskk7RdeIArdWSu6qC8DgER69pQaadbMaYzVuHRz4EGbtzuYRmRpmyHeS2f0gomZs+lEExQs89SSDUCaa4yN+dR4slCsShmRstmcNekDch0yYiBCmjJvEL2cerOByIg5IzKLMqoUiJzGvHh4iP89EtKQyegFqVVKtbqDZUQ6GqpQHzcSjwdPGht3U/ZhSRqR8hnObthNNSwQYWJVC40IZffK5gUhEGHW+qLRljmjSrhDzIicGE1gajpd0PU1m8TuFIicxpwczRlqpTI6hianC040VJpxBzu9NFRH0VJnPBwPZWvprLNjNp1ogmIoG2ywTAgrzSRSGX6SZFBGpHy2HC4MRMYT5DvkJemMnhdEZ3TgVWG6dEOVcbCZTfczBSKnMSOm0gyLvEUo1eqO8Ww9tzYe4WUDJupj/07Noo0kKNjJsbHaWNPaWBjRbEsjy0AxqMxYHrquc+EkAPRkAxHR34ICkfIZnpzmmj02smB3n6HLqY9HUJ0dHTGbfHEoEDmNGZnMrzmKgYiWbU+njcUdPBCJhTGnlmVEjI2bBSJkaFY+rDTDMiKapvHyjNjNAcyuE2QQTCTTSAn3LC/NTFFpxkuY7qm+KoJ52YnSu3sNr5bGrCgbmF33MwUipzHmjEj/6BTPgDRljYkoEHHHeDKXEZlTa5xqBkzCyulZtJEEBcuIMN0NkNOJHDmVLw6ebaPT/casuTk8YFWaoXu6XIYmcvtEWzYjwkzjGqujiEWMxzZpRIhZgbmrQMyIMPFfpfiI/GnvSXzhf1+x7AQKArY518bDXCPCYDoG5o5IuGfIJFYFgOba/JZGVqqZTansIGBrHc4ODhyZSiGZyuS1lVJGpHxYRqSpJoa2euO+3n9iLPuxKPcmmk0aMwpETmNYRqQ2W3MUAxFm1ZxIqT/T4I+v9OL939uEu58+iB88dTDoywEglmYivDTDaBEempQVKY9cIJILPlhdndFebwzCq5SgWlVYRmRBSw3YEOPB8STP/gFGsJeh4LoshoRyI7uXD5w0yoxiRiSZnj1BHwUipzFMI9LdUgPA2Gh4IFKV87pT/dT+402H+d9/9eIRJQInsTTTUmudEQGQV3MnnDM0mT09VufWdOGcmrzXLJ9bB4AyIuXCApGmmijPQB0dmoD57UYt/+XBPIiaa2Joq88PqhurYzmNyCzyIaJA5DSGZUTmZwVRo1MpTGU369pYLhBR+WGp6zpeOjLE/31wYALbhDkNQZErzRQGImKGhDpnysMqI7JQmADbXBNFe3Yzp4xIebBSbmN1lIuDewYNHU5ImL1GOpHyYNnU+qpIQXavsTpXmiGxKjErYIHIvKZsIJLIZURq45URiBwcmMDQxDRikRAuW9EGIN90KQh0XRcyImEuVmU0Cg/N2bSZ+I2u65aByOLW2ry/s1Q2BSLlMSwEIiy4Zi28DULJgHQi5cEOMTWxwkCkqSaKKIlVidkEK82wFrGxqRQ/zdTFw/x1aYVFUVt7jKDjrK4GXLCwGQCwTciQBMHkdJqnq+vikQKxakNVhAsoafCdeyan0zyQaxZ0N4uEjEhXUzXikdnnuxAEw3kZEWO9WQtvbSyCquwDkjrtymMimWv9bzXtHUZGxNg7ZpO+TOrQO0JdMhmdd5h0NQmlGcuMiLo3/J4+Q01+zrxGrO5uAoDASzOsi0DTgOpoGKFaLe/z9VVRREIhTKfTFIiUAXswRkIaamK5wFncvCMhTciI0AOyHLhGpDrKgzoWiNRXRZDKZDAylaLBd2Uynl2/mngErSaNSFOeWFXdfdkplBE5TRlPpsAqLqw0MyIEItXRMG/TU1mseiJrU9/RWIXV8xoBGApzs+eBn0wwfUgsAk3TUBUN54l/G6ujPCNSCRN40xkdH/j+c3jPt5/hqXgVYGPR66qMdWaIfz97XiPibOOmjEhZMDv9huooF1wzr5a6eARVUSMYpICvPCYEM8T6eITfvwDbO2bf/UyByGkKm4USi4R4HXJ0KqcRqY7lAhGVNSID2THwrbVxNNfG0N1iBFU7jo0Edk0sIyKe0r9x/Vp85HVL8IMbL0RVNMw3k0rIiOw4NoIn9pzApgOD+NDdzyvRlQTk1lkUVjN+/tH1uPnypfjA+kWkEfGIPI0I75oxApHaeATV2UBkMknrXA5MX1YTNwJslrEGslocEqsSswWmgG+oiqI+e1pPCOZE8WgYkQrIiJwcM1rdWrPGPyvnNgAAdvcGF4gw1XudUN56zfJWbHjzGbhiZTsAIFJBdd5nXj3J/763f4yn44OGifrEdWZcuKgFf3fNKsQiIdKIeESeRsTUCVZfFUE8G4iQRqQ8WGmL+Tvd9sYVAAwjuc7GKkGsqu6+7BTSiJymjE7lWsTEjfxE9sFeFQlVREbkZDYjwjpTVnXU46GdfdjdNxrYNU0kC3U2ZiIh5o6o/sPx6f0Def/e9OpgXotsULDx87WCsNoK0oh4w6hQmmGBNKOzsYq/F6lrpjy4RiSb6fuz1V1Y3FqLkckU5tTFBWdV9fcOu1BG5DRFbC+NhEO8jHAyq7moysuIqHnD67qOAZ4RMQKRlR31AIBdvcEFIlalGTO8a0bhIA8w1viFg0Zn0uUrjfboTQcGg7wkzlhi5oAPAOKzsKYeBGNCps/ckt7ZWM01IipnRP7f/bvw//1mhzLlRSu4RkQIsM/qasT6pXMAgMSqxOxh3FRfZ+WZE0IgEs6e2lV9WI5MpfibkZmErcoGInt6RwOzmrYqzZiJVsipZmhimj+A3nfRAgDAlp5gfVoYdtYZAOJR0oh4Ad8z4pG8FmkA6GqqEu5pNfeL4clpfOOx/fj+Uwfwu5ePB305RTFnRMzMxtlJFIicpkyYTpNsM2cP9oaqCM+IqCqoZKngekGxv6i1FrFwCOPJNBfS+c24ndKM4ps2g61ha10MZ2e7knoGJ5TQDY3ZDERilBEpm0xGxwRv7Q+jsSaa5xDc2VgtZPnUXGdxyOd/PLIvwCspzUSyMCMiEgtnNU+KH2KcQIHIacqYcLoBDG8LkebamPIaEXNZBjAyDUvajNPa7oDKM+NOSjOKbybHsoFIV1M1OhuqEIuEMJ3W+ceDZNx0DxeDZURm08btN2aTPgBYIMz06WysEnRPau4XYkv/rt5RJTVDyVSGr19NtEhGJJIVus+iwJoCkdMU0b0PyJVmGM01MS5IU1UjkhOq5iv4WXkmKMGqOPCuGCzbpOqmzeCBSGM1QiENC7IDEg8NBN85Y7c0w06QCZqB4ppxk0kfkN823VoXV74TzOwtdHxoKqArKc6EMMm4ushBhsSqxKzBLPQzByJNNVHlSzMD40ZGZI7JBnllh9HCG5Rg1Vz2soKVZlRNYzOODxubNfMyWJQ9BR8cGA/smhi2xaqUESkbXm6M5czjWDkUAEIhjT8gVc3ymQORoEq3pWDrHAuHuCjVDIlViVmDOSPSIJRm6qsiiIZDPNWqgh7AityJOL+sxDMiAXmJjCfy19aKWIUYmh3lpZkqALnJtocUCERyv/8Z2neza51QuJtDdcYtOjneuqYTgFGWAURvHDXv6ZEKCERYx0xNiXs656yq5jq7gXxETlPMGpGO7GYCgE/WVF0jMsHV5flvWtbC++qJcSRSaW5o5ReiM2Ix2Kat+qmGlWbYGICFPCMSfGnGfA8Xg5xVy8dqra9d04V4JIw13YaIORJSO8tXkBE5pV4gImaeikHOqsSsgZUP2MOyuzknPGvK2jfnNCJqBiKTSWtRaGdjFRqro0hldOzNDsXzExYglTqp801b0dMjo2/E0OG0N+RnRA5XUCBSKa3SKmNu9weMmT7XnN2BzkYjSFV9onQllGYmiuxpIjln1dlzP1MgcprCTu3sYdndkgtEWmqMUofqGRF2ejCLujRNwxmdRlZk53H/yzO5rplSPiJqtzoyRrITmpuy9wTTiBwaHA/Mp4XB1rl+xkBE7YC6Esi1pJcIrhU/qbN7md3DKnR+mTEfEK2IVsDoDadQIHKaYn5YsmFxgGHhDEB5Z9XJEmnMMzuNdPHO4/4LVscTM6dXK8FHJJPRedaBiZnnNVUjEtIwNZ1Bf9b8Lijstu+ygHp6Fm3cfuPEpE/djIjxM5zRaYjZVcyIjCdn1pfl7mc192U3UCBymmJ+WLbX5zQirM1R9YwIS2NatbmxjMiO48O+XhOQb59fjErwERlLprh3BBMzR8IhzG82gtagO2eclmZUP0FmMjoOnBxX0n7cTtAXDamd5WOlGRaIHB+aCjyrZ2ZiBldVQP2Azw0UiJymmB+WLOgQP6e6jqGYWBXIbTa7ekd939jtDL2LVsDQOzYYMRYOIS60EqrQOaPrOi8XzOQjEhZS2So+5Bn/8eg+XHHnY7h3y9GgL6WAMRvlRtWzfCwQWTG3DuGQhmQ6w72IVMGqO8mM6gdEN1AgcppS6oSztK0OgPo3fKlAZFl7HTTNmJXC/Eb8ws7QO9VbHQFgNFtTr6/KeUcAuc6ZIE3NEqkMz3DMNH2XBX2Auveyruv46oN7AAD/577tAV9NIXYE2Kpn+dj04JbaODqy4usjipVnSu1pjIji6+wGCkROU6zmofzy5kvw/osX4FNXrQAgivzUvOFLpTGromFeQtjX71/nzHQ6w2ea2KqnK7q2ADAyma8PYbCBZ/tP+N+RxGDBHlBaiwMAYWFkvarZPVHLlNF15UoGdspgqrsFs4xIY3WU++Ko1sLLW/9LZZ4U93dyAwUipyHiw1IURa1d2IwvXXcOGiuka6ZY+y5jebuhE/EzEGHBETDTZqJ2qyOQy4gw8TKDGcYF5VwLAGNTud99SCgrWhERPq9q4PfE3hP871PTGewLMMizwpZYNaJ2uVHMNjBfHNUEq9yV2U42VdF72Q0UiJyGsJsdqOzIu1j7LmNZu1Fi8jcQMTbsaFgratEMiJu2mmsL5DQi5ozIqqz+5tDABH9A+Y3dybuAKRBRdL0HTeXDLYdPBXQl1jBxe0kRJTc0U3ONWRAaDYcwL5stVa2F15YZItM8KXovu4ECkdOQsWROhFjqYRlW/NQ+OYPCfFmb/4GIHQ8RINdhoOrpEcj5LtSbLPRbamOY22BMPA4qK2J34B2QL8RW9SFpDuiUKxnYEFGqPPRO13Ue9EfCGp+dpNo628qIMKG7oveyGygQOQ2ZsLGpAKKPiHo3vK7rBfNyzCwNICPCTo4zPSArYegdy4g0VBf+LKv4YMGA5vnYmHDM0DQtVwpTdL1Z2aAxWwY7NqzWZFizn4wVEYXbSsUANBoOqVuamZ4586S647UbKBA5DbHTigeorRFJpDJglzVTaaZ3ZIrrHWQzbsOiGaiMrhmeEamKFnzurC4jENl8MJgSQm7yrr05QhHF7cdZxmF59p5VrmRgYfFuRuUsn/h7j4Y1LmRXLhCxk3lSeJ3dQoHIaciETf+FiMJdM3ZEoY3VUbTXGyWE/Sf88bywY9EMCPV0hTcT1jXTYBGIXLaiDQDwyO7+QH4GJ6UZQBzIpmYgwu7nZYoGIqNsvUtkRPhMHwXXWLSdj4ZDvDQzOpXiAbcKjNswNFNdu+cGCkROQ3hGZIbTZFjhdjxWlolFQnkaADN+C1bNM3yKUQkZEdFHxMzahc1oroliaGIazweQFbFr785QOagGcvcND0SGp5QyX2NdSma9kIjK/hbiNUVCGmpiETRnuwNV0olM2HBlVj275wYKRE5DJpL2TpMqR965OTOlH/hsY9/b74+o0k53AVBZGhGrQCQSDuH1q+YCAB7c0efrdQH27d0ZqntcsEza0jbDiC+ZyvhuxFeMdEbH5PTMpTCVrcfZ7z0a1rg5n4qdM3b2j0iFDMx0AgUipyFjiZnd+wC1NSJ2UphALhDZ71NGZCYBLaMSJmjOJFB8w5nZQGRnr++n99wJ3VlpRtX1npg2fp7Gmija6oxyoioPSNE8rlRpJqLwMDamp4gILrtdjerpRHL7x8ylmYwO5Yzv3EKBiEROjiXwLw/sxt1PHQj6UvKYsHmaVDmdXWrgnYjfLbx2T+oql70YiZQR7MWj1mv8uhWtiEdC6Bmc9H3KsZOuGUBcb/XuZUBs24ygM6tfOK5I5wwrgxkzh0qVDNQ1NOOBiOCyyzIiqpRmMhmda4VK7Wviz6DiIdENFIhIIpnK4J3ffBpff2QfvvCbHfjp84eDviSOHQU8ILh/Kniz2y7NzDUCkcODE5iaTpd8rRfYGXgHVMZEWDaFOV7Ea6YmFsHlKw3R6r89tMe36wLErhl7gUhU8ZZHsduqrS4GoNDkLCjGbLb7xxQuzbA9jF0jAMxvDn5mksiksD/Z6ZoBZk95hgIRSfxh+3EcFG7wr/xhlzJpNKs5M1aEFU5nszdtsdM6o60ujoaqCDI6cOCk/M6ZcRsD7wD1T+iA0SINoOQp+FNvWIGQBjywow9/9cPnfft5cl0z9tp3Vc5ApTM6prJBX208gjm1RmlmQJHJsEwrVKosA6gtwGYjLcRswhmdxqiCl48OB3JNZlgwqmlAVanMUwUMcXSK1EDkiSeewFvf+lZ0dXVB0zTcd999Mr+dUvzPJiMD8jevX4baWBinJqYDnc0hksuI2DM0U/FmZw+8Yqd1hqZpvnbO8IzITM6qip/QAaE0U2KNV3U04O+uWQUAeGhnP559dcCXa3MqVlU5A8XKjIARwM7JZkROjqmREckFfcU7ZgBh+q6Cp3S2h0WFjMjZ8xoBGBoRFYI+3vofLT0/qRJGFjhFaiAyPj6ONWvW4K677pL5bZRD13Vsz0bZ1547D2sXtQAANh3wZ5OeCS70tKljUHGmATvhiKnWYvgZiNjXiKjrucBIpuwFex+5bCnedm4XAODp/f7c407bd8MKCylZ8BoOaYhHQpiTFauq0jUzZjP7xL1aFNwvWPuuGIg0VEWxpM2YJL3tSPBZETtzZgAgFNLAYhEVgz43SA1E3vSmN+FLX/oS3v72t8v8NsoxOJ7km0t3SzXWLc4GIq8OBnlZHLtpbZUzIuwhGbURiLApvH608NrxAQDUFgIz7JRmGK9bbmhFnt53Uuo1MRwbmrGMiIIPSbGcp2kaWrMZERVO6UCuQ8muAaKK5cYkD0TyMw1r5jcBALb0DPl8RYXY1b0Bagd9blBKI5JIJDAyMpL3pxI5klVhz22IIx4JY/3SOQCAp/efVOJNancwW1jh+RzJ7Buw1NA+xors2PrdPpTGbPuIKD5QEBACkejMa3zJMuMef/nosC92+mM2Z/owVJ41Yy7n5TQiamVEZso+xRTummHvM1FfAQAXLzEOiQ+80uv7NZmxa0kAzL55M0oFIhs3bkRjYyP/093dHfQluaLnlCFS7c6qstfMb0JLbQwjUylsPhT8eO9x24Zm6mdE7AQiq7KByMEB+Z0zdqaUAupbjqfSGb7JzVSaAYDOxmrMa6pGRvdH/DeWMIId54GIeus9bnI6ZhqRgXFFMiI2Bt4BuayTiv4W00UyItec1YloWMOu3lHs6QtWw2d3GClQGWJ3JygViGzYsAHDw8P8T09PT9CX5AqWEWGDlcIhjc/meHRXf2DXxZiwa2imcDrbSSDSXh9HU00U6YyO/Sfk6kTsilVVtsMG8mdz2FljAFg93xD/ya63p9KZvC4TO6hsi12QERHad1U48Y7ZLIOJHSmqaXFyzqr593JjTRSXrWgHAPxxe7BZEScZEZXF125QKhCJx+NoaGjI+1OJ9AxmMyItNfxjr19l3OyPKBCI2E21RhU+RbKTgB2xqqZpWDHXn/LMuF2NiMJrC+Q8RAB7awwAq7P19pclByLjSXt+CyIqZ6DMJlYtNUYgktGBoYngyzP29wuhrVSxgM/K0IzxmmxZ8YWAs9V29WWA2u3oblAqEJktmDMiAPC6FW0IhzTs7R/jgUpQ2DXd4l0zip1ugNyJ3e5pnZVndh6XqzuasGm0pbrYjOlDIiGNp9xnYk02I/LSkSFZlwUgV8qIhjVbQlr2WkDNDNS4aSxAJBziA9lUaOF1KlYF1LuvmTbIStx+Qbar8cVDpwLNMDB9WXXURkakAkZEOEFqIDI2NoatW7di69atAIADBw5g69atOHxYHZdRGZzMqt3bG6r4xxqro1i7sBlAsFkRXdftn9rD6p7anbTvAsDZXcZDcvtReYFIMpXhAdLMQ+/UXVvAnoeImbOya3zk1KRUwarT1l1A7blJiaxuqUow52vOZkVUyIiM29WICP4WScUCvmKlGcA4pNTGwhhNpALViTjKiLAOJQUPiW6QGoi88MILOO+883DeeecBAD796U/jvPPOw+c//3mZ3zZwirUWvuEMY0jYPc/3BDbieyKZBvvWM51wVHZWTTho3wVy5kXbjw1LE9KZjalKobL5EyB4iMzgXCvSWBNFW73R8bH/hDwX2zGbIwpE+LRjxR6QQO4hKWaeGrMZkaFJ+R1IMzFqM/DTNE3Z+7qYWBUw1v3cBU0AgC2Hh3y8qnzsdtwBuTKYapknt0gNRC6//HLoul7w5+6775b5bQNnLGEtWHzXBfNRGwtj5/GRwLIizK45HNJQPcNDRmUdw7TD0szyuXWIRUIYnUrhkKTSGNMuxCKhGQMkHuQpupEkHGacGMuz5nF7JZ4sxx227gJq38ss0BczCk3VRiAyPBF8IGK3NAOoW3JMWQR7Imd2GnrE3b3BWUbYndwNqG2t4AbSiEigWEakqSaG91+8EEDOAt5vWMq8vioCTStuIwyIGhG1NhXAWdcMYGROzshuNrLaSyccmGypPDIdECfvOtsiuIutxO4k3sUxQ6lARGWxKrsH8gIRVpqZVKA0Y7PdH1DX1IxnRIpYp6/sMPaGIMdw2HW8BsQMn3r3sxsoEPGYdEbnA9msan3vvtDwRnl8zwmcGPXfJ2Bkyl69F1D7FJnTiJQOpkTOzA65knVaH7M58A5Qu50UmHnybjF4INInPxBxohGJKBxUW53WG7MZkSGVMiI29gyWCVRtzyilEQFyYvbdfaOBlc0nHWREVL6f3UCBiMeMCzoBq41yaVsdzu1uQjqj44u/ecX3mjXPiMwwwAoQ0n+KnW4A56UZwFh7QN7MGbseIkD+CT2oja8UCT5U0L5GBPAnI+J08i6g7kkdEOegiBkR9TQidjIi7GdgBwVVyLXvWu8Xy9rrENKMwK8/gAMiIGhEKjjz5BYKRDyGbZKR7AArKz579UpEwxp+u+043v3tZ/j/4wejjjIi6opVnbbvAsDyrJeIrEBELHvNhJiGV3F9WUbEyfoCuUCkZ1Cei60rsarCJ0iWPQgrqBFJpjI8qHCkEVFsnVPp0hnUqmgYi1uNAXhBdc440YiofD+7gQIRjxFbC4tpMC5Z1oq7/uJ81FdF8OLhIdz99EHfri8XiMycEVG5xTQnprR/KmYPyYMD41KyPI7KXqLngpLr67x9FwDa6uJorI4iowOvSuqccdO+G+FzUNRba6sR9axrZjjgjIh4SLKz3qr6tSRnEKsC4IHIwYFgfJ4czZqpgOndTqBAxGPsDuN641kd+OK1ZwEAvvenA9JnoDDYqb3Bwaldxai7VDteMboaq1ATC2M6rUvpnBnJPjQaqm0EeaILpYLrm5u862yL0DRNennG6eRdQLyX1XpAAkLZIC8jooZYlWWfqqIzd4IB6gZ8qRLOqowFLUYgcnhAXut5KZzMmqmE6d1OoEDEY+wOPQOAa9d0oaOhCoPjSTx/cFD2pQFwVppRuUXMadcMYDwkmU5kv4TyjKOyl7AhqtjCy31EHGpEAGAZ0+JIEwXbc68VydXU1Vtrq/Zd7iMScGnG7pwZBu8GUywjwoL9Uu3oC+cYIzkOBZ4RsV+aUfF+dgMFIh7jRNEfCYdwyVJjzsGzrw5IvS5GTsdg/9Su8oPSqYaBbTaHZWREHK2tugPCAKH05XB9AcOzBfAhI+KgfVdlcz4rQzNVNCJOAxF2v6h2eEnyrFPx+3lBi7y9wQ5MI2KnNKPy/ewGCkQ8xmna+OIlRiCy6VV1MyIq1iGdDL0TYYMIZcz7YWvbYCMQ0TRNaZ8WtxoRAELWSZJGhPta2M/WRBXO7lmVDZiPyGgiFWh2wUnrLpB7P6rWNcM7kyIlSjPCIcXvTrZkKsMDUjsibFW1OG6hQMRjxh0q+tctMQYuvXRkyBedyIgLsaqKD0q3GRGZpx6mEbET5AHiBE31NhPuI+LQ0AzIzzrJ2NBZwOekayassG+LVWlG1HCNBChYddqhxN6PCcUCEe4jUiIjMr+5GppmtOH7PWxQHA9RbcuHSM3uJLdQIOIxOXc8e6e1BS01aKyOYjqtY79E7wWGkxZTJk6bVmxTAdy17wJyAxGeEbEhVgXUnqCZdOkjAgDzm2sQ0oDJ6bQU0z43YtWoom2lQC7jKJYNIuEQf48G6SUyZnPgHSMaoFg1k9Gx4Vfb8KNnDhZ8zo64PR4Jo6vRmJh+eNBfwSofDxEO2drTuNmkgoG1GygQ8Rinm6SmaViZ9bfwo3/dmY+IujbkbmehsECk59Sk58PvRhwEeYCYEVFvM3HrI8L+n64mY0OX0Qo526bvWhmaATlTsyBbeJ2uNbtfgijN/PGVXvzkuR587tevFHxuJkMzBtsf/BasMldVuwdYlV2v3UCBiMe4sZ9e0WHU1Hf3+pARSdgXVEYVnmeQO+E4u4U7G6sQDmlIpjKeOyg60YgAuWtXMSNSjkYEABbNMVohD0lohXTzHlO5pp4zNMtf60YFBKujDgbeAbmDQRDlxgMl7rUUt3gv3e4fVOeM03JjROH72Q0UiHiMm7Qxy4jInFjKGJlkD0v7LaYq2pAnXfpcRMIhdDVVAfC+PDPiwKPFuBaFNSJltO8C8jZ0Xdd5GtvJeyyscGmmmMeFCl4ibrtmgsiInBwtvk5JmweXBRK76krhJFMNqOtg6xYKRDyGzQuwY9PLWJENRGRPfkylM/xh2Vwbm/H1UUVNt1LpDNjluCkdzG8yNpujQ95tNrquO3KtBRS30HcZ6DFYIFLqlOqGRCrD18vR9F2FT5A5Z9X8QEQFLxEnJn2A0DUTwDqfGMtlOM0HJ6vBglYsbJGXySuF02yqyh5PbqBAxGNY50tV1Ln1+LHhSamdM8OT02DvzyY77p+iDblC5RlRU+G0NAMY6ngAODI46dk1TU6n+QOyodphelXBzYQFIlGXgcjydjlZvjHBcrzGwXtM5Zo6e2+ZSzNNCkzg5Vk+uwLsSHBD704KpVbz75m9x2aa1i3TZ6gUTpoIAKHUqOD97AYKRDzGTTdHS20MdfEIdB04ckreG+DURK50MNPJAMgPRII44RRD3ORcZUSajc3myCnvAhFW8gqHNFTbfECGFVa+s407Giq9cRdjVacRiOw/Me5pcJ1rjw8j5ODaIgrrnYqttQpiVSelXCA3+ymI/eKkkBExlzv5rJkS7btArjRzciyZF/TKxmlphpcaFbyf3UCBiMe4GU+vaZovau1TE0YN1U5ZBjCVZhQKRBJp48GmafneC3ZhGZGjQ94FIuKJptiwQzNKt5TaTGUXo6OhCk01UaQzuqfTjrmoz4E+BFB9bpL1WnONyERwGpGKyogIgYj5++cMzUrfzw1VUTRnA8DDPgpWnTheA7mMiIr3sxsoEPEYbpzjcAP3Q619ajwbiNTYC0RCIU3Jtkdxje0+9EV4acbD7BPzerBT8mKouLYMfkp3MFRQRNM0rOrwXvvkRgwOqN2Kzg3NimhEAs2IcAG2vfs6HlDXTCKV5hlfoDAjw7vsbBxcFmQ7vvz0EnEyuRtQ2wzRDRSIeIxb63E/1NosI9JiMyMCqDnEigspXZ7W57cwsap3XiKsjt9kM8gDFG8p5boFd4EIAKzqaAAAvHJs2JNrAnL27o4zIgqfIK2m7wK59t0gDc1YaabRpu4pqK4Zs46mMCNiP8O3MAAvEadCd5Vb/91AgYjHcJGf04yID2rtwXH2sLR/alfRS8StvTtjbn0ckZCG6bTumZcIC/KcrK3aGRF7NfVSnL+wGQDw3AHv5ijlJu86aytmP4eK5nHF1jrowXeZjM5LBk69cfzWiJj1HOZAJK3bD6yDGH7nVKyqshmiGygQ8ZikDSthK3hpRuLNz2rNLQ5O7Sp2dpQbiETCIXQ0Gl4iXpVn2MPCSWlGaQGly/tYZH12oOOO4yO8LFguudKM/XUGFG/fLeqsynxEgglExpMp3iZvu303oIzIRCJfEG1+QLPMgZ0EXxBeIs59RNTbl8uBAhGPmbYpijLDovCjpyalmYcNjjsTqwK5U1oypc7D0q45USlyOhFvBKvMdMpJaUblzSTn9uk+EGmrj2PF3DroOvDsqwOeXFcuEHGWEQnS8XMmiq11E/cRSXo+jsAOTLcQC4ds+8kEFYjMlBHJOLifAynNJBxqcQI0jpMBBSIeM519YDvViHQ0ViGkGYZNMgaFAULXjIOHZUzBjEgxcZ8TWAuvV50zpyacl73Uzoi4E12bec2yNgDALzYfKfuaAHf27kDuAaliKrvYWjONSEYHxpL+tZIycmZmDjrBAgr4JkzrYy4NsdJMyMbPsTArVj06NOnbz+E0IxKkg60MKBDxGDftu4DxBu7MTn7s8dDfQoQ9LJtdPCxV2sBZUOSmdZfhdeeMq9KMyi2lHqwxALz/4gXQNODhXf2emJuNOZx9wmAPyKDG0ydTGbx4+JRlZoPfz6bAuioa5iffIHQiPBCxeUoHhJO6ahqR7D/tZETa6+OIR0JIZ3Qc87DFvxROxaqxgNZZFhSIeEw5ZQMZbaUirkozCtbWizlROsFrU7NySjOV1FLqlCVtdbj6zA4AwHeeeLXs63LbNRPUSZ3x1z96AX/+jadx/yu9BZ/LiVUL15oPvgtAJ8JbSh0E11ys6rdGJGnWiJhKMw7EqqGQP75ODGM8hDOxKjOOCyqw9hoKRDxmugyRX3eL946fIswCua0+bvv/UdF0K11i47aL1xqRU2V0JKmYEUnZdKK0w19ftgQAcN/Wo/jRMwfxm5eOue4Oy3XNOAtE4pHgApFkKoPHdp8AAPz8hZ6Cz5da60ADEZ4Rsb/WuVkz/t7T4zNmROyXZgB/mgcYiVSGZ5ydlmZmSyDi7N1MzAjv6CgjI9Ij4eafmk5jNPtmba2zH4ioOCE25YlGJOuuesrwEnFiF24Fe1A4yYio3ILHvS3KzIgAwPkLmnHpsjl4at8APvfrVwAYG+ldf3E+3nDmXEdfy61YNaiTOgA8te8k//s585sKPl9qrYO0eXfqqgoEp10YL+iacS9WBYAFWTuFwz4Mv2MBX0gDamP2HskkViWKks7ovN3NTWmmW8IMFAYTwMYiIUcnHBU1ImkP9AudjdWIR0JIpjOetOmx1mhn7btMI6LeZuKFj4jIN65fi/de2I1VHfWY11SNZCqDz/7iJcclP6dW2Az2gExldN87UJ49kOsYsvre6RJrHWxGxNlEWEB9sWrYaUbEh9LMoNBEYPdAlAv45A1J9RPKiHiI+OZzM7WUZ0QkaETYiOy2urgjW/SYihoRD1pLwyENK+bW4+Wjw9jVO4JFrbWuv1YylcF4tkbtqGtG4YxIysOMCGA8UL/yjtUAjPfJBV96CKcmprG1ZwgXLGqx/XWcjktnRE0DHKtCzjIq5SB6qJgf0Lqul8zwNQQ4gTeXEXFQmlGkfddcsuClGZvbsp9eIqys60S7R2JVoijiTVGORuTY0KTnugGmD2l1oA8BBEdKhXQMpU6QTmCzUHYeL6+bg2VDQpqzB6TS7bvZNY56lBERiYZDeO3yVgDg2gm7iC2lTr8nw+/TuhhEmB+QovbKaq3Z4LtgNSIOSjOKilWZNZNtjYjgrirL14lxyoXRJFvnxDQFIqcduq6XdIicFsfTuyjNzG2oQjRsWI/3jUy5usZiiBkRJ6jdNVPeaX1VpzELZefxkbyPZzI6fr31KL702x14Ys/MD8qB8dwMH0ej6UMKl2bS5etwSnHFynYAwJN7HQYiDtscGbG8QMTfwE90RjU/IMUDh9VaB9s1414j4new56XFO2B01YU0I8A5MSbH14mR62a0v85VUcqInLb842934oIvP4Rfbz1q+fncVFjN1VTYcEhDV5McwerJUeNmb6u3H3UDas6a8aJrBgDOyGZEdgiBiK7r+MwvtuET92zFd/90AB/4/nN4dFd/ya8zMGas7Zzays82MbzwainFmu4mAMCevjHbmo10RucPHCc6J8BoyWQ/i9+nddEDxPyAFv9t9ZBkw+aGJ72xyHdCTiOifmmGaUSKTaV12jUTiwi+TpLLM06nogO59l0Sq56GfP+pA0hndHzinq3oHy3MWEyX4SHC8LqtlHFizLhexxkRBb0u2LWUmxE5e34jwiENR05N4nBWlPbj5w7jly8eQUgDurLzaP7h3pdLnvAGxo0T05w6Z0GeqhNhM4Lo2s60UjcsnFODSEjD5HQax4bt3evMzAxwnhEBghNSDudlRPJ/12KAb7VvsC6sSsmIsJJ0wveMiFGaYWaN4gNaDHSd7Bl+eYlwsaoLjchsad+lQMQBLcKNsuPYSMHnvZiBwjpnvBassoyIU40I37wVuuG9MttqqIriguyE2Ed392P70WF88Tc7AAC3v2kVHr7tcjTXRHFseApbDg8V/Tonx3KlGSewTVu1U40YdMoqzUTDIS4Q3tc/Zuv/YQ/GqmjI1cDDoAR+Q0I2w/y9mUZE04plRBQozTjRiAilGdnaCpGJbKaMBW6ij0lauA67XTOAf50zLCPiSCMSyXkQqXaQcQMFIjaZTme4qAiwfniwj3mREekZ9DYjwjI4rjUiCt3sXpptXbHK0Cp854lX8ZEfbUYylcFVZ7TjptcuQXUsjMtWGLNSHttdvDwzkK0hO/FnAYDqqJFenZpWqwVPPKXLKs0AwLK2OgDA/hP2vBrcPBhFgvASmZpOY0oQFJq/90wlsEC7ZrKlmUYnXTPZNdZ1f/cMJlZlD3NxncUHtZMtw6/OmcEJ910zgHoHGTdQIGKT/tEExADfKiXG58yUcYpcmt2c9/aXP5dDpG/EeFjOzZYb7BIVfER0XcdkMviHplcaEQB489mdiEVCODo0iaNDk5jXVI0737WGa3wuW8kCkeKiypxGxFlGpCobiEyqFoiIAkoJXTOMZe3GvW47I8I0Cw5KBSKxAMz5zJkM8/eeKahurgkmEMlkcrbjbjIigL/rPMYzItGC753R3ZVmFmZNzdy6ANuFZ0QciFXjFIicnvSa6thWv3yuEXGRNmac2WV0cuzqHfWsUyWT0XlGZG6D00Ak1zVz75ajOOPz9+N32457cl3F2Nc/hrufOlB0A/DCR4SxYE4N7vqL81EbC+P8BU34/g0X5rmjXrrMaDPdcXyEb8xmWNfMHKcZkVg2EFEguBMR7zuZGZElbcZGf+Cks9KMXRtsM6KQMp3ReSZLJuYAoiAQmaHMyATQY4kUEj6aV40nU1wn5KhrJuz/A1LXde642zxTRsRFaUZ6RsSFWDUS0sB+FD/vC1lQIGKT3uH8TcsqI5JMlT86vbu5BrWxMJKpDF496U0kPjiRxHRah6YZkyWdIHZ2fPpnLwEAbvnxi55clxX7+kdx1Vcfxxd+swMbf7/L8jXpItNK3fKGM+di2xeuxq8+dilWZjtpGO31VVy0+oqFLghwL1atDigjMjI1jRcODhb9fIp3GKBs6/tSMN+cozYnnLo1M2Pw0kw6g28+tg9rv/QQHtnV5+pr2aUgI5Iyi1VnKs1E+OcGS1gHeA1rk46FQ3mn75kICw9IvwKR8WSa37Nsjla+WDX/+uzCSjMnx5IF7cFewn1EHGRUNU3LeYlQRuT0odfk62FlrZsrzbhf1lBIwxlF/C3cwjxJ5tTGHQdJoo+IaNImyyb7uQOn+N+LdVN4mRFhlPpa58xvBABsPzps+XlWmml1GYhMTaexr38UX31gN376/GFHX8MNG371Mt75rWeKZrZyp3S528O8bKv68aEpW4I7ZrDlNiMilhnvfGAPAOBDd7/g6mvZZWgiP3gwi1Wn06XXWtM0rh1g95kfiMZxTqwIxAekX6JgVtqIR0Lc6K5YacZJRqShKspLY4clCVbHEimub3GaURXF1//42x143f971LKbsxKgQMQm5tJMKY1IOaUZIFeeeanH+sHnFBaIzG1wdqMD+S2PYslij8caFsau3lzwNVKkU8BLsaodzplnBCLbjhQLRLIZEYc+IlWxXEbks7/Yhn9/ZB/+7pcv562B1yRSaR6A3PnAbsvXsFN6VGI2BDDKhJGQhlTGnoGfm3ZSkWIeFzJnzzAzs3ARDxMmVi211kx75GtGxIWrKoMFIlPTGfzzH3fhf1865um1mREzCjxLIAQi6bxAxNnXXjAnO/xuUI5O5Hg2G1hfFUGd44nSxv4xPDmN7/3pAA4PTuCnzxVOd64EKBCxyfHh/I1SllgVAC5eMgcA8PCuPk9a4FhZqcOhPgTIpYynpjN5NfUXDp4q9r+Uxa7eXIAzMmWdDpWRESkFm5hqlREZmZrmc2baHQZ6vDSTTKNH8I3ZflReIPLcgVxJpn9kqojWyZ/1DYc0dGTLXnbKM+WWZthDyjwgbYdHmUcr2GmddasV04iES+wZrOTHSoB+wB1sXQR9LOD7zUvHcNej+/E3P9kiVcdwaiI3+ZodAqctfERCGhwbTS604SVyeGACH//JFvz8BedBAHuudGXN05zASmaPC0L6Az5MC5YBBSI2YQ+KzuzGadm+my5fIwIAl61oQywSwqGBibwHs1vYabPdRSDCfpYjpyYgHhz39nmfEdF1HbuO52dErAIxL6bvOoFlRF49OV4gWD2avS+aa6KosTnCm8ECkYlkOu+0u1tiRkTctMaTaWztGSp4DT+lSy7NALl29aM2DPyGyyzNsAfkq6Z24S2H5QTVQO5Bw8yxinXNlJrp05LNtAVSmnGx1uz389ttuUyIrIMLkCt/NddELctCTu3dRbiXSBHBav/IFN75rafxm5eO4TO/2Ia7Ht3n6Osfz2baO5uc783sfn5wR07n9OIheessE18CkbvuuguLFi1CVVUV1q1bh+eee86Pb+spR7MGY6y91irC98JHBABq4xG8brnRNvovD+wpO3XMAhE3GRGmCzGfCPadsNfp4ITjw1N5WZBURi8YZsU+Dsgz2zLTUhvjegZztuJY9iQ/r9n5iYZ1zRwfztdIeBF8FuN500Zlle6XPWdGZF6TsdEfsWHgl/NrcabFYbB72Xzv7ihz6GEpelkgMocFIkXEqqUyIgGUZlhJqclBJweDdeaJ/jCP25jZ5Bax68Rq1o1Te3cRFkAWs3m/84Hd6B/NZar+7aE92O3g/csC1U6HtgpALsMnZvQODkzgxKh/mTOvkB6I/PSnP8WnP/1p3HHHHXjxxRexZs0aXH311ejvLz2/QyUmk2nunrk023JYsn3Xg5PkJ65cjlgkhId29uHd337GtteCFSzt7SbqZiK6g9mUX0324bm3z/tA5OVs6WNVRz1/aIxYtMymeWnGv4Qey4qYyzNsbVmg4gSWETFT7jTgYkxNp/FK9vrZSc/KTI0Hej6sLwvg7JRmeJu0Qy0Og70v95veS16Jwq1gJ172QCs2fbfUvdwSQCDCsk9OzMwYHRYPVTvDI+2QSmfw5N4TeO7AID+gneKGYFHL6b+sa8ZdRoR5iRQGIocGxvHzzUcAAL+8+RJcdcZcTKd1fOeJV21//eNDLBBxvn8UcxfeXIFZEek7zVe/+lXcdNNNuPHGG3HmmWfiW9/6FmpqavD9739f9rd2xc7jI/jw3c/jLf/+JP5n0yEAwNEh4yasr4rw9rCSGpFI+SfJc+Y34l/ffS5qY2G8cOgUrv2PP+FVl1kItsnPd/GwZOUPdmBn49v7RxN8szo+PImfPn8Y928/njfgqxi6rmPbkSF898lX8dttx/i6vZwVg66e38h1AFbW1ikPDc3swjpntpkDkWxJoctNIBLLD0S6GqsQ0oCTYwmeaZlIpvDwzj48ve9kUR8TK0ampvH0vpN4/uAgP3VvOzKMVEZHW30cy9vrs1/fIhCxcUr3CnZP2pmtdDJ70nM6poDBNu4D2bZ45pq7u3eUB7cDYwncv70XLxwcdOR4e2xoEh/4/nNY9ve/x599/Un+u5qxNMPLYMXXmgUiA34GItlyR1O184yImHltq49D04wsH8vMJlMZvHJsGHv6nHklTSbT+MiPNuMvv/cc3v3tZ/CvDxmdT7nSTEzoJCm0eHdi785YILSYm393v3rxKHTd2BPXLmzGX712MQDgwR29tluXWWegVfA2E+a26osWtQAAXhRKjXv7RvH0/pM46YNnTjm4K7baJJlMYvPmzdiwYQP/WCgUwlVXXYVnnnmm4PWJRAKJRG7BRkbknFSe3n8SH//xFugANBhvlvnNNQB0PLr7BN+U/uHe7VjeXo/xrLhtfnMNVypb+4iU374r8pbVnThvQRNu+fGL2HJ4CF/+3U5874YLHX0NXdfLKh+YszvdzTWY2xBH30gC+/rHkExlcOPdz3Eb65AGrOxoQCxsDDQbm0ohldFRGzdU4fVVEfScmsizsL9yVTu+8f7z8dKRIQDA6vlNeP7gKQyMJ7mbpkjaJzGlSLGMyBEPMyLzW2owt7EKWw4P4cm9J7CsvQ4f+dFmno0LhzQsbatFNBxCOqNjajqNRCqDkKYhHg0hFg4hGg5hLJHiD1sAOKOzAf/1oYvw3IEBAMDaBc18wzYLNwF/A735NjMiuq7jJM+IuCvNmH0X1i5sxqYDA5icTuPgwDhePTGOj//kRX4vR8MalrbVIRzSkEhlsnbtaUwm04hHw2iuiWLRnFq01cfxu5ePczHt9qMj+LeH9uL2N63iI+S7Z9CIlLqXWSnKDwM2Rq4041ysKpomntfdhL7RBF7qGcLje06gs7EKt//yZf77roqG0NVUjVg4hFTGcG6eSKYwOZ3GdFpHU3UUZ3Y1YOXcemw6MMizpgDww6cP4ubLl/JMUVNNzNLGn5dmXNzP7fVxxCMhJFIZHBua5BkSXddxX3YK+zvOnw8AuHBRC1rr4jg5lsDT+0/i8pXtM3793jLEquaMyBvOnIvnDg7ihYODGJ2axmd+vg33v9LLP9/VWIWG6ihCmoapVBqJaWMeUCQcwrrFLfjnd61xfA1eITUQOXnyJNLpNObOnZv38blz52LXrkKzqo0bN+KLX/yizEsCYNRpxdPFwHgyry5/zVkdODGWwOZDp/DF37yC917YDcDYNEuNuZ72SKwq0tVUjX951xq88V+fwMO7+vH4nhP8JGeHgfEkpqYz0DR36T/zqbihOoqzuhrRN9KP/372EB7a0Yep6QwWzalBOKRh/4lx61S3qW5ZFQ1h7cJmPHdgEA/v6sddj+zjm8ya+U28RVOZjEg2EDlwchwjU9M8Y8OCvPkugrwqUyDSVhfHsvY6bDk8hH97aC/GEymMTKXQWhdHdSyEnsFJ7HFQEpvXVI2B8QR2Hh/B+7+7id/zV6xq40P8LEszEu7jotcoiFV1XS/a1TCaSPH3XJvLjIj552muieLc7iY8++ogPvuLbXipZwipjI55TdVIpDI4OZYoqtcZzwqMRR3Emu4mXLWqHf/y4B788OmDeNu5XdB1I6BhGgBzIJKxcVpnM4xO+ihWHZ503yot6h0Wt9ZiVUc9XuoZwmd/sY1/vCYWRkjTMJZIFYiHRQbGk3hy70k8ufckACMr/d0PXIDP/nIbDg1M4Ndbj3H32uaaKA/oRJF7pgyxaiikYUFLDfb2j+HQwAQPRNi/q6IhvPGsufzrv+HMdvzkuR48tW/mQCSVznDXVjf7hxiIaBpw5Rnt+PLvd+LFw0N4478+gePDU9A042sfOTWJY8NTODZs3SbPXI6DQmog4pQNGzbg05/+NP/3yMgIuru7Pf8+axc244+ffB1CmpG26x2ewpFTk5hIpnDxkjlYPb8Jp8aTWLfxYbxybAQ/yfZmL2ip4ekwK7GqVz4iZpa01eGGSxbhu386gC//bgdet/x1ttvQWOmgvT7uamKpefNuqIrgz8+fh0d29ePeLcaJ4PwFTfjxTRejKhpG7/AUth0ZQkjTUB0Loy4eQSSsYSKZxujUNIYnpzGnNo61C5tRG4/gt9uO4dYfb8G/P2KozWtjYazsqOdqfSsvEZbO9jMj0lwb42/o7UeHcclSo0TFRGxMdOmEcEhDLBLiD9g5dTFctrINX3t4L0/pX7CwGT/68DpUx8I4OjSJ/f1j0GE8uKqiIcQjYWT0XHYkndERCWs4s7MBc+riOHhyHO/81jPYne1yqo9H8NY1XVyHYlWamfZxfTsbq6FpyD74k0WDDNYxUhePFARwdjHf/w3VUXxg/SI8++ogr6u/5ZxOfO295yIc0nDk1CT29o8ipBm/p+poGNWxMKoiYUyl0hgYS2L/iTEcG5rCGZ31ePM5nYiGDV3XS0eG8d0nDwAw0u5xLqLU8wIuFpeUOq231xsP9v7RqZLBmpewh3uTi0BEnGe1qLUWly5txQ+ePsgzRm9Z3Yk737kG8UgIBwbGcWI0gWQqg2g4hOpYGDWxMKqjYUTDIfSPTuHlo8N45dgImmuieO+FC9DdUoN3X9CNf/7jbjyyq5/7iDTXxrirqyj+ZoGI29t54ZxsICIIVp/aZwRGFy5qyeuWu2hxC37yXA+es9EldHBgHIlUBtXRMC8BOUHMvDdVR7G4tRbnL2jCi4eHcHx4CvXxCP7rwxfhvAXNGJ6cxr7+UUwmM0jrOqoiIVRFw9A0455024nmFVK/e2trK8LhMPr68m2U+/r60NHRUfD6eDyOeNzdaccJdfFInpX3qo6Ggtc018bw5rM7cN/WY1yVfPnKNq5ILu0j4v1J8uNXLsd/bzqEPX1j2Hl8lJuezUQ5YkqgsHZdXxXFG8/s4CnIxuoovvbe8/jDoaOxCh2Nhb/bYrzlnE784Zxe/O5lw2Tr1tcbIl02/txKrBpERgQwsiJiIHJqPMlPqW5PFNXRMA9EWuviOHd+E647twu/2XYcqzrq8b0bLuRaknlN1Y5/j4taa/Gt95+Pj/xoMwbGk7jh0kWoiUW46NhaI+KPsypgBAdz66vQOzKFo0OTRQMRVuN2aqMvUhBUV0fx2mWtWDm3Hrv7RnHFyjb8y7vX8J+7u6WGl1SKwWYRiVx77jy8dGSYG3l1NlbnHU6S6Qwv8drRLzB/mqnpDEamUvy9IZORMrpmRI3Iwjk1WDCnBnffeBHu/ONuXH3WXHxg/SIeeC1tq+OdiJZfq7EKq7M+PiKvXd6Kf/7jbjy7f4CvbXNNDIlshk80MSunawYAFrDhd0K58+n9RpmTHUgYF2Z1Gq8cHcZEMlWypZ8dBlZ21LsqG8WFgLylNgZN0/CN69fi/d/bhOpoGP/0jtX8OdFYHcXahS2Ov4dfSA1EYrEY1q5di4cffhjXXXcdACCTyeDhhx/GrbfeKvNbe8IHL1mE+7bmeuHXL5mDP75iBFWWGpH0zMIztzRWR/GaZW14aGcfHtrZZz8QOcX0Ic4jbqCwc6KhOopYJIQf3HAhtvScwp+t7nI0I8GMpmn41/eci87GKoxOpfDh1yzm3wewLs2kfXxQipwzvxF/2N6Ll7Ki2r3Z7ot5TdWodeiKyKiOhvnPOKcuhlBIw7+99zx86e3nIB4JeVIeuWBRC579+ysxNpXiduEsELEqzaRtuH16ybzmaiMQOTWJc7ubLF+Ta911f1CJmkTkDVVRRMIh/PJjl2AikXLls2PFW9d04p/+sIvvB1ed0Z53OJlO62C3i26jbFAVDaOhKoKRqRROjE75EogM8a4Z599LnGfFShlrFzbjJ399sTcXB+CsrkY0VkeN907C2HNXzq3H9mPGe1O0HyqnawbITYlmWcVUOoNnX2WByJy8185rqkZnYxWOD09h6+EhXGIRqDKYgzIb6eEU8Z5i9vAdjVV48FP2M+aqIH0n//SnP43//M//xA9/+EPs3LkTN998M8bHx3HjjTfK/tZlc96CZvyft5wBALj58qWICAOgSolVZdXW33CmUXN8aKf9QV09p9zXIIHCoIqVTM6Z34gPrF9UVhDCiEVC+D9/dib+6Z2refqcaTCsxKpBZUTOX9AMAHjh4CB0XcferM398rnFT3QzIXbOiIK1unjE0/soGg7xIATI6VMsSzM+i4Hn8c6Z4l4iJ1zO8xGJm9aTPWTr4hHPghDAKKX8xboF/N/vvqA773c5bSGknOm5wa6vb0S+YFXXdR4cuxGrRsIhfO+DF+Br7z3XdSZ2JsIhDa8TtHLnLWhGdVZ3AuSXZtJ6eRmRs7KHvleOjUDXdbxybASjUynUV0VwdlY7xtA0DecvNPYJc4edGZYROaOzvuTriiGWGkUBd6UFIYAPGpH3vOc9OHHiBD7/+c+jt7cX5557Lu6///4CAauq/NVrl+Dac7u4d0FpsSpre5QTiFy2wghEth8dxlgiZWs2AeueWNzqrnRglRHxAza8ytpHxH+NCACc292EaFhD30gChwcnuJfKirnuNhIgvwVvkcvfkRtYytjaMM4/Z1XAnpcIa911OhhMpLA0I2/7u+2NKzAyNY2Ll8zh5Y1wSEM6o1uabc10L89tiGNf/5gvQ83GEil+XW6zL1eeIX9/v/HSRfhNtvzFMmlsHTMWpRm3+8XKjnqEQxoGx5PoHZnCU/sNfcjFS+ZYfs2zuxrxu23Hiw7JBIwM35+yOpNiWcCZEPcOLw6EQeLLTnPrrbfi0KFDSCQS2LRpE9atW+fHt/WM9voqfsOVEquyG77cWTPF6GiswvzmamR0+7bUTJG+xOVDzkrg5weshm4V8PntrMqoioaxJluv3nRgEHuyqVqWunXDqOAkK+v0aEWp0oyfzqqAPZt3ltkrZ43MInK3M2vsUF8VxVfffS7efUFObM+yi6L9uJ2uGUAQrPqQEWFC1XhW0Kgq5y9oxlVntCMS0vD28+YByAlSMxZiVbeBSFU0jOXZ9/j2oyN4JqsPudRUlmGcPS+XQbGif3QKn/rZS0imMlg9v5F35DmlNp773bhtaVcFmjXjEPZgTkxbPCDT7vvV7XLBQlYemDkQmZpOc8MctxmRLpMbq5vZE25gwZy53REIxlmVsW6JIfi6b8tR/js4z+WJBkDeCddNV5NbcqWZ4EtfLLgolREpN6AG8mvqQTxkrTwu2PNypj2DCVb9KM2UU5bxm7uuPx/PbLiS6yxY+UWcipETq7r/Pmd1GcHCY7v7selVY3Dka5Zb6z/Yaw9YzKZ64eAgrv7XJ7jT7M2XLXVdSrl+3UKct6AJACwFvZUEBSIO4Sf1Eg9ImRv42qwq246N76GBCei6ETy4Td3NN4lcax0OdnML27TNszmA4DQiAHDtGuPk9fT+ASTTGSxrr8PyMkozVj+fH5TummFDBf3ZHlhG5EjWS8SMruvcVXhxGX4HYkbEr8yeSMzinrb7kGQZkT4fSjPDZQhV/SYeCed1WnGNiOgj4sG07stWGnqU/9l0GMl0Bivm1mFZu/X7XpxN9VJPrjxz8OQ4PnT38zg1Mc1NBt90Tqfra+pqqsavbr4EL37uDbjqzMqQOhSDAhGH5DIiFqUZXf5JfU3WanyXjQmtB06yzbvOddRtPjXKzPaIRPimbZV5CkYjAhj14rXZrBQAvLmMjSRISpZmfC59MXv8sUTKUpx8amKaD0NcNMd9ICKKVYN4yFoNZLNbNmAPtkM+jHnPeYhUXrrfytCsXLEqYHQ+iU7Ibzmnq+Tr12fLNo/tzs1U+9eH9mBkKoXzFjTh3o9dkie2dYumaRWvDwEoEHEM04hYZUT8OKkva6+DphkuizPND2AunEvLFEHWxPyvE0dtlGaCyIgAwD+85Qy8dnkr3nxOBz6wfmFZX+v9FxvdFX//5lVeXJptSnXNcI2IT+tbE4vwGveRocLOGRZQdzVWlVVOETuU/CoxivDSjIvJsKyzYk/fmKP5LG4YmjQ6lBoroDRjht2y+YZm7HPu7+eaWARvO9cIPhbNqcH7LipttHnlKqOx4OFdRiByeGCCC2v/8W1nK629CQKlnFUrgXg0175rdjn0YwZKTSyCBS01ODQwgT19oyV9FZhl+lkuxVCM5poYJpIzDyXzEpbGTpUqzfjsI8I4f4HhduoFd7z1LLznggW8RdAvWHA5WcJZ1c/1nddcjYHxJI6emuQ1dsb+/mznV5k21KL52EGLaaqy4WJVi/bdmfaM7uYa1MbCGE+m8erJ8bI6tWaikkozZkKhQo2IF6UZAPjCtWfh/RcvxKqO+hnfG69d0YZoWMOBk+PYcWwEP3nuMDLZAXnmll+CMiKOiYeNDVzXC+v7fmkX2OTUPUXmYDDEabbl4HbaaTlELE6PjKAzIl4SDYdwzvxG30peDNa+O1ly1ox/18R0Ilbj1p/Yawj7zpnXVNb3aKmNYW5W9DnXQ98Qu0Qtyo26zdN6KKRhVVaQaTnLyUOGy7B3DxouVhV9RMoYeidSFQ3j7HmNtgL0ungEbzzTcJj+2P9sxk+fN8aE3Hz50rKuYbZCgYhDWEYEKHxIMn8L2Q+VlR1GK9me/uID0PpHptA7MoWQBpzp0rmP8X/ffjaqoiF8+g0ryvo6TihVmkl5dMI5nWH17lRGL2iRzgXU/m0P7B592eS9kEil8dhuIxC5+qzyBXn33XIprju3C//0jnPK/lpOsdKIONEvsPLMDsmBCNeIVGBpJmwhVs3Z6Pt7LTdeugiAkX1LpjO4aFEL1i+xbvk93aHSjEPEFsDEdDrPVMyvjAhLy5bKiDAb8mXtda7txxlndTXi5S9c7ZvBFSB2GMzujEhQiHqJyel0XutwEGLgc7Lth+ZA5P7tvRhLpNBeH+ceLuXQ2ViNf3vveWV/HTfEePuuldnWzP//GTwjUjoTWi6VXJph8VzG464ZN6xd2Ixbr1iGHz17CMva6/Dtv1xbka6nfkCBiENCIQ3RsIbptG6REfHnhmcD+3b3jRadxslmIYgdHuXgZxAC5Eoz1hqR4LpmZguxSAiRkIZURsdkMp330GEBtZ+lmdXzct4Lw5PTxhyRiWl86Xc7AQB/sW6B7+Urr7EqzTh5SLJAZEcRoyyvyIlVK68bgzurCluzF10zbtA0DX979Ur87dUrff2+lQiVZlzATjZmU7O0Tyntxa21CIc0jE6lihocsTHV5umQlYKVCyWDD70LwNBsNlFdxNTMz+m7jObaGLpbmPfCEABg4x924sRoAkvaavHRyyq/ts7aoVMZsX3X+K+dk/Kqjvpsx1yCTwGXwXC2hboSMyIyLN4J+dBO7oJYkcF3ft3w8UiYO6WyiZAiJ8cS2JUt25inQ1YKVqdHxjRtLJ5Qxb1EzBoRZmjm7/pessQImn//sjGn456swO8rf756VrQ75gay5T6WtmnxDhgCY+ajIlOwOjxhZEQqUazKljHP0KxMi3dCPhSIuIAZlom96oC/jp8rS+hEnsx2GZzR2VDWkLAgiZYozfDMk9/qs1lGNFQ4qVT8t98b99vPN1xrf7ftOP7v742SzNvO7cJFi1t8vQ5ZWJ3WneoXmGCVjbuXwVAFWbybYQGdrudMzVjg53dphrAPBSIuiFhsKIC/GzgbPW+VEXlop2Gi8/pV5Tv3BUWp0kzOgpw2lnIIs86kTJHMns8b90WLWrCgpQajiRSe3j8ATQM+/vrlvl6DTKwGsjnVL1yYHfHwx+293l5clmQqw03uKrE0I64jW+YMX+MgroiwAwUiLmCBRqpIRsSPQIRlRPaaApHpdAZPZNsd/RjFLYtSpRm/tDiznUiRzB4PRHzOOIVCGv7l3Wu4e/H/ecuZZU02Vg3LOSi8bGDva7x1TRfCIQ0vHRnGvn7vu2dYx4ymGROEKw1R0MzWNqiuGcI+tJO7gD3/Cjdw/07qKzpyls/iCevJvScwmkihtS6Ocyt4ImOp0kwqoAflbIPdp+Y1DiojAhgn/t/9zWvws4+sx4dfs9j37y+TXGkm9zH23rWbEWmti+OK7AC27z910NPrA4DhbMdMfTxSkQ9u8ZLZfRxU1wxhHwpEXMBOkkGWZha21CAWDmFyOo0jp3L267988SgA4K1rOiu63TEazmWdMkVO7FSaKY9wMY1IwOK+Ze31s0YXImLt+pn9nIO1vum1SwAAP3+hB0dOeWtVPzBmBCKVqi0LU0akIqFAxAXsfi52kvRDRBkJh7A0m7beky3PDIwl8OCOPgDAO86fL/0aZCKObBc1DLquk7OqR0SKaERofeUQsgj8Mg66ZhjrlszBJUvnYDqt465H93l6jQPjRiBSqRNdrTQiXlm8E/KgQMQFVup3ILeB+5UCXJkVrDLL5x88dRDJVAbnzGv0fYia10QF/Yc400fcxCkjUh68+8sUUGco4yQFdj7JWGhEnD4kP5Udt/DzF454mhVhgcicWRCI5Eozxr+DKDUS9qBAxAXF2nf9FlEy19Qn957AyNQ0fvjMQQDALVcsq3grYdHVUxx7LgqE6cReHpEZRNd0gvQWXpqxMNtyutQXLmrBJUvnIJXR8cOnD3p1iRjkpZnKDETEPUGn0kzFQIGIC8JFxKp+p7SvWNUOANh86BT+45F9GJ1KYXl7Hd54ZuV2yzDCIY2bE4ktvPkZEbp9yyFSRCPCN+4KD2ZVI1eayX3MTWmG8VevNcS89zzXg7FEaoZX22Ng3HBsnVNbmRoREqtWJrSTu4BPeCyWEfGpm2N+cw1WddQjowPfeeJVAMDHrlg6K06ymqbx8oxYmhFP72RoVh5WluNA8GLV2Uq4VEbExVpfvqIdS9pqMZpI4Rcv9HhyjZWuEdE0TRh8Z/zXyWBBIhjoV+MC3m0QYNcM46OXLeVvvCtXtePaNfN8+96y4Z0zRTIidGIvD1ZiLNq+S4GIp7AEXiZPrGr8181ah0IabrzUyIp8/6mDSKTSZV/jwFg2I1KhpRmgsASmU0ZEeWj6rgtyEx6Dbyu97rx56G6pwUs9Q/iLdQtm1cMjGgkByXSeqRk7vYc00jCUS7HSDAUicrA0NHOpEWG84/x5+LcH9+Dw4AQ+/dOXcN1587CvfwxvPGsulrY5N4Mb5GLVyizNAMYBJQ2dByJuWqQJf6GMiAvYhlIo8svkfd4v1i5sxodes3hWDAYTYRqQZKowlU36kPJRwSH4dMLqAFOufqEmFsGX3342AOB3Lx/HTf/1Av7p/l249ut/wjP7Bxx/PeYjUqmlGUAYfGfSiFAGVV1oN3dBsfZdGsbmLTELDQMrI9BDsnxY6Stt0ohQ+64cciWD3Me8yD5dc3Yn/uMvzsPrV7XjjM4G1MbCGE+mseFX2xyVa9IZHaeyk3dbK7g0w9aSbc/UNaM+VJpxQTFHSjpJegszNZu2aN+lh2T5hC3EwID/fjinC6VnzZS31n+2ugt/troLADCWSOGKOx/DwYEJ3PNcDz54ySJbX2NoIsmDpOYKzoiETM0E1DWjPpQRcYFVSjuT0XkETmUDb2DBRn5pxghKaM5M+RRt39UpsyeDsJVYNRtje+n7UxeP4G9evwwA8L0/HSj4/Rajf9QQqrbUxvisp0qExXTpAh+RoK6ImAn61biAt+EJb3Ay2vIePvguY5URoVu3XIpqRNJ0gpSBpaGZJP3CO9bOR2N1FIcHJ/DY7n5b/w8LRNrrK1eoCuREqToXq5JBn+rQbu4Cq/ZdcXOhsoE3xKxKM2kqzXhFLiNi0ojoFOzJwNLQTNJpvSYWwZ+fb7Ty/27bcVv/T//IFACgrcIDkZzPk/FvEquqD+00LrDSiFBGxHtYRsSqa4bWuHwi4SIZEX6C9P2SZjWWhmYS9QtvOrsTAPDgzj4kU5kZXi1mRKo8vxY/CZmaCUisqj601bjAaoqmODiMbnhvYCd2S7Eq6RfKJlLE0Iws3uXAtoX8oXfGf2XsGWsXNqO1Lo7RqRSeOzA44+tPsECkobIzIlwjkl1ctsaVPn9rNkOBiAusRH6ijoE2cG9gpRlxbSkj4h3FNCJpEqtKweoAk5HYoRQOaXjd8lYAwLOvzuwp0j9qlGYqXSPC9l8W71FpRn0oEHFByZkR5PjpGaw0M50qDPhII1I+xTQiJFaVg9ezZuywbkkLAGDTARuByMjsKM1opjZp6ppRH/rVuCBkcZKkbg7v4e27FmLVMK1z2RTTiJBYVQ5cuyDEfbJP6+sWzwEAvNQzjKnp0uZmTCMyt8JLM2bDSeqaUR/aaVwQ4RsKiShlwgzNrIbeUUakfIoNvSOxqhysDM10Xe5pfeGcGsxtiCOZzuDFw6eKvk7XdaE0U9kZEa7FIYv3ioG2GhdYteFRIOI9MVaaSVtknki/UDaRIhqRDGX3pGBlaMb2DVlCSk3TeFbk2VeLC1YHx5OYmjY2tLmNlZ0RMWtxqGtGfWincUGuT72wm4Nudu+wKs2kSSPiGeFiGhGqqUvB2tDM+K/M0zrXiZQQrB4dmgRgCFXjkcoenmme6cPWmDRP6kJbjQusDM2oZOA9udJMYUaEAr7ymSkjQjocb8mVZnIf8+O0fvESIyOypWeoqE7k6CkjEJnXXC3tOvzCLAqmjIj60E7jgrBFaYZ1c9DN7h250oyVRoRu3XKJZNe36PBGOkF6SthCW8YeljKFlEtaa9FaF0cylcFLPUOWrznCApGmyg9EzIZmJFZVH9rNXWCV0qaMiPdYGpql6XTjFTwjYhKrcnEf6XA8xfyABPLb/mWhaRouzpZniulEWGlmfnONvAvxiUJDM/lrTJQHBSIusM6I0ObtNWwt0xbiPgr4yidnaGaaNUMZESmYH5BA7iEpe63XZcszxfxEjsym0gwfemf82681JtxDgYgLrIyJaPP2HraWooZhmkpgnmHlEAxQ+64sgjA0Y6zPZkQ2HzqFyWShToRnRGZBaYYbmmWoNFMp0FbjAiurZhJRek+kRCqb2nfLx8riXdQvkA7HW3KlmdzHZM6aEVnaVod5TdVIpDJ4at/JvM9lMjoODYwDALpbKr80w7YGrhHxoTOJKA9pO82Xv/xlXHLJJaipqUFTU5OsbxMIVid1ElF6j6WDbZrW2SuYhb5VVxJAG7fXhLTCA4xf+gVN03DVGe0AgId29uV97ujQJCaSacTCISyaU/mBiLlNmrpm1Efabp5MJvGud70LN998s6xvERjsNJ6hjIhUSjnYkkakfKw0ImL2ifRO3sINzSzFqvLX+g1ndgAAHtzRl+dWvLd/FACwpK2Wd1JVMmbDSSrNqE9E1hf+4he/CAC4++67ZX2LwLCyauZGW7R5ewa3IKeATwrWU6QpIyILK0MzP0/r65a0oKU2hoHxJJ7aP4DLVrQBAPb0jQEAls+tl34NfhAqKM2Qfk91lAp/E4kERkZG8v6oCDs0pC1KBvSA9A6rdaaAzzusNCLiWtO97C1WpZm07l9GJBoO4c9WdwIAfr3lKP/4nj4jI7KivU76NfiBeeid7Hk+RPko9avZuHEjGhsb+Z/u7u6gL8kSdlIPog3vdMJqnSkj4h2REu3RAK2x1+QMzXIfY8vtl/34287tAgD88ZVe3j2z45hx4FvRMVsyIiaNSHaNZc3zIcrHUSBy++23Q9O0kn927drl+mI2bNiA4eFh/qenp8f115IJO4yLpRl6QHoPX2cSq0qBraE4VFBca7qVvSXo0gwAnL+gGfObqzGeTOOhnX0YGEtgV6+REblgYbMv1yCbXOYJ2f/6l3Ui3OFII3LbbbfhhhtuKPmaJUuWuL6YeDyOeFz9yY/c0MxiA6eSgXeELSzIKeDzjpxGpFCsGg5pdIL0mJDFASbtc9lA0zS87dwu3PXofvzyxSP84byqox5z6tTfe+1ApZnKw1Eg0tbWhra2NlnXUjHwkoFeeFKnQWHeYTWUjabveoeVRoQCPXlYzZoJ4rT+rrXd+MZj+/H4nhMYnUoByA3Gmw1wsSozNMvu0xRYq4u0rpnDhw9jcHAQhw8fRjqdxtatWwEAy5YtQ11dZYuieBsetZVKxcqJMkWZJ8+w0oiQQ7A8rAzN2K3tZ+C3qLUWl69ow6O7T2DzoVMAgDed3eHb95dNrgRm/Jsl/OieVhdpgcjnP/95/PCHP+T/Pu+88wAAjz76KC6//HJZ39YX2I1OJ0m5lOrqoMxT+fD2aAtDM7qPvceyayYg/cLfXr0SLx0ZxuB4Eu+9sJvPopkNmO0VMj52JhHukBaI3H333bPSQwQQDM0sfEQo6vYOqynHKco8eUau9FU4RZoCEe+xnDXDHpI+r/dZXY149LbL8WLPKbx2Wauv31s2uaF3NH23UpAWiMxmSp1syI3SO3KBiLDO5NfiGaXad2l9vSdk4awaZCmssSaKK1a2+/59ZcOWkt3LvEWa7mllofy2C6wekHRS955Szp+0zuVjLQamQEQWJWfN0E7sGeb9ORNQ+YuwD93+LrB6QNIG7j3WU46zJTBa57Lh3V8WbehUYvSesEmsquu674ZmpwNsLVniKUPtu8pDvxoXWM2aoZO691BGRC5sDadFjYhOAbUsijl+AhT4eYl5f6b2XfWhQMQFpfwAaAP3jpBV6YBpROh4UzakEfEXbmjG/C1EF1tab88wTzlmcTZlndSFdnMXlDKCopvdO0plRKK0cZdNqfZoyjh5j/kAI4pWKfDzDp55ypicVWlvVhYKRFxgJVbN0AbuOZZdM6QR8Qw2a0bXBRdKFlDT+npOgdGWEIjQcnuH2TguV5oJ6oqImaBAxAUq+QHMZsKltDjUJl02YjDHdCKUEZFHgXYhb8AgrbdXmEtgbJnp8KIuFIi4wEq7QNbY3lNaw0C3brlEhWCO6xbIhVIaBaWZTOHniPIJ864Zat+tFGg3d0GExKq+YOW7QF0z3iHeqylemqHSlyzMIkox00cHGO/QTJknclZVHwpEXMD9LSzHedPd7hVMw5AXiKTpQekVESGrxLqR0mxAGK2v52imwFos7VIc4h05bZnxb3JWVR8KRFzANSJCapUyIt5DXR1yEZcwpxGhQE8WYbNYNZM7qZPHhXewW5dKM5UDBSIuyD0gC4eF0c3uHVZ+LTmxKt265aJpmrDGxscoIyKPnLNqfmmG1tpbzI7MGWrfVR7azV1gTv0Boo0w3exeQRkR+Zg7k1I0RVoa5mFsdHiRgznzRO276kOBiAvMJxuASjMyKJURoXX2Bj4R1nR6pPZo7zHvG2z7oHvZW4pZ6ZNGRF0oEHEBP6mnxdKM8V863XhHqemwlBHxhrBJQEn3sTwK15oyIjIImQI+slZQHwpEXGBO/Rl/pwek11g5q9L0XW8xd4AxsSrdx96jFSkZ0FJ7S6GhGa2z6lAg4gLrByQ5q3pN2PSQBHJtphEyNPMEc/mLZ0ToPvYcMXjOZPTcSZ3W2lMKupOoNKM8tJu7oNSsGSqte4e4zqwVb5o2b08xi1UpIyIPsTSQ1nWyHpdESAiuRX0ZlcDUhQIRF1ie1OkB6Tnixs3T2TRrxlPMrY409E4emrDbZnSdrzV5iHiLKFalwYKVAQUiLrCyHqehd94TFoINpg1hAmE6sXuD2ZwvRcI+aeQF1hnyt5AF14joet5hkfZmdaFAxAURU61X/C89IL0jf52N/+a6ZujW9QJzdo9E1/IQs6VpISNCWVRvEXVPQhxCpRmFod3cBWJkzYeF0dRSzxHXkmdE2OZNpRlPYPEceyiS6Foe4tYglg0opvYWsTtJLM1Q5kld6C3ggjz1u55fW6fTjXeIp3KzhoFO7N4QNps/0fpKI780IwQi9ID0lLBYmhHK57TM6kKBiAtKPSApEPGOsGmddV0nZ1WPKRSr5n+c8A7z/czn+tAT0lPYOutCZxJAAZ/KUCDigvySAbkkykLTtDxzIvF0Qyd2b8iJVal9VzaaqQuMOpTkoAnNBGL7Lh1e1IUCEReYjYkAGnonCyZKTQvZEIDW2SvMYlXSOslFnDdDXTNyyK0xqH23QqBAxAXiDZ0mjYhUmJAvlTZnROjW9QJzK3qKNCJSEefNsIckxSHewm7dTEbPm7xLfi3qQru5C8SSAU9pM5dEutk9hWdEMvkZETI08wbzRFiyHZcL2x4y1L4rDdHQjCVEKMOnNhSIuERM/wG52jptKt6SZ04klmZoY/GEnFjV+DeJgeWS87igcq4seJZPJ9O4SoECEZdwQRQvzRgfJ+GZt0TCYkbEWOSQRuvsFbzVMUMZET8QZ/vwPYMekp4iGprlbPSDvCJiJigQcYm52yA39I7ueC8RB9+Rq6r3mEsz3NCM7mMphCzEqhTzeYtY/qLSTGVAO7pLzBN405RmlYIo7kulaY29xixWJYt3uYjaMso+ycHq8EJrrDYUiLhE1C4AlNKWhbipUEeH95gzIuRtIRexXZpapeXADi+6oBGhJVYbCkRcwjZqXTdnRAK7pFkJ27hTGT0nCKaOGc8wZ/Yo2JML7+jIUMu/LET9HtO30xqrDT02XZIrGRj/ZmUDOt14S4QyIlIpKM3Qw1EqVq2ltNbeYmUaR/uy2lAg4hLzjA5qxZNDXmkmTWJVrykmVqX7WA5W+gUy2vKWPB0OCYIrAtrRXWKeWkqzZuRAwjO5hEyZPQqo5cJi6IygEaFKo7fkOpNoX64UKBBxibm2zrsNaFfxFFHcx0sztMaewTRN7KFInUlyEUszVAaTg1hupPbdyoACEZeIveqAIDyjG95TcgFfhjIiEhDNnwByopSNqC3L0ENSCmK2mvaMyoACEZdQ26M/8K6ZdM5ZlcSq3lFs6B1t3HIQDc2ofVcOIeGQSO27lQEFIi4xd81QRkQOEWHjzpUN6Lb1imIBNQUiciBDM/mIjQSUdaoMaEd3iblrhpxV5cA2kFSexTutsVeEizir0n0sh5DgcUFZVDmELAzN6H5WGwpEXGLumslWDeiG9xgmTM3zESGxqmeEBDEwQGJV2YhTuzPUNSMFUYDNsk6UEFEbaYHIwYMH8eEPfxiLFy9GdXU1li5dijvuuAPJZFLWt/SVArEqRd5SEDUMadKIeE7B8EYSq0olJKw3mW3JQexMStP9XBFEZH3hXbt2IZPJ4Nvf/jaWLVuG7du346abbsL4+DjuvPNOWd/WNwqG3lG/uhSsnFUp2POOXInR+DetsVzEki5bcyrNeItoo0/tu5WBtEDkmmuuwTXXXMP/vWTJEuzevRvf/OY3Z1UgIvoBiB8nvIEJU9N5GhGqKHqF2UeEBJRyCQuZVMo+ycHK4p2WWG2kBSJWDA8Po6WlpejnE4kEEokE//fIyIgfl+UK0ZEyJQYidMd7CntQpjI66RckYC7NUEZELiELjwvKiHgL24LJjbly8O1ouW/fPnz961/HRz7ykaKv2bhxIxobG/mf7u5uvy7PMVZRN5CzcCa8gWU/xI2bNCLeYRar0sYtF7EURnNQ5CAKgqk0Uxk4fmzefvvt0DSt5J9du3bl/T9Hjx7FNddcg3e961246aabin7tDRs2YHh4mP/p6elx/hP5hOgHkBYyIlQ28Ba2cU+ndUxnxar0kPQOc0aEAhG5iN12VAaTA2WdKg/HpZnbbrsNN9xwQ8nXLFmyhP/92LFjuOKKK3DJJZfgO9/5Tsn/Lx6PIx6PO72kQMjzA6CMiDS4oZmoEaF+R88oEF2TbkEqVkPv6LTuLWKnHWWdKgPHgUhbWxva2tpsvfbo0aO44oorsHbtWvzgBz9AaBY9pcUNPEMaEWmwQCSV0RFOk1jVa4qVZijYk0N+O7rxMcqIeIuVxTsFe2ojTax69OhRXH755Vi4cCHuvPNOnDhxgn+uo6ND1rf1DVEjkqauGWnkDM0ySGeMv5NGxDvEjBNAbeiyydcvUGlGBuIgR7Y10wFRbaQFIg8++CD27duHffv2Yf78+Xmf04VSRqUi9qqzzVvTAI1ueE8JixkRqql7jlhiBKh9VzaioZm4bxDekdOIgNp3KwRpOe4bbrgBuq5b/pkNsH1a1IjQSd17Ink+IllnVSobeEZY6OIAqH1XNlbaMjqte4tYbiTxdWXgq4/IbCJsIaKkdLb3UEZELmFTaYaGhMklLIhVKfskBxbYGQdf42O0N6sNBSIuEU82NPBOHlysms7wDYbEqt5hLs3wwYJ0L0shf9ZM/scIb+DZaip/VQwUiLgkLyNCKVZpUEZELvyETmJVX8ibNUMdHVIICYJgyvBVBnS0dIl4s5NpjjwiYQuNCK2zZ5gzIjTPRy5hUUjJA+sgr2j2IQZ2FFhXBpQRcUm+HwBF3bKIWGRESKzqHUWnSNPDUQqixwUdYOQgZqanKRCpCGi7cUnYYkOhQMR7+IMyLa4z3bZeIfrhAJQRkY1YmiGPCzlowq2byraD0dasNpQRcUn+hkIaEVlYZkRoV/EMMbMH5Eo0FIfIIWzhcUGndW8R92E2sZvWWG1ou3FJWPQDoIyINHJi1QzSaVpnrxF9RDKZXLsjZUTkQAPZ5CPuDzQoszKg3cYl7MbWdTpFykTMiFBrqfeI02DF4Y2U3ZODVdcMSZ68Rbx1WUaEbme1oUenSzQhpc3V73S3ew7vmknrSNHpxnPyHozCzCQKquXAOmTy9g26nz0lvzRDe0YlQBoRl4gbCtliy4M0InIRnT7FQIRKM3JgpRldmAxL86m8JURdMxUH7TYuEVPadLKRR07DIGhEyHjBM/La0HXKiMgmb9YMOTJLQdTc5LpmaI1VhrYbl5BDoj8wzxBRIxKljdszRB8RFugBlBGRRZ44mLrtpMG2iGneNRPgxRAzQruNS8Q2POqakQfzDEmlc86qtM7eUUysSkssB7auOnXNSEXstgPokKg6FIi4JGfxrtM8A4lEhBM775qhNgPPsBKrhkMa6RYkYeU/RNuG97D7l/uI0CIrDQUiLhFr62SaI488HxFyVvWcnB+OkNmj+1gaov8QHWDkwdaZSjOVAe3oLslrw9Opm0MW0bBFRoTW2TPypkhTiVE6ua4ZGsgmE3YLU8t/ZUDtuy7Jq61n1e+U/vMerhHJ6AiTJ4DnFCvNEHLIK81Q14w02DpTtroyoIyIS0SNSJrU79KIWDwoKSPiHVZiVXowysOqNEMPSe9h9/B09vBCS6w2lBFxSU4jAvIRkUhOIyIYmpGPiGeEhBIjZUTkk9c1Q2JVabD9OUW6p4qAdnSXWNXWqTTjPdxZNZ2hjIgErIY30gldHvmlGQr8ZBHS8jMitDerDQUiLglZbOD0gPQeMSNCVvreYxVQ030sD9HQLDcsk9bba7hYlTQiFQEFIi7hMzrIWVUqzOGTNCJy4Cd0nUozfiCWZrhYlfYNzxEdgwEqf6kOBSIuCeV1zdADUhb5Fu/UNeM1XKyaAWWcfCBEYlVf4KUZclatCCgQcUnIygiKNnDPyeuaSbOAj25brxBPjmSwJZ+82T5cWxbkFc1O2JqSRqQyoLeAS8TaOp0k5REWxKrTtM6eI57QWT2d1lceeYZm1PYvDd41Q86qFQEFIi6xUr9TacZ7IoKhGS+B0awZzxADapoGKx/qmvGHsKlrhu5ptaFAxCVi2yNlROQRFjUi5KzqOXxUAYlVfSHf0Mz4GA0Y9J6QWaxK97TSUCDikvxx3sYDkk7q3iNqRJLZQCRGhmaeIQ5vpEBEPuzW1SnwkwpbUjb0jmI9tSFnVZeIEXcqQ+p3WYiBiJ4tHcQiFIh4BQ298xdNCPyoFCaPnLMqlWYqAdrRXWI1Pp00It4jdsiwVDZlRLwjRCVGX7HaN6hrxnsKxap0T6sMvQVcYn2SpOX0mrBFuYsyIt6Ru49BJ3QfYOutCxoRekh6j3noHWlE1IZ2dJdYjU8njYj3WGWZKBDxDu5rQRkRX2AxB/m2yIVbvJOzakVAO7pL2I2doQ1cKlZrSiUw78g32KKuJNlYGppRRsRzQqaMCO0ZakOBiEu4NTZZvEvFXCaIRULU7ughUaGcmExRICKbsGBoRj4i8shN36WyeSVAvx2X5HfN0DwDWYRCWl5aNU5CVU8RNTgUiMhHy/MRIU2OLMxrSodEtaFd3SXUNeMfESH4IH2It4j37NQ0pbFlk1ea0cnjQhbmNaXgWm1oV3eJZdcMiVWlID4Yo5QR8RRxbSen0wBojWUiGpplE6n0kJSAeU2pkUBtaMdxCYu4RbEqnSTlIG4qlBHxFnFtE6l0wccIbxFLM2nqmpGGeU1pjdWGdnWXWKnfSRAlhwgFItLQNI3fy7w0Q6dHafCSruDbQtoy7zEL2umQqDa0q7tE7Jrh7bt0r0tBDPDIVdV72CbNSzMUUEtDLOnq3NAswAuapZj3Yjokqg39dlySZ2jGWsToISkFyojIJcIzIkYgQhkRebCD+jQTiIDKBjIwZ5koI6I2tKu7hJ9sdPBaL93schAfjJQR8R52Lyeoa0Y6Ye5vkQtEyH7ce8xrSsGe2kjd1a+99losWLAAVVVV6OzsxF/+5V/i2LFjMr+lb4jOqjS1VC6UEZEL65LJZURojWXB9gg2jA0gHxEZmLdiCq7VRuqOc8UVV+BnP/sZdu/ejV/+8pfYv38/3vnOd8r8lr7Bp5ZmqGtGNtQ1IxcuVk1RaUY2msnxEyCxqgyoa6ayiMj84p/61Kf43xcuXIjbb78d1113HaanpxGNRmV+a+nk+4iQI6VMIiRWlUrE1DVDYlV5mKfCAgAtt/cUdM1QcK00UgMRkcHBQfzP//wPLrnkkqJBSCKRQCKR4P8eGRnx6/IcExL8AFJpKs3IRFzXKGVEPIeVYiaT5CMiGyuNCJVmvMe8ptQ1ozbSfzt/93d/h9raWsyZMweHDx/Gr3/966Kv3bhxIxobG/mf7u5u2ZfnGlGsmiGxqlRIrCoXdt8yQ7MonR6lwZ6PeRoR2jc8p8BZldZYaRzv6rfffjs0TSv5Z9euXfz1n/nMZ7BlyxY88MADCIfD+MAHPgBd1y2/9oYNGzA8PMz/9PT0uP/JJMMyIhlBI0JRtxxIIyKXQkMzWmNZsLVOChkRmibtPTRrprJwXJq57bbbcMMNN5R8zZIlS/jfW1tb0draihUrVuCMM85Ad3c3nn32Waxfv77g/4vH44jH404vKRDYXp0WumYo6paDqFmIUyDiORFz1wzdx9IgEaU/0PTdysJxINLW1oa2tjZX3yyTFXWKOpBKJa9rhjQiUolGKCMikwJDM7qPpWFeWtKHyMHciUR7s9pIE6tu2rQJzz//PF7zmtegubkZ+/fvx+c+9zksXbrUMhtSaVhO36WbXQpNNTH+d9IveE+ufZdKM7KhB6Q/mA3NIlQ2Vxppv52amhr86le/wpVXXomVK1fiwx/+MFavXo3HH3+8YsovpeAaER1IUfuuVFqEQCQWDgd4JbMTFtyxgJqCPXnQeHp/KMg80TorjbSMyDnnnINHHnlE1pcPHD5rRteR3b8ppS2J5lohEKHSjOcUdhjQGsuCZqD4A3XNVBa047iE3diGsyplRGTSUpPznaFAxHvMgQed0uVRUDKgMpgUqARWWdC7wCV5gUiadc3QcsogLyNCD0nPMQcedB/LwyxOjdIDUgqUeaosaMdxiXiSYd0GtH/LoYVKM1Ixb9KUEZFHwTA2yohIoUAjQoGI0tC7wCWioI8bQVEkIoXmGgpEZGLepEmsKo/C0gyttQxI91RZ0G/HJeKNzaaWUtQtBzEjEqUTpOeYT+XkECwPMtryB3PAR3uz2tCO4xLx1KhT14xUxIxIMpUp8UrCDeb7lnQL8ijULtAWLIOCEhjd00pD7wKXaJpWcHNT1C2H6ljOO2QskQrwSmYnhd4WtC3Iwhx3UBlMDmLmSdMKMySEWtCOUwbm+i4FIvJhpluEd0Spfdc3KOjzB3GQIGVD1IfeBWVQsIHTDS+NW69YhhVz6/COtfODvpRZh9l1ku5jeZC/hT+I60prrD7SnFVPBygj4h9/e/VK/O3VK4O+jFlJQfsu6RakYQ5EqDQjB/GWpvtZfeg3VAbmtCrd8EQlYr5v6eEoD2or9YcQZUQqCnoXlIG5u4AGKxGVSIGzKukWpGF+JlLQJwexbE6lRvWhHacMCjMidMMTlQcNCPMPTdOgUdlAOlXR3LpSRkR96F1QBuaTpLn+SxCVgDmzR10zchFbSymLKod4NNfyT4G1+lAgUgbUNUPMBsxOqnRKl4t4YCHzODlUCYEIBXvqQztOGYgnRzLNISoVcwaEdAtyEeM80uPIoSoiakRojVWHfkNlIG4ilA0hKhVyCPYXsTRDQZ8cxIwI3c7qQ4FIGcSETYQ2b6JSKZy+S9uCTMTSDO0bcqjK04jQ/aw69BsqA/EGN0/VJIhKodDQjO5lmYglXHpIyoG6ZioLeheUQYQyIsQsIGzKgNC9LBcx40SlGTnkZURojZWHApEyEDcUEp0RlUo074Su5Q0MI7xHPK3TviGHqojQNUOBtfLQu6AMImQjTMwCxHuXTo/yEU/r1L4rh7zSDAXWykOBSBlEqWuGmAWIwYfZG4fwnnz9Aq23DERDMz3A6yDsQe+CMhA3cHJVJSoVUTBJGRH5iGUDWm85iMFeKp0J8EoIO1AgUga0gROzgfwSI20JsolHSawqm5iQrZ5OU05EdWjXKYModc0QswDx3qUHo3zyMiIU+ElBFFynMpQRUR16F5SBmAUhjQhRqeR3f9F9LBtqLfWXFGVElIcCkTLIMzSjkw1RoeRlROg+lo5YmqGMiHymKSOiPPQuKINYhLpmiMqH2tD9hTIi/kIZEfWhQKQMaAMnZgMRMubzlXiExKp+QmJV9aFdpwzETbsuHgnwSgjCPWIQ3dEQD/BKTg/EjAiVdOVDYlX1oXdBGYiuiPVVFIgQlc8713YHfQmzHrFrhpxV5UOlGfWhQKQMKCNCzAY6G6v4399w5twAr+T0gGbN+Ms0GZopDz09y0Cs79ZXRQO8EoJwT1dTNX7x0fVor6/KE2ATchA1IiRWlU8qQxkR1aFApAxEsWodlWaICuaCRS1BX8JpQ/7QOwr8ZJOmQER56F1QBmJatYECEYIgbJAvVqWMCEFQIFIGYmmGNCIEQdihimbN+EpLbSzoSyBmgAKRMhBdEUkjQhCEHeJ5hma0BcviVx+7BOsWt+C/PnRR0JdCzAAd48tAFJqRRoQgCDvEyZHZF85f0IyffmR90JdB2IDC8TIQR02TjwhBEHYgi3eCyIcCkTIQ06r1pBEhCMIGoqEZDb0jCApEyiJCPiIEQTiExKoEkQ8FImWQFqyDSSNCEIQdSKxKEPn48i5IJBI499xzoWkatm7d6se39IXJ6TT/e20sXOKVBEEQBlWCWJW0qgThUyDy2c9+Fl1dXX58K1+ZEgIRTaMdhSCImREzIuT6SRA+BCJ/+MMf8MADD+DOO++U/a18Z1FrbdCXQBBEhVEtBCJzauMBXglBqIFUYUNfXx9uuukm3HfffaipqZnx9YlEAolEgv97ZGRE5uWVzYWLWvDVd6/Bsva6oC+FIIgKIRzS8MyG1yOV1lFNJV2CkJcR0XUdN9xwAz760Y/iggsusPX/bNy4EY2NjfxPd3e3rMvzjD8/fz5Wz28K+jIIgqggOhur0d0y8+GMIE4HHAcit99+OzRNK/ln165d+PrXv47R0VFs2LDB9tfesGEDhoeH+Z+enh6nl0cQBEEQRAWh6bruSC114sQJDAwMlHzNkiVL8O53vxu/+c1v8kSc6XQa4XAY119/PX74wx/O+L1GRkbQ2NiI4eFhNDQ0OLlMgiAIgiACwsnz23EgYpfDhw/naTyOHTuGq6++Gr/4xS+wbt06zJ8/f8avQYEIQRAEQVQeTp7f0sSqCxYsyPt3XZ0h6Fy6dKmtIIQgCIIgiNkP2foRBEEQBBEYvvmSL1q0CJKqQARBEARBVCiUESEIgiAIIjAoECEIgiAIIjAoECEIgiAIIjAoECEIgiAIIjAoECEIgiAIIjAoECEIgiAIIjAoECEIgiAIIjB88xFxA/MdEa3iCYIgCIJQG/bctuMfpnQgMjo6CgDo7u4O+EoIgiAIgnDK6OgoGhsbS75G2tA7L8hkMjh27Bjq6+vzpvh6wcjICLq7u9HT00MD9SRC6+wPtM7+QWvtD7TO/iFjrXVdx+joKLq6uhAKlVaBKJ0RCYVC0gfkNTQ00E3uA7TO/kDr7B+01v5A6+wfXq/1TJkQBolVCYIgCIIIDApECIIgCIIIjNM2EInH47jjjjsQj8eDvpRZDa2zP9A6+wettT/QOvtH0GuttFiVIAiCIIjZzWmbESEIgiAIIngoECEIgiAIIjAoECEIgiAIIjAoECEIgiAIIjBOy0DkrrvuwqJFi1BVVYV169bhueeeC/qSKo4nnngCb33rW9HV1QVN03DfffflfV7XdXz+859HZ2cnqqurcdVVV2Hv3r15rxkcHMT111+PhoYGNDU14cMf/jDGxsZ8/CnUZuPGjbjwwgtRX1+P9vZ2XHfdddi9e3fea6ampnDLLbdgzpw5qKurwzve8Q709fXlvebw4cN4y1vegpqaGrS3t+Mzn/kMUqmUnz+K8nzzm9/E6tWruaHT+vXr8Yc//IF/ntZZDl/5ylegaRo++clP8o/RWnvDF77wBWialvdn1apV/PNKrbN+mnHPPffosVhM//73v6+/8sor+k033aQ3NTXpfX19QV9aRfH73/9e/4d/+Af9V7/6lQ5Av/fee/M+/5WvfEVvbGzU77vvPv2ll17Sr732Wn3x4sX65OQkf80111yjr1mzRn/22Wf1J598Ul+2bJn+vve9z+efRF2uvvpq/Qc/+IG+fft2fevWrfqb3/xmfcGCBfrY2Bh/zUc/+lG9u7tbf/jhh/UXXnhBv/jii/VLLrmEfz6VSulnn322ftVVV+lbtmzRf//73+utra36hg0bgviRlOV///d/9d/97nf6nj179N27d+t///d/r0ejUX379u26rtM6y+C5557TFy1apK9evVr/xCc+wT9Oa+0Nd9xxh37WWWfpx48f539OnDjBP6/SOp92gchFF12k33LLLfzf6XRa7+rq0jdu3BjgVVU25kAkk8noHR0d+j//8z/zjw0NDenxeFz/yU9+ouu6ru/YsUMHoD///PP8NX/4wx90TdP0o0eP+nbtlUR/f78OQH/88cd1XTfWNBqN6j//+c/5a3bu3KkD0J955hld142AMRQK6b29vfw13/zmN/WGhgY9kUj4+wNUGM3Nzfp3v/tdWmcJjI6O6suXL9cffPBB/bLLLuOBCK21d9xxxx36mjVrLD+n2jqfVqWZZDKJzZs346qrruIfC4VCuOqqq/DMM88EeGWziwMHDqC3tzdvnRsbG7Fu3Tq+zs888wyamppwwQUX8NdcddVVCIVC2LRpk+/XXAkMDw8DAFpaWgAAmzdvxvT0dN46r1q1CgsWLMhb53POOQdz587lr7n66qsxMjKCV155xcerrxzS6TTuuecejI+PY/369bTOErjlllvwlre8JW9NAbqnvWbv3r3o6urCkiVLcP311+Pw4cMA1FtnpYfeec3JkyeRTqfzFhYA5s6di127dgV0VbOP3t5eALBcZ/a53t5etLe3530+EomgpaWFv4bIkclk8MlPfhKXXnopzj77bADGGsZiMTQ1NeW91rzOVr8H9jkix8svv4z169djamoKdXV1uPfee3HmmWdi69attM4ecs899+DFF1/E888/X/A5uqe9Y926dbj77ruxcuVKHD9+HF/84hfx2te+Ftu3b1dunU+rQIQgKpVbbrkF27dvx5/+9KegL2XWsnLlSmzduhXDw8P4xS9+gQ9+8IN4/PHHg76sWUVPTw8+8YlP4MEHH0RVVVXQlzOredOb3sT/vnr1aqxbtw4LFy7Ez372M1RXVwd4ZYWcVqWZ1tZWhMPhAmVwX18fOjo6Arqq2Qdby1Lr3NHRgf7+/rzPp1IpDA4O0u/CxK233orf/va3ePTRRzF//nz+8Y6ODiSTSQwNDeW93rzOVr8H9jkiRywWw7Jly7B27Vps3LgRa9aswde+9jVaZw/ZvHkz+vv7cf755yMSiSASieDxxx/Hv//7vyMSiWDu3Lm01pJoamrCihUrsG/fPuXu6dMqEInFYli7di0efvhh/rFMJoOHH34Y69evD/DKZheLFy9GR0dH3jqPjIxg06ZNfJ3Xr1+PoaEhbN68mb/mkUceQSaTwbp163y/ZhXRdR233nor7r33XjzyyCNYvHhx3ufXrl2LaDSat867d+/G4cOH89b55Zdfzgv6HnzwQTQ0NODMM8/05wepUDKZDBKJBK2zh1x55ZV4+eWXsXXrVv7nggsuwPXXX8//Tmsth7GxMezfvx+dnZ3q3dOeSl8rgHvuuUePx+P63Xffre/YsUP/67/+a72pqSlPGUzMzOjoqL5lyxZ9y5YtOgD9q1/9qr5lyxb90KFDuq4b7btNTU36r3/9a33btm362972Nsv23fPOO0/ftGmT/qc//Ulfvnw5te8K3HzzzXpjY6P+2GOP5bXgTUxM8Nd89KMf1RcsWKA/8sgj+gsvvKCvX79eX79+Pf88a8F74xvfqG/dulW///779ba2Nmp1NHH77bfrjz/+uH7gwAF927Zt+u23365rmqY/8MADuq7TOstE7JrRdVprr7jtttv0xx57TD9w4ID+1FNP6VdddZXe2tqq9/f367qu1jqfdoGIruv617/+dX3BggV6LBbTL7roIv3ZZ58N+pIqjkcffVQHUPDngx/8oK7rRgvv5z73OX3u3Ll6PB7Xr7zySn337t15X2NgYEB/3/vep9fV1ekNDQ36jTfeqI+Ojgbw06iJ1foC0H/wgx/w10xOTuof+9jH9ObmZr2mpkZ/+9vfrh8/fjzv6xw8eFB/05vepFdXV+utra36bbfdpk9PT/v806jNhz70IX3hwoV6LBbT29ra9CuvvJIHIbpO6ywTcyBCa+0N73nPe/TOzk49Fovp8+bN09/znvfo+/bt459XaZ01Xdd1b3MsBEEQBEEQ9jitNCIEQRAEQagFBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQQGBSIEQRAEQQTG/w8cT7utS50EXAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4C97S-PeeXd"
      },
      "outputs": [],
      "source": [
        "# from numpy import savetxt\n",
        "# savetxt('train_data_check.csv', train_dataset_1[:,48:92], delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjRHNe1ckRoy"
      },
      "outputs": [],
      "source": [
        "### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "### 0:48- IMU, 48:92-2D body coordinate, 92:97-- Target\n",
        "\n",
        "\n",
        "### Data Processing\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "val_targets = torch.Tensor(Y_validation)\n",
        "test_features = torch.Tensor(test_X_1D)\n",
        "test_targets = torch.Tensor(test_y)\n",
        "\n",
        "\n",
        "## all Modality Features\n",
        "\n",
        "train_features = torch.Tensor(train_X_1D)\n",
        "train_targets = torch.Tensor(train_y_5)\n",
        "val_features = torch.Tensor(X_validation_1D)\n",
        "\n",
        "\n",
        "train_features_acc_8=torch.cat((train_features[:,:,0:3],train_features[:,:,6:9],train_features[:,:,12:15],train_features[:,:,18:21],train_features[:,:,24:27]\\\n",
        "                             ,train_features[:,:,30:33],train_features[:,:,36:39],train_features[:,:,42:45]),axis=-1)\n",
        "test_features_acc_8=torch.cat((test_features[:,:,0:3],test_features[:,:,6:9],test_features[:,:,12:15],test_features[:,:,18:21],test_features[:,:,24:27]\\\n",
        "                             ,test_features[:,:,30:33],test_features[:,:,36:39],test_features[:,:,42:45]),axis=-1)\n",
        "val_features_acc_8=torch.cat((val_features[:,:,0:3],val_features[:,:,6:9],val_features[:,:,12:15],val_features[:,:,18:21],val_features[:,:,24:27]\\\n",
        "                             ,val_features[:,:,30:33],val_features[:,:,36:39],val_features[:,:,42:45]),axis=-1)\n",
        "\n",
        "\n",
        "train_features_gyr_8=torch.cat((train_features[:,:,3:6],train_features[:,:,9:12],train_features[:,:,15:18],train_features[:,:,21:24],train_features[:,:,27:30]\\\n",
        "                             ,train_features[:,:,33:36],train_features[:,:,39:42],train_features[:,:,45:48]),axis=-1)\n",
        "test_features_gyr_8=torch.cat((test_features[:,:,3:6],test_features[:,:,9:12],test_features[:,:,15:18],test_features[:,:,21:24],test_features[:,:,27:30]\\\n",
        "                             ,test_features[:,:,33:36],test_features[:,:,39:42],test_features[:,:,45:48]),axis=-1)\n",
        "val_features_gyr_8=torch.cat((val_features[:,:,3:6],val_features[:,:,9:12],val_features[:,:,15:18],val_features[:,:,21:24],val_features[:,:,27:30]\\\n",
        "                             ,val_features[:,:,33:36],val_features[:,:,39:42],val_features[:,:,45:48]),axis=-1)\n",
        "\n",
        "\n",
        "train_features_2D_point=train_features[:,:,48:92]\n",
        "test_features_2D_point=test_features[:,:,48:92]\n",
        "val_features_2D_point=val_features[:,:,48:92]\n",
        "\n",
        "\n",
        "train_features_2D_velocity=train_features[:,:,92:136]\n",
        "test_features_2D_velocity=test_features[:,:,92:136]\n",
        "val_features_2D_velocity=val_features[:,:,92:136]\n",
        "\n",
        "\n",
        "train_features_2D_acceleration=train_features[:,:,136:180]\n",
        "test_features_2D_acceleration=test_features[:,:,136:180]\n",
        "val_features_2D_acceleration=val_features[:,:,136:180]\n",
        "\n",
        "\n",
        "train = TensorDataset(train_features, train_features_acc_8,train_features_gyr_8, train_features_2D_point,train_features_2D_velocity,train_features_2D_acceleration, train_targets)\n",
        "val = TensorDataset(val_features, val_features_acc_8, val_features_gyr_8, val_features_2D_point, val_features_2D_velocity, val_features_2D_acceleration, val_targets)\n",
        "test = TensorDataset(test_features, test_features_acc_8, test_features_gyr_8, test_features_2D_point,test_features_2D_velocity,test_features_2D_acceleration, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP_eDnJwrKCC"
      },
      "source": [
        "# Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdVunLKprSkv"
      },
      "outputs": [],
      "source": [
        "def RMSE_prediction(yhat_4,test_y,s):\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,5))\n",
        "  yhat=yhat_4.reshape((s1,5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "  # y_6_no=yhat[:,5]\n",
        "  # y_7_no=yhat[:,6]\n",
        "  #y_8_no=yhat[:,7]\n",
        "  #y_9_no=yhat[:,8]\n",
        "  #y_10_no=yhat[:,9]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  y_4=y_4_no\n",
        "  y_5=y_5_no\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "  # y_test_6=test_o[:,5]\n",
        "  # y_test_7=test_o[:,6]\n",
        "  #y_test_8=test_o[:,7]\n",
        "  #y_test_9=test_o[:,8]\n",
        "  #y_test_10=test_o[:,9]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #print(y_1.shape,y_test_1.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  Z_1=y_1\n",
        "  Z_2=y_2\n",
        "  Z_3=y_3\n",
        "  Z_4=y_4\n",
        "  Z_5=y_5\n",
        "  # Z_6=y_6\n",
        "  # Z_7=y_7\n",
        "  #Z_8=y_8\n",
        "  #Z_9=y_9\n",
        "  #Z_10=y_10\n",
        "\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "  # rmse_6 =((np.sqrt(mean_squared_error(y_test_6,y_6)))/(max(y_test_6)-min(y_test_6)))*100\n",
        "  # rmse_7 =((np.sqrt(mean_squared_error(y_test_7,y_7)))/(max(y_test_7)-min(y_test_7)))*100\n",
        "  #rmse_8 =((np.sqrt(mean_squared_error(y_test_8,y_8)))/(max(y_test_8)-min(y_test_8)))*100\n",
        "  #rmse_9 =((np.sqrt(mean_squared_error(y_test_9,y_9)))/(max(y_test_9)-min(y_test_9)))*100\n",
        "  #rmse_10 =((np.sqrt(mean_squared_error(y_test_10,y_10)))/(max(y_test_10)-min(y_test_10)))*100\n",
        "\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "  # print(rmse_6)\n",
        "  # print(rmse_7)\n",
        "  #print(rmse_8)\n",
        "  #print(rmse_9)\n",
        "  #print(rmse_10)\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "  # p_6=np.corrcoef(y_6, y_test_6)[0, 1]\n",
        "  # p_7=np.corrcoef(y_7, y_test_7)[0, 1]\n",
        "  #p_8=np.corrcoef(y_8, y_test_8)[0, 1]\n",
        "  #p_9=np.corrcoef(y_9, y_test_9)[0, 1]\n",
        "  #p_10=np.corrcoef(y_10, y_test_10)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "  # print(p_6)\n",
        "  # print(p_7)\n",
        "  #print(p_8)\n",
        "  #print(p_9)\n",
        "  #print(p_10)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "\n",
        "  return rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "def RMSE_prediction_WN(yhat_4,test_y,s):\n",
        "\n",
        "  test_o=test_y.reshape((s,5))\n",
        "  yhat=yhat_4.reshape((s,5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "  # y_6_no=yhat[:,5]\n",
        "  # y_7_no=yhat[:,6]\n",
        "  #y_8_no=yhat[:,7]\n",
        "  #y_9_no=yhat[:,8]\n",
        "  #y_10_no=yhat[:,9]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "  # y_test_6=test_o[:,5]\n",
        "  # y_test_7=test_o[:,6]\n",
        "  #y_test_8=test_o[:,7]\n",
        "  #y_test_9=test_o[:,8]\n",
        "  #y_test_10=test_o[:,9]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #print(y_1.shape,y_test_1.shape)\n",
        "\n",
        "\n",
        "\n",
        "  cutoff=6\n",
        "  fs=200\n",
        "  order=4\n",
        "\n",
        "  nyq = 0.5 * fs\n",
        "  ## filtering data ##\n",
        "  def butter_lowpass_filter(data, cutoff, fs, order):\n",
        "      normal_cutoff = cutoff / nyq\n",
        "      # Get the filter coefficients\n",
        "      b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "      y = filtfilt(b, a, data)\n",
        "      return y\n",
        "\n",
        "\n",
        "\n",
        "  y_1=butter_lowpass_filter(y_1_no, cutoff, fs, order)\n",
        "  y_2=butter_lowpass_filter(y_2_no, cutoff, fs, order)\n",
        "  y_3=butter_lowpass_filter(y_3_no, cutoff, fs, order)\n",
        "  y_4=butter_lowpass_filter(y_4_no, cutoff, fs, order)\n",
        "  y_5=butter_lowpass_filter(y_5_no, cutoff, fs, order)\n",
        "  # y_6=butter_lowpass_filter(y_6_no, cutoff, fs, order)\n",
        "  # y_7=butter_lowpass_filter(y_7_no, cutoff, fs, order)\n",
        "  #y_8=butter_lowpass_filter(y_8_no, cutoff, fs, order)\n",
        "  #y_9=butter_lowpass_filter(y_9_no, cutoff, fs, order)\n",
        "  #y_10=butter_lowpass_filter(y_10_no, cutoff, fs, order)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  Z_1=y_1\n",
        "  Z_2=y_2\n",
        "  Z_3=y_3\n",
        "  Z_4=y_4\n",
        "  Z_5=y_5\n",
        "  # Z_6=y_6\n",
        "  # Z_7=y_7\n",
        "  #Z_8=y_8\n",
        "  #Z_9=y_9\n",
        "  #Z_10=y_10\n",
        "\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =np.sqrt(mean_squared_error(y_test_1,y_1))\n",
        "  rmse_2 =np.sqrt(mean_squared_error(y_test_2,y_2))\n",
        "  rmse_3 =np.sqrt(mean_squared_error(y_test_3,y_3))\n",
        "  rmse_4 =np.sqrt(mean_squared_error(y_test_4,y_4))\n",
        "  rmse_5 =np.sqrt(mean_squared_error(y_test_5,y_5))\n",
        "  # rmse_6 =((np.sqrt(mean_squared_error(y_test_6,y_6)))/(max(y_test_6)-min(y_test_6)))*100\n",
        "  # rmse_7 =((np.sqrt(mean_squared_error(y_test_7,y_7)))/(max(y_test_7)-min(y_test_7)))*100\n",
        "  #rmse_8 =((np.sqrt(mean_squared_error(y_test_8,y_8)))/(max(y_test_8)-min(y_test_8)))*100\n",
        "  #rmse_9 =((np.sqrt(mean_squared_error(y_test_9,y_9)))/(max(y_test_9)-min(y_test_9)))*100\n",
        "  #rmse_10 =((np.sqrt(mean_squared_error(y_test_10,y_10)))/(max(y_test_10)-min(y_test_10)))*100\n",
        "\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "  # print(rmse_6)\n",
        "  # print(rmse_7)\n",
        "  #print(rmse_8)\n",
        "  #print(rmse_9)\n",
        "  #print(rmse_10)\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "  # p_6=np.corrcoef(y_6, y_test_6)[0, 1]\n",
        "  # p_7=np.corrcoef(y_7, y_test_7)[0, 1]\n",
        "  #p_8=np.corrcoef(y_8, y_test_8)[0, 1]\n",
        "  #p_9=np.corrcoef(y_9, y_test_9)[0, 1]\n",
        "  #p_10=np.corrcoef(y_10, y_test_10)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "  # print(p_6)\n",
        "  # print(p_7)\n",
        "  #print(p_8)\n",
        "  #print(p_9)\n",
        "  #print(p_10)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "\n",
        "  return rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "def PCC_prediction(yhat_4,test_y,s):\n",
        "\n",
        "  test_o=test_y.reshape((s,5))\n",
        "  yhat=yhat_4.reshape((s,5))\n",
        "\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "  # y_6_no=yhat[:,5]\n",
        "  # y_7_no=yhat[:,6]\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "  # y_test_6=test_o[:,5]\n",
        "  # y_test_7=test_o[:,6]\n",
        "\n",
        "\n",
        "\n",
        "  cutoff=6\n",
        "  fs=200\n",
        "  order=4\n",
        "\n",
        "  nyq = 0.5 * fs\n",
        "  ## filtering data ##\n",
        "  def butter_lowpass_filter(data, cutoff, fs, order):\n",
        "      normal_cutoff = cutoff / nyq\n",
        "      # Get the filter coefficients\n",
        "      b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "      y = filtfilt(b, a, data)\n",
        "      return y\n",
        "\n",
        "\n",
        "\n",
        "  y_1=butter_lowpass_filter(y_1_no, cutoff, fs, order)\n",
        "  y_2=butter_lowpass_filter(y_2_no, cutoff, fs, order)\n",
        "  y_3=butter_lowpass_filter(y_3_no, cutoff, fs, order)\n",
        "  y_4=butter_lowpass_filter(y_4_no, cutoff, fs, order)\n",
        "  y_5=butter_lowpass_filter(y_5_no, cutoff, fs, order)\n",
        "  # y_6=butter_lowpass_filter(y_6_no, cutoff, fs, order)\n",
        "  # y_7=butter_lowpass_filter(y_7_no, cutoff, fs, order)\n",
        "\n",
        "\n",
        "  Y_1=y_1\n",
        "  Y_2=y_2\n",
        "  Y_3=y_3\n",
        "  Y_4=y_4\n",
        "  Y_5=y_5\n",
        "  # Y_6=y_6\n",
        "  # Y_7=y_7\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "  # rmse_6 =((np.sqrt(mean_squared_error(y_test_6,y_6)))/(max(y_test_6)-min(y_test_6)))*100\n",
        "  # rmse_7 =((np.sqrt(mean_squared_error(y_test_7,y_7)))/(max(y_test_7)-min(y_test_7)))*100\n",
        "\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "  # print(rmse_6)\n",
        "  # print(rmse_7)\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "  # p_6=np.corrcoef(y_6, y_test_6)[0, 1]\n",
        "  # p_7=np.corrcoef(y_7, y_test_7)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "  # print(p_6)\n",
        "  # print(p_7)\n",
        "\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "  return rmse, p, Y_1,Y_2,Y_3,Y_4,Y_5\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "def estimate_coef(x, y):\n",
        "    # number of observations/points\n",
        "    n = np.size(x)\n",
        "\n",
        "    # mean of x and y vector\n",
        "    m_x = np.mean(x)\n",
        "    m_y = np.mean(y)\n",
        "\n",
        "    # calculating cross-deviation and deviation about x\n",
        "    SS_xy = np.sum(y*x) - n*m_y*m_x\n",
        "    SS_xx = np.sum(x*x) - n*m_x*m_x\n",
        "\n",
        "    # calculating regression coefficients\n",
        "    b_1 = SS_xy / SS_xx\n",
        "    b_0 = m_y - b_1*m_x\n",
        "\n",
        "    return (b_0, b_1)\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "def DLR_prediction(yhat_4,test_y,s,Y_1,Y_2,Y_3,Y_4,Y_5,Z_1,Z_2,Z_3,Z_4,Z_5):\n",
        "\n",
        "  a_1,b_1=estimate_coef(Y_1,Z_1)\n",
        "  a_2,b_2=estimate_coef(Y_2,Z_2)\n",
        "  a_3,b_3=estimate_coef(Y_3,Z_3)\n",
        "  a_4,b_4=estimate_coef(Y_4,Z_4)\n",
        "  a_5,b_5=estimate_coef(Y_5,Z_5)\n",
        "\n",
        "  #### All 16 angles prediction  ####\n",
        "\n",
        "\n",
        "  test_o=test_y.reshape((s,5))\n",
        "  yhat=yhat_4.reshape((s,5))\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "  # y_6_no=yhat[:,5]\n",
        "  # y_7_no=yhat[:,6]\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "  # y_test_6=test_o[:,5]\n",
        "  # y_test_7=test_o[:,6]\n",
        "\n",
        "\n",
        "  cutoff=6\n",
        "  fs=200\n",
        "  order=4\n",
        "\n",
        "  nyq = 0.5 * fs\n",
        "  ## filtering data ##\n",
        "  def butter_lowpass_filter(data, cutoff, fs, order):\n",
        "      normal_cutoff = cutoff / nyq\n",
        "      # Get the filter coefficients\n",
        "      b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "      y = filtfilt(b, a, data)\n",
        "      return y\n",
        "\n",
        "\n",
        "\n",
        "  y_1=butter_lowpass_filter(y_1_no, cutoff, fs, order)\n",
        "  y_2=butter_lowpass_filter(y_2_no, cutoff, fs, order)\n",
        "  y_3=butter_lowpass_filter(y_3_no, cutoff, fs, order)\n",
        "  y_4=butter_lowpass_filter(y_4_no, cutoff, fs, order)\n",
        "  y_5=butter_lowpass_filter(y_5_no, cutoff, fs, order)\n",
        "  # y_6=butter_lowpass_filter(y_6_no, cutoff, fs, order)\n",
        "  # y_7=butter_lowpass_filter(y_7_no, cutoff, fs, order)\n",
        "\n",
        "\n",
        "\n",
        "  y_1=y_1*b_1+a_1\n",
        "  y_2=y_2*b_2+a_2\n",
        "  y_3=y_3*b_3+a_3\n",
        "  y_4=y_4*b_4+a_4\n",
        "  y_5=y_5*b_5+a_5\n",
        "  # y_6=y_6*b_6+a_6\n",
        "  # y_7=y_7*b_7+a_7\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "  # rmse_6 =((np.sqrt(mean_squared_error(y_test_6,y_6)))/(max(y_test_6)-min(y_test_6)))*100\n",
        "  # rmse_7 =((np.sqrt(mean_squared_error(y_test_7,y_7)))/(max(y_test_7)-min(y_test_7)))*100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "  # print(rmse_6)\n",
        "  # print(rmse_7)\n",
        "\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "  # p_6=np.corrcoef(y_6, y_test_6)[0, 1]\n",
        "  # p_7=np.corrcoef(y_7, y_test_7)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "  # print(p_6)\n",
        "  # print(p_7)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5])\n",
        "\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "  return rmse, p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5Q-cJ2tK8Vb"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        mse = nn.MSELoss()(pred, target)\n",
        "        rmse = torch.sqrt(mse)\n",
        "        return rmse\n"
      ],
      "metadata": {
        "id": "wVzTJJzbjfn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HtJVDh1mEB-"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIGFafmhdP5O"
      },
      "outputs": [],
      "source": [
        "def train_IMU_early(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    # criterion =nn.MSELoss()\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    # criterion=PearsonCorrLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    # optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data[:,:,0:48].to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data[:,:,0:48].to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCrgBUvih7OD"
      },
      "outputs": [],
      "source": [
        "def train_2D_early(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_2D_vel_acc_early(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data[:,:,48:180].to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data[:,:,48:180].to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lqKHbCaVjJbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mm_IMU(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    # criterion =nn.MSELoss()\n",
        "    criterion =RMSELoss()\n",
        "    # criterion =PearsonCorrCoefLoss()\n",
        "\n",
        "    # criterion=PearsonCorrLoss()\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "D3_Dr1-cvCOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAtfy-YimaWR"
      },
      "outputs": [],
      "source": [
        "def train_mm_2D_vel_acc(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    # criterion =nn.MSELoss()\n",
        "    criterion =RMSELoss()\n",
        "    # criterion =PearsonCorrCoefLoss()\n",
        "\n",
        "    # criterion=PearsonCorrLoss()\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output,x= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output,x= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early Fusion"
      ],
      "metadata": {
        "id": "JU11NXkGUqCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Early Fusion--IMU only"
      ],
      "metadata": {
        "id": "m2_enhIBjamV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "b5etKK2QjewU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MM_early(nn.Module):\n",
        "\n",
        "    def __init__(self, input, drop_prob=0.20):\n",
        "        super(MM_early, self).__init__()\n",
        "        self.encoder_input=Encoder(input,drop_prob)\n",
        "        self.fc = nn.Linear(128, 5)\n",
        "        self.BN= nn.BatchNorm1d(input, affine=False)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "\n",
        "        input_x_1=input_x.view(input_x.size(0)*input_x.size(1),input_x.size(-1))\n",
        "        input_x_1=self.BN(input_x_1)\n",
        "        input_x_2=input_x_1.view(-1, 50, input_x_1.size(-1))\n",
        "        out=self.encoder_input(input_x_2)\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "B_Fk_K6ljjK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = MM_early(48)\n",
        "\n",
        "mm_early = train_IMU_early(train_loader, lr,40,model,path + encoder + '_early_IMU.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sEfjRAQjkQT",
        "outputId": "77000d67-ada5-45a0-b0ad-899e9cde1fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 4.6476, Training Loss: 0.3316,  Validation loss: 0.2214\n",
            "Epoch: 2, time: 4.2676, Training Loss: 0.2202,  Validation loss: 0.1901\n",
            "Epoch: 3, time: 4.1802, Training Loss: 0.1993,  Validation loss: 0.1685\n",
            "Epoch: 4, time: 4.6138, Training Loss: 0.1898,  Validation loss: 0.1649\n",
            "Epoch: 5, time: 3.5559, Training Loss: 0.1793,  Validation loss: 0.1626\n",
            "Epoch: 6, time: 3.7714, Training Loss: 0.1736,  Validation loss: 0.1611\n",
            "Epoch: 7, time: 3.1521, Training Loss: 0.1703,  Validation loss: 0.1578\n",
            "Epoch: 8, time: 3.1316, Training Loss: 0.1656,  Validation loss: 0.1464\n",
            "Epoch: 9, time: 2.9670, Training Loss: 0.1611,  Validation loss: 0.1413\n",
            "Epoch: 10, time: 2.9760, Training Loss: 0.1590,  Validation loss: 0.1494\n",
            "Epoch: 11, time: 3.2499, Training Loss: 0.1564,  Validation loss: 0.1428\n",
            "Epoch: 12, time: 3.1783, Training Loss: 0.1537,  Validation loss: 0.1542\n",
            "Epoch: 13, time: 2.9698, Training Loss: 0.1523,  Validation loss: 0.1431\n",
            "Epoch: 14, time: 2.9735, Training Loss: 0.1486,  Validation loss: 0.1372\n",
            "Epoch: 15, time: 3.0031, Training Loss: 0.1466,  Validation loss: 0.1386\n",
            "Epoch: 16, time: 3.4496, Training Loss: 0.1464,  Validation loss: 0.1334\n",
            "Epoch: 17, time: 3.0559, Training Loss: 0.1447,  Validation loss: 0.1328\n",
            "Epoch: 18, time: 2.9997, Training Loss: 0.1425,  Validation loss: 0.1300\n",
            "Epoch: 19, time: 2.9664, Training Loss: 0.1407,  Validation loss: 0.1339\n",
            "Epoch: 20, time: 3.4167, Training Loss: 0.1411,  Validation loss: 0.1310\n",
            "Epoch: 21, time: 3.0467, Training Loss: 0.1387,  Validation loss: 0.1317\n",
            "Epoch: 22, time: 2.9496, Training Loss: 0.1379,  Validation loss: 0.1335\n",
            "Epoch: 23, time: 2.9552, Training Loss: 0.1372,  Validation loss: 0.1305\n",
            "Epoch: 24, time: 3.1935, Training Loss: 0.1349,  Validation loss: 0.1276\n",
            "Epoch: 25, time: 3.0631, Training Loss: 0.1336,  Validation loss: 0.1404\n",
            "Epoch: 26, time: 3.3067, Training Loss: 0.1329,  Validation loss: 0.1310\n",
            "Epoch: 27, time: 2.9838, Training Loss: 0.1319,  Validation loss: 0.1314\n",
            "Epoch: 28, time: 3.2399, Training Loss: 0.1312,  Validation loss: 0.1281\n",
            "Epoch: 29, time: 3.2318, Training Loss: 0.1293,  Validation loss: 0.1282\n",
            "Epoch: 30, time: 2.9891, Training Loss: 0.1293,  Validation loss: 0.1257\n",
            "Epoch: 31, time: 3.0078, Training Loss: 0.1280,  Validation loss: 0.1258\n",
            "Epoch: 32, time: 3.0326, Training Loss: 0.1280,  Validation loss: 0.1334\n",
            "Epoch: 33, time: 3.2074, Training Loss: 0.1279,  Validation loss: 0.1273\n",
            "Epoch: 34, time: 3.2516, Training Loss: 0.1261,  Validation loss: 0.1280\n",
            "Epoch: 35, time: 3.1087, Training Loss: 0.1264,  Validation loss: 0.1239\n",
            "Epoch: 36, time: 3.4633, Training Loss: 0.1251,  Validation loss: 0.1287\n",
            "Epoch: 37, time: 3.1724, Training Loss: 0.1244,  Validation loss: 0.1263\n",
            "Epoch: 38, time: 2.9972, Training Loss: 0.1239,  Validation loss: 0.1258\n",
            "Epoch: 39, time: 3.0294, Training Loss: 0.1234,  Validation loss: 0.1270\n",
            "Epoch: 40, time: 3.0369, Training Loss: 0.1225,  Validation loss: 0.1285\n",
            "Training time: 130.9141125679016 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early= MM_early(48)\n",
        "mm_early.load_state_dict(torch.load(path+encoder+'_early_IMU.pth'))\n",
        "mm_early.to(device)\n",
        "\n",
        "mm_early.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early(data[:,:,0:48].to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_1=np.hstack([rmse,p])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CEvSUR1jlfO",
        "outputId": "51a32771-062d-4353-d8bd-1f0385ece867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "9.227001667022705\n",
            "4.317132383584976\n",
            "5.177011713385582\n",
            "3.3717934042215347\n",
            "4.869215190410614\n",
            "\n",
            "\n",
            "0.8417110674337875\n",
            "0.9331497338188166\n",
            "0.9523043355273396\n",
            "0.9942950850027459\n",
            "0.9628427396436953\n",
            "Mean: 5.392 +/- 2.251\n",
            "Mean: 0.937 +/- 0.058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Early Fusion--2D point only"
      ],
      "metadata": {
        "id": "TbKi4_MDkS0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "n78guVL0kS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MM_early(nn.Module):\n",
        "\n",
        "    def __init__(self, input, drop_prob=0.35):\n",
        "        super(MM_early, self).__init__()\n",
        "        self.encoder_input=Encoder(input,drop_prob)\n",
        "        self.fc = nn.Linear(128, 5)\n",
        "        self.BN= nn.BatchNorm1d(input, affine=False)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "\n",
        "        input_x_1=input_x.view(input_x.size(0)*input_x.size(1),input_x.size(-1))\n",
        "        input_x_1=self.BN(input_x_1)\n",
        "        input_x_2=input_x_1.view(-1, 50, input_x_1.size(-1))\n",
        "        out=self.encoder_input(input_x_2)\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "El1oSRzwkS0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = MM_early(44)\n",
        "\n",
        "mm_early = train_2D_early(train_loader, lr,40,model,path + encoder + '_early_2D.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458e0464-14f7-4274-824d-80c136108347",
        "id": "Kb0Zs7n6kS0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 4.1128, Training Loss: 0.4290,  Validation loss: 0.3167\n",
            "Epoch: 2, time: 3.8325, Training Loss: 0.3234,  Validation loss: 0.2830\n",
            "Epoch: 3, time: 4.8303, Training Loss: 0.2980,  Validation loss: 0.2644\n",
            "Epoch: 4, time: 3.1590, Training Loss: 0.2870,  Validation loss: 0.2488\n",
            "Epoch: 5, time: 3.1031, Training Loss: 0.2729,  Validation loss: 0.2486\n",
            "Epoch: 6, time: 3.1310, Training Loss: 0.2673,  Validation loss: 0.2409\n",
            "Epoch: 7, time: 3.3934, Training Loss: 0.2611,  Validation loss: 0.2334\n",
            "Epoch: 8, time: 3.0811, Training Loss: 0.2561,  Validation loss: 0.2287\n",
            "Epoch: 9, time: 3.1321, Training Loss: 0.2522,  Validation loss: 0.2197\n",
            "Epoch: 10, time: 3.0241, Training Loss: 0.2462,  Validation loss: 0.2168\n",
            "Epoch: 11, time: 3.0278, Training Loss: 0.2424,  Validation loss: 0.2285\n",
            "Epoch: 12, time: 3.0104, Training Loss: 0.2407,  Validation loss: 0.2224\n",
            "Epoch: 13, time: 2.9416, Training Loss: 0.2363,  Validation loss: 0.2192\n",
            "Epoch: 14, time: 2.9498, Training Loss: 0.2347,  Validation loss: 0.2194\n",
            "Epoch: 15, time: 3.0410, Training Loss: 0.2307,  Validation loss: 0.2115\n",
            "Epoch: 16, time: 3.0215, Training Loss: 0.2289,  Validation loss: 0.2092\n",
            "Epoch: 17, time: 2.9607, Training Loss: 0.2263,  Validation loss: 0.2106\n",
            "Epoch: 18, time: 2.9371, Training Loss: 0.2253,  Validation loss: 0.2135\n",
            "Epoch: 19, time: 2.9470, Training Loss: 0.2226,  Validation loss: 0.2079\n",
            "Epoch: 20, time: 3.0036, Training Loss: 0.2220,  Validation loss: 0.2049\n",
            "Epoch: 21, time: 2.9170, Training Loss: 0.2193,  Validation loss: 0.2112\n",
            "Epoch: 22, time: 2.9189, Training Loss: 0.2168,  Validation loss: 0.2055\n",
            "Epoch: 23, time: 2.9359, Training Loss: 0.2152,  Validation loss: 0.2008\n",
            "Epoch: 24, time: 3.0283, Training Loss: 0.2150,  Validation loss: 0.2018\n",
            "Epoch: 25, time: 2.9220, Training Loss: 0.2138,  Validation loss: 0.2009\n",
            "Epoch: 26, time: 2.9048, Training Loss: 0.2122,  Validation loss: 0.2050\n",
            "Epoch: 27, time: 2.9094, Training Loss: 0.2102,  Validation loss: 0.2081\n",
            "Epoch: 28, time: 2.9731, Training Loss: 0.2095,  Validation loss: 0.2025\n",
            "Epoch: 29, time: 2.9243, Training Loss: 0.2074,  Validation loss: 0.2010\n",
            "Epoch: 30, time: 2.8971, Training Loss: 0.2078,  Validation loss: 0.2003\n",
            "Epoch: 31, time: 2.9217, Training Loss: 0.2059,  Validation loss: 0.2019\n",
            "Epoch: 32, time: 3.3507, Training Loss: 0.2055,  Validation loss: 0.2011\n",
            "Epoch: 33, time: 3.0364, Training Loss: 0.2034,  Validation loss: 0.2012\n",
            "Epoch: 34, time: 2.9200, Training Loss: 0.2031,  Validation loss: 0.2011\n",
            "Epoch: 35, time: 2.9179, Training Loss: 0.2026,  Validation loss: 0.2015\n",
            "Epoch: 36, time: 2.9464, Training Loss: 0.2009,  Validation loss: 0.2010\n",
            "Epoch: 37, time: 3.0310, Training Loss: 0.2002,  Validation loss: 0.2005\n",
            "Epoch: 38, time: 2.9280, Training Loss: 0.1987,  Validation loss: 0.1994\n",
            "Epoch: 39, time: 2.9292, Training Loss: 0.1998,  Validation loss: 0.1992\n",
            "Epoch: 40, time: 2.9267, Training Loss: 0.1970,  Validation loss: 0.1961\n",
            "Training time: 124.00057911872864 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early= MM_early(44)\n",
        "mm_early.load_state_dict(torch.load(path+encoder+'_early_2D.pth'))\n",
        "mm_early.to(device)\n",
        "\n",
        "mm_early.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early(data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_2=np.hstack([rmse,p])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18e87ef-7570-4fbd-9314-980cb04047df",
        "id": "ULhTbgxWkS0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.885297924280167\n",
            "4.6606700867414474\n",
            "5.924829468131065\n",
            "4.466388002038002\n",
            "5.854096636176109\n",
            "\n",
            "\n",
            "0.8275496061986716\n",
            "0.9149098043900825\n",
            "0.9400545449528455\n",
            "0.9898522288397674\n",
            "0.9321623149601547\n",
            "Mean: 5.958 +/- 1.767\n",
            "Mean: 0.921 +/- 0.059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Early Fusion--2D point+velocity+acceleration"
      ],
      "metadata": {
        "id": "z040uGvvk0be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "8sJrKHAkk0bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MM_early(nn.Module):\n",
        "\n",
        "    def __init__(self, input, drop_prob=0.35):\n",
        "        super(MM_early, self).__init__()\n",
        "        self.encoder_input=Encoder(input,drop_prob)\n",
        "        self.fc = nn.Linear(128, 5)\n",
        "        self.BN= nn.BatchNorm1d(input, affine=False)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "\n",
        "        input_x_1=input_x.view(input_x.size(0)*input_x.size(1),input_x.size(-1))\n",
        "        input_x_1=self.BN(input_x_1)\n",
        "        input_x_2=input_x_1.view(-1, 50, input_x_1.size(-1))\n",
        "        out=self.encoder_input(input_x_2)\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "I8q-H_M6k0bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = MM_early(132)\n",
        "\n",
        "mm_early = train_2D_vel_acc_early(train_loader, lr,40,model,path + encoder + '_early_2D_vel_acc.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f78e996-e043-4e6f-8192-f311bc44c298",
        "id": "1CetemX9k0bk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 3.4680, Training Loss: 0.3945,  Validation loss: 0.2834\n",
            "Epoch: 2, time: 3.5240, Training Loss: 0.2971,  Validation loss: 0.2528\n",
            "Epoch: 3, time: 3.2456, Training Loss: 0.2754,  Validation loss: 0.2432\n",
            "Epoch: 4, time: 3.2840, Training Loss: 0.2617,  Validation loss: 0.2325\n",
            "Epoch: 5, time: 3.4405, Training Loss: 0.2513,  Validation loss: 0.2238\n",
            "Epoch: 6, time: 3.4771, Training Loss: 0.2446,  Validation loss: 0.2198\n",
            "Epoch: 7, time: 3.2898, Training Loss: 0.2377,  Validation loss: 0.2152\n",
            "Epoch: 8, time: 3.5207, Training Loss: 0.2308,  Validation loss: 0.2158\n",
            "Epoch: 9, time: 3.6351, Training Loss: 0.2274,  Validation loss: 0.2094\n",
            "Epoch: 10, time: 3.3383, Training Loss: 0.2241,  Validation loss: 0.2102\n",
            "Epoch: 11, time: 3.2660, Training Loss: 0.2190,  Validation loss: 0.2055\n",
            "Epoch: 12, time: 3.2472, Training Loss: 0.2162,  Validation loss: 0.2047\n",
            "Epoch: 13, time: 3.5907, Training Loss: 0.2135,  Validation loss: 0.2022\n",
            "Epoch: 14, time: 3.2667, Training Loss: 0.2107,  Validation loss: 0.2073\n",
            "Epoch: 15, time: 3.2866, Training Loss: 0.2088,  Validation loss: 0.2049\n",
            "Epoch: 16, time: 3.2622, Training Loss: 0.2063,  Validation loss: 0.2004\n",
            "Epoch: 17, time: 3.5045, Training Loss: 0.2046,  Validation loss: 0.2046\n",
            "Epoch: 18, time: 3.2285, Training Loss: 0.2007,  Validation loss: 0.1991\n",
            "Epoch: 19, time: 3.2692, Training Loss: 0.1994,  Validation loss: 0.2022\n",
            "Epoch: 20, time: 3.3045, Training Loss: 0.1986,  Validation loss: 0.1980\n",
            "Epoch: 21, time: 3.5381, Training Loss: 0.1965,  Validation loss: 0.1993\n",
            "Epoch: 22, time: 3.2398, Training Loss: 0.1946,  Validation loss: 0.2014\n",
            "Epoch: 23, time: 3.2242, Training Loss: 0.1941,  Validation loss: 0.2010\n",
            "Epoch: 24, time: 3.3709, Training Loss: 0.1922,  Validation loss: 0.1984\n",
            "Epoch: 25, time: 3.4432, Training Loss: 0.1901,  Validation loss: 0.1967\n",
            "Epoch: 26, time: 3.2768, Training Loss: 0.1894,  Validation loss: 0.2023\n",
            "Epoch: 27, time: 3.2648, Training Loss: 0.1879,  Validation loss: 0.1984\n",
            "Epoch: 28, time: 3.4507, Training Loss: 0.1867,  Validation loss: 0.1973\n",
            "Epoch: 29, time: 3.4289, Training Loss: 0.1861,  Validation loss: 0.1956\n",
            "Epoch: 30, time: 3.2633, Training Loss: 0.1847,  Validation loss: 0.1957\n",
            "Epoch: 31, time: 3.2621, Training Loss: 0.1843,  Validation loss: 0.2007\n",
            "Epoch: 32, time: 3.4476, Training Loss: 0.1819,  Validation loss: 0.1993\n",
            "Epoch: 33, time: 3.3229, Training Loss: 0.1818,  Validation loss: 0.2042\n",
            "Epoch: 34, time: 3.2539, Training Loss: 0.1813,  Validation loss: 0.1962\n",
            "Epoch: 35, time: 3.2599, Training Loss: 0.1794,  Validation loss: 0.1965\n",
            "Epoch: 36, time: 3.6093, Training Loss: 0.1784,  Validation loss: 0.1969\n",
            "Epoch: 37, time: 3.2870, Training Loss: 0.1783,  Validation loss: 0.1973\n",
            "Epoch: 38, time: 3.2797, Training Loss: 0.1772,  Validation loss: 0.1987\n",
            "Epoch: 39, time: 3.3408, Training Loss: 0.1771,  Validation loss: 0.2014\n",
            "Stopping early after 39 epochs\n",
            "Training time: 131.13508296012878 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_early= MM_early(3*44)\n",
        "mm_early.load_state_dict(torch.load(path+encoder+'_early_2D_vel_acc.pth'))\n",
        "mm_early.to(device)\n",
        "\n",
        "mm_early.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_early(data[:,:,48:180].to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_3=np.hstack([rmse,p])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7cf6574-fa84-48db-e28e-d3d5438d71fb",
        "id": "-hokMhxJk0bk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.67144837975502\n",
            "4.538719728589058\n",
            "6.254046410322189\n",
            "4.538261890411377\n",
            "4.841368272900581\n",
            "\n",
            "\n",
            "0.8485544841778533\n",
            "0.918457642051591\n",
            "0.9383332902934237\n",
            "0.9895097891896117\n",
            "0.9463160608540431\n",
            "Mean: 5.769 +/- 1.771\n",
            "Mean: 0.928 +/- 0.052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Modal Concatenation"
      ],
      "metadata": {
        "id": "Wuq4-YdeUym-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "oCq9xShq_yrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djhcNLtif6mI"
      },
      "source": [
        "## 4. Feature Concatentaion-Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ_H_QN8f6mI"
      },
      "outputs": [],
      "source": [
        "class MM_concat(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr,input_2D, drop_prob=0.25):\n",
        "        super(MM_concat, self).__init__()\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2d=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2d= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(3*128, 5)\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2d):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2d_1=x_2d.view(x_2d.size(0)*x_2d.size(1),x_2d.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2d_1=self.BN_2d(x_2d_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, 50, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, 50, x_gyr_1.size(-1))\n",
        "        x_2d_2=x_2d_1.view(-1, 50, x_2d_1.size(-1))\n",
        "\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2d=self.encoder_2d(x_2d_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2d),dim=-1)\n",
        "\n",
        "        out = self.fc(x)\n",
        "\n",
        "        return out,x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuvcGV94f6mI",
        "outputId": "4cbf828a-f98c-447e-d42a-83567e0eab2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 6.1243, Training Loss: 0.3784,  Validation loss: 0.2887\n",
            "Epoch: 2, time: 5.9957, Training Loss: 0.2779,  Validation loss: 0.2539\n",
            "Epoch: 3, time: 6.0773, Training Loss: 0.2584,  Validation loss: 0.2452\n",
            "Epoch: 4, time: 6.1252, Training Loss: 0.2439,  Validation loss: 0.2276\n",
            "Epoch: 5, time: 6.1595, Training Loss: 0.2314,  Validation loss: 0.2220\n",
            "Epoch: 6, time: 6.0916, Training Loss: 0.2247,  Validation loss: 0.2204\n",
            "Epoch: 7, time: 6.0951, Training Loss: 0.2161,  Validation loss: 0.2266\n",
            "Epoch: 8, time: 6.0456, Training Loss: 0.2113,  Validation loss: 0.2104\n",
            "Epoch: 9, time: 6.0590, Training Loss: 0.2041,  Validation loss: 0.2105\n",
            "Epoch: 10, time: 6.0016, Training Loss: 0.1992,  Validation loss: 0.2096\n",
            "Epoch: 11, time: 6.0471, Training Loss: 0.1953,  Validation loss: 0.2021\n",
            "Epoch: 12, time: 6.0025, Training Loss: 0.1896,  Validation loss: 0.2025\n",
            "Epoch: 13, time: 6.0486, Training Loss: 0.1864,  Validation loss: 0.2034\n",
            "Epoch: 14, time: 5.9915, Training Loss: 0.1828,  Validation loss: 0.2022\n",
            "Epoch: 15, time: 6.0497, Training Loss: 0.1790,  Validation loss: 0.2032\n",
            "Epoch: 16, time: 5.9893, Training Loss: 0.1759,  Validation loss: 0.2008\n",
            "Epoch: 17, time: 6.1009, Training Loss: 0.1728,  Validation loss: 0.1984\n",
            "Epoch: 18, time: 6.0543, Training Loss: 0.1701,  Validation loss: 0.1993\n",
            "Epoch: 19, time: 6.1462, Training Loss: 0.1673,  Validation loss: 0.1980\n",
            "Epoch: 20, time: 6.0369, Training Loss: 0.1645,  Validation loss: 0.2007\n",
            "Epoch: 21, time: 6.0669, Training Loss: 0.1626,  Validation loss: 0.2012\n",
            "Epoch: 22, time: 6.1057, Training Loss: 0.1609,  Validation loss: 0.1977\n",
            "Epoch: 23, time: 6.1413, Training Loss: 0.1562,  Validation loss: 0.1980\n",
            "Epoch: 24, time: 6.1190, Training Loss: 0.1560,  Validation loss: 0.1994\n",
            "Epoch: 25, time: 6.0763, Training Loss: 0.1538,  Validation loss: 0.1982\n",
            "Epoch: 26, time: 6.0724, Training Loss: 0.1517,  Validation loss: 0.1966\n",
            "Epoch: 27, time: 6.0617, Training Loss: 0.1501,  Validation loss: 0.1986\n",
            "Epoch: 28, time: 6.0954, Training Loss: 0.1479,  Validation loss: 0.1978\n",
            "Epoch: 29, time: 6.0717, Training Loss: 0.1474,  Validation loss: 0.2015\n",
            "Epoch: 30, time: 6.0865, Training Loss: 0.1459,  Validation loss: 0.2009\n",
            "Epoch: 31, time: 6.0721, Training Loss: 0.1449,  Validation loss: 0.1974\n",
            "Epoch: 32, time: 6.0977, Training Loss: 0.1416,  Validation loss: 0.1993\n",
            "Epoch: 33, time: 6.0400, Training Loss: 0.1421,  Validation loss: 0.2012\n",
            "Epoch: 34, time: 6.1176, Training Loss: 0.1407,  Validation loss: 0.1979\n",
            "Epoch: 35, time: 6.0571, Training Loss: 0.1384,  Validation loss: 0.1987\n",
            "Epoch: 36, time: 6.0754, Training Loss: 0.1376,  Validation loss: 0.1976\n",
            "Stopping early after 36 epochs\n",
            "Training time: 218.7888948917389 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_concat(44,44,44)\n",
        "\n",
        "mm_concat = train_mm_2D_vel_acc(train_loader, lr,40,model,path+encoder+'_concat_2D_vel_acc.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inQPtQYdf6mI",
        "outputId": "acf998db-4ffc-427c-f57a-1b8fe07f7010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.852237462997437\n",
            "4.6233076602220535\n",
            "4.854240268468857\n",
            "4.525458440184593\n",
            "6.395775079727173\n",
            "\n",
            "\n",
            "0.8360925824087985\n",
            "0.916074013513598\n",
            "0.953028080761638\n",
            "0.9915199814922306\n",
            "0.9554623346408729\n",
            "Mean: 5.850 +/- 1.841\n",
            "Mean: 0.930 +/- 0.059\n"
          ]
        }
      ],
      "source": [
        "mm_concat= MM_concat(44,44,44)\n",
        "mm_concat.load_state_dict(torch.load(path+encoder+'_concat_2D_vel_acc.pth'))\n",
        "mm_concat.to(device)\n",
        "\n",
        "mm_concat.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_concat(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_4=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature Concatenation -- GCN"
      ],
      "metadata": {
        "id": "GqerNT98Xk6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
        "\n"
      ],
      "metadata": {
        "id": "Pk79kx84Xk6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "        support = torch.matmul(x, self.weight)\n",
        "        output = torch.matmul(adjacency_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features):\n",
        "        super(GraphConvolutionalNetwork, self).__init__()\n",
        "        self.gc1 = GraphConvolution(in_features, hidden_features)\n",
        "        self.dropout=nn.Dropout(p=0.10)\n",
        "        self.attention = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "\n",
        "        attention_weights = self.attention(x)\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "        # Apply the attention weights to the input features.\n",
        "        weighted_features = attention_weights * x\n",
        "\n",
        "        x = F.relu(self.gc1(x, adjacency_matrix))\n",
        "        x=self.dropout(x)\n",
        "        # x = F.relu(self.gc2(x, adjacency_matrix))\n",
        "        # x=self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GoexLv8SXk6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGJF1YcjXk6i"
      },
      "outputs": [],
      "source": [
        "class MM_concat_GCN(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_concat_GCN, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(3*128,5)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "\n",
        "        ## Graph Convolutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_1(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_1(x_2D_3)\n",
        "\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=x_gc\n",
        "        out=self.fc(x)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f25ba427-e096-431a-e589-c8fcbb6843a3",
        "id": "rNqn3S1dXk6i"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 5.7436, Training Loss: 0.6248,  Validation loss: 0.5547\n",
            "Epoch: 2, time: 2.5033, Training Loss: 0.5682,  Validation loss: 0.5382\n",
            "Epoch: 3, time: 2.4594, Training Loss: 0.5571,  Validation loss: 0.5296\n",
            "Epoch: 4, time: 2.4744, Training Loss: 0.5492,  Validation loss: 0.5259\n",
            "Epoch: 5, time: 2.5755, Training Loss: 0.5457,  Validation loss: 0.5198\n",
            "Epoch: 6, time: 2.6196, Training Loss: 0.5436,  Validation loss: 0.5191\n",
            "Epoch: 7, time: 2.4911, Training Loss: 0.5422,  Validation loss: 0.5179\n",
            "Epoch: 8, time: 2.4798, Training Loss: 0.5415,  Validation loss: 0.5161\n",
            "Epoch: 9, time: 2.4700, Training Loss: 0.5404,  Validation loss: 0.5159\n",
            "Epoch: 10, time: 2.5372, Training Loss: 0.5408,  Validation loss: 0.5146\n",
            "Epoch: 11, time: 2.6869, Training Loss: 0.5408,  Validation loss: 0.5167\n",
            "Epoch: 12, time: 2.4773, Training Loss: 0.5388,  Validation loss: 0.5116\n",
            "Epoch: 13, time: 2.4873, Training Loss: 0.5384,  Validation loss: 0.5124\n",
            "Epoch: 14, time: 2.5096, Training Loss: 0.5370,  Validation loss: 0.5115\n",
            "Epoch: 15, time: 2.5166, Training Loss: 0.5370,  Validation loss: 0.5119\n",
            "Epoch: 16, time: 2.6430, Training Loss: 0.5360,  Validation loss: 0.5094\n",
            "Epoch: 17, time: 2.4967, Training Loss: 0.5365,  Validation loss: 0.5104\n",
            "Epoch: 18, time: 2.5141, Training Loss: 0.5380,  Validation loss: 0.5174\n",
            "Epoch: 19, time: 2.4675, Training Loss: 0.5370,  Validation loss: 0.5115\n",
            "Epoch: 20, time: 2.4745, Training Loss: 0.5368,  Validation loss: 0.5096\n",
            "Epoch: 21, time: 2.5589, Training Loss: 0.5372,  Validation loss: 0.5093\n",
            "Epoch: 22, time: 2.4598, Training Loss: 0.5358,  Validation loss: 0.5100\n",
            "Epoch: 23, time: 2.4855, Training Loss: 0.5356,  Validation loss: 0.5103\n",
            "Epoch: 24, time: 2.4635, Training Loss: 0.5363,  Validation loss: 0.5083\n",
            "Epoch: 25, time: 2.4901, Training Loss: 0.5375,  Validation loss: 0.5097\n",
            "Epoch: 26, time: 2.5060, Training Loss: 0.5368,  Validation loss: 0.5102\n",
            "Epoch: 27, time: 2.4506, Training Loss: 0.5362,  Validation loss: 0.5090\n",
            "Epoch: 28, time: 2.4522, Training Loss: 0.5355,  Validation loss: 0.5083\n",
            "Epoch: 29, time: 2.4645, Training Loss: 0.5355,  Validation loss: 0.5097\n",
            "Epoch: 30, time: 2.5301, Training Loss: 0.5357,  Validation loss: 0.5109\n",
            "Epoch: 31, time: 2.5227, Training Loss: 0.5356,  Validation loss: 0.5123\n",
            "Epoch: 32, time: 2.6791, Training Loss: 0.5352,  Validation loss: 0.5088\n",
            "Epoch: 33, time: 2.4573, Training Loss: 0.5354,  Validation loss: 0.5086\n",
            "Epoch: 34, time: 2.4867, Training Loss: 0.5357,  Validation loss: 0.5087\n",
            "Epoch: 35, time: 2.5166, Training Loss: 0.5356,  Validation loss: 0.5078\n",
            "Epoch: 36, time: 2.5093, Training Loss: 0.5357,  Validation loss: 0.5069\n",
            "Epoch: 37, time: 2.4749, Training Loss: 0.5349,  Validation loss: 0.5066\n",
            "Epoch: 38, time: 2.4677, Training Loss: 0.5349,  Validation loss: 0.5070\n",
            "Epoch: 39, time: 2.4659, Training Loss: 0.5362,  Validation loss: 0.5088\n",
            "Epoch: 40, time: 2.5363, Training Loss: 0.5360,  Validation loss: 0.5104\n",
            "Training time: 103.68548083305359 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_concat_GCN(44,44,44)\n",
        "\n",
        "mm_concat_gcn = train_mm_2D_vel_acc(train_loader, lr,40,model,path+encoder+'_concat_2D_vel_acc_GCN.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10fae540-7185-4e93-d27e-4ff832af75ea",
        "id": "qAko7H63Xk6i"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "9.93407592177391\n",
            "7.217597216367722\n",
            "7.54242017865181\n",
            "9.739238023757935\n",
            "7.640025019645691\n",
            "\n",
            "\n",
            "0.7424053041278158\n",
            "0.7825516387133999\n",
            "0.8787856980007224\n",
            "0.9520803055939029\n",
            "0.8968188772724135\n",
            "Mean: 8.415 +/- 1.309\n",
            "Mean: 0.851 +/- 0.086\n"
          ]
        }
      ],
      "source": [
        "mm_concat_gcn= MM_concat_GCN(44,44,44)\n",
        "mm_concat_gcn.load_state_dict(torch.load(path+encoder+'_concat_2D_vel_acc_GCN.pth'))\n",
        "mm_concat_gcn.to(device)\n",
        "\n",
        "mm_concat_gcn.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_concat_gcn(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_5=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Feature Concatenation -- GCN+attention"
      ],
      "metadata": {
        "id": "GUXZmam7e9vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "        support = torch.matmul(x, self.weight)\n",
        "        output = torch.matmul(adjacency_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features):\n",
        "        super(GraphConvolutionalNetwork, self).__init__()\n",
        "        self.gc1 = GraphConvolution(in_features, hidden_features)\n",
        "        self.dropout=nn.Dropout(p=0.10)\n",
        "        self.attention = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "\n",
        "        attention_weights = self.attention(x)\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "\n",
        "        # print(attention_weights.squeeze(-1).shape)\n",
        "        # print(x.shape)\n",
        "        # Apply the attention weights to the input features.\n",
        "        weighted_features = attention_weights * x\n",
        "\n",
        "        x = F.relu(self.gc1(weighted_features, adjacency_matrix))\n",
        "        x=self.dropout(x)\n",
        "        # x = F.relu(self.gc2(x, adjacency_matrix))\n",
        "        # x=self.dropout(x)\n",
        "        return x,attention_weights"
      ],
      "metadata": {
        "id": "twczO2xjgIBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jNjwpjPgIBa"
      },
      "outputs": [],
      "source": [
        "class MM_concat_GCN_attention(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_concat_GCN_attention, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(3*128,5)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3,attention_weights=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3,attention_weights=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3,attention_weights=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=x_gc\n",
        "        out=self.fc(x)\n",
        "\n",
        "        return out,attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ac2d41-408c-4da5-e8e3-06e2ef4139e1",
        "id": "ExzMpI8QgIBb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 2.7048, Training Loss: 0.6767,  Validation loss: 0.5571\n",
            "Epoch: 2, time: 2.6997, Training Loss: 0.5606,  Validation loss: 0.5296\n",
            "Epoch: 3, time: 2.6544, Training Loss: 0.5467,  Validation loss: 0.5221\n",
            "Epoch: 4, time: 2.7665, Training Loss: 0.5401,  Validation loss: 0.5145\n",
            "Epoch: 5, time: 2.6282, Training Loss: 0.5365,  Validation loss: 0.5100\n",
            "Epoch: 6, time: 2.6205, Training Loss: 0.5327,  Validation loss: 0.5063\n",
            "Epoch: 7, time: 2.5983, Training Loss: 0.5330,  Validation loss: 0.5089\n",
            "Epoch: 8, time: 2.6968, Training Loss: 0.5298,  Validation loss: 0.5021\n",
            "Epoch: 9, time: 2.6489, Training Loss: 0.5281,  Validation loss: 0.5041\n",
            "Epoch: 10, time: 2.6217, Training Loss: 0.5261,  Validation loss: 0.5057\n",
            "Epoch: 11, time: 2.6202, Training Loss: 0.5258,  Validation loss: 0.4991\n",
            "Epoch: 12, time: 2.5954, Training Loss: 0.5266,  Validation loss: 0.5017\n",
            "Epoch: 13, time: 2.7751, Training Loss: 0.5246,  Validation loss: 0.5040\n",
            "Epoch: 14, time: 2.6346, Training Loss: 0.5241,  Validation loss: 0.4996\n",
            "Epoch: 15, time: 2.6038, Training Loss: 0.5233,  Validation loss: 0.4990\n",
            "Epoch: 16, time: 2.6106, Training Loss: 0.5244,  Validation loss: 0.4977\n",
            "Epoch: 17, time: 2.7866, Training Loss: 0.5245,  Validation loss: 0.4997\n",
            "Epoch: 18, time: 2.7222, Training Loss: 0.5226,  Validation loss: 0.4988\n",
            "Epoch: 19, time: 2.6061, Training Loss: 0.5224,  Validation loss: 0.4963\n",
            "Epoch: 20, time: 2.5910, Training Loss: 0.5245,  Validation loss: 0.4978\n",
            "Epoch: 21, time: 2.6025, Training Loss: 0.5230,  Validation loss: 0.4991\n",
            "Epoch: 22, time: 2.7244, Training Loss: 0.5229,  Validation loss: 0.4995\n",
            "Epoch: 23, time: 2.7087, Training Loss: 0.5236,  Validation loss: 0.5008\n",
            "Epoch: 24, time: 2.6941, Training Loss: 0.5240,  Validation loss: 0.5001\n",
            "Epoch: 25, time: 2.6211, Training Loss: 0.5219,  Validation loss: 0.4974\n",
            "Epoch: 26, time: 2.6945, Training Loss: 0.5228,  Validation loss: 0.4995\n",
            "Epoch: 27, time: 2.7022, Training Loss: 0.5234,  Validation loss: 0.4974\n",
            "Epoch: 28, time: 2.6457, Training Loss: 0.5218,  Validation loss: 0.4975\n",
            "Epoch: 29, time: 2.6278, Training Loss: 0.5220,  Validation loss: 0.4963\n",
            "Stopping early after 29 epochs\n",
            "Training time: 77.25846362113953 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_concat_GCN_attention(44,44,44)\n",
        "\n",
        "mm_concat_gcn_attention = train_mm_2D_vel_acc(train_loader, lr,40,model,path+encoder+'_concat_2D_vel_acc_GCN_attention.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZlGjVIXgIBc",
        "outputId": "77ac2a25-3bc4-455b-acaa-18ee164a1f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "9.720035642385483\n",
            "7.050458341836929\n",
            "7.382342219352722\n",
            "9.655017405748367\n",
            "7.197517901659012\n",
            "\n",
            "\n",
            "0.7589932210376532\n",
            "0.79761160059642\n",
            "0.8840109336158641\n",
            "0.9533267911391666\n",
            "0.9087639710995238\n",
            "Mean: 8.201 +/- 1.362\n",
            "Mean: 0.861 +/- 0.080\n"
          ]
        }
      ],
      "source": [
        "mm_concat_gcn_attention= MM_concat_GCN_attention(44,44,44)\n",
        "mm_concat_gcn_attention.load_state_dict(torch.load(path+encoder+'_concat_2D_vel_acc_GCN_attention.pth'))\n",
        "mm_concat_gcn_attention.to(device)\n",
        "\n",
        "mm_concat_gcn_attention.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_concat_gcn_attention(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_6=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Feature Concatenation -- Bi-LSTM + GCN + attention"
      ],
      "metadata": {
        "id": "TZ7MtrTtVOQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "        support = torch.matmul(x, self.weight)\n",
        "        output = torch.matmul(adjacency_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features):\n",
        "        super(GraphConvolutionalNetwork, self).__init__()\n",
        "        self.gc1 = GraphConvolution(in_features, hidden_features)\n",
        "        self.dropout=nn.Dropout(p=0.10)\n",
        "        self.attention = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "\n",
        "        attention_weights = self.attention(x)\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "        # Apply the attention weights to the input features.\n",
        "        weighted_features = attention_weights * x\n",
        "\n",
        "\n",
        "        x = F.relu(self.gc1(weighted_features, adjacency_matrix))\n",
        "        x=self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8ahdVSmpjZiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "vhLssrBmjZiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMzlU7zRjZiX"
      },
      "outputs": [],
      "source": [
        "class MM_concat_LSTM_GCN_attention_WOG(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_concat_LSTM_GCN_attention_WOG, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        embedd_dim=128\n",
        "\n",
        "        self.fc = nn.Linear(3*embedd_dim,5)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.gate=GatingModule(128*3)\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        # x=self.gate(x,x_gc)\n",
        "        x=x+x_gc\n",
        "        out=self.fc(x)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d64005c-df1d-478f-aa84-4c0ffdd4d8d4",
        "id": "eP6vatYyjZiY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 7.4947, Training Loss: 0.3726,  Validation loss: 0.2849\n",
            "Epoch: 2, time: 6.9123, Training Loss: 0.2775,  Validation loss: 0.2609\n",
            "Epoch: 3, time: 6.8495, Training Loss: 0.2567,  Validation loss: 0.2449\n",
            "Epoch: 4, time: 7.7718, Training Loss: 0.2424,  Validation loss: 0.2275\n",
            "Epoch: 5, time: 7.6839, Training Loss: 0.2291,  Validation loss: 0.2256\n",
            "Epoch: 6, time: 8.1730, Training Loss: 0.2237,  Validation loss: 0.2212\n",
            "Epoch: 7, time: 6.9399, Training Loss: 0.2157,  Validation loss: 0.2107\n",
            "Epoch: 8, time: 6.8095, Training Loss: 0.2104,  Validation loss: 0.2150\n",
            "Epoch: 9, time: 7.0958, Training Loss: 0.2032,  Validation loss: 0.2051\n",
            "Epoch: 10, time: 7.5557, Training Loss: 0.1972,  Validation loss: 0.2070\n",
            "Epoch: 11, time: 7.1623, Training Loss: 0.1927,  Validation loss: 0.2055\n",
            "Epoch: 12, time: 7.0057, Training Loss: 0.1896,  Validation loss: 0.2078\n",
            "Epoch: 13, time: 8.2954, Training Loss: 0.1870,  Validation loss: 0.2032\n",
            "Epoch: 14, time: 7.6165, Training Loss: 0.1820,  Validation loss: 0.2018\n",
            "Epoch: 15, time: 6.6348, Training Loss: 0.1789,  Validation loss: 0.2110\n",
            "Epoch: 16, time: 6.5960, Training Loss: 0.1751,  Validation loss: 0.1992\n",
            "Epoch: 17, time: 6.6480, Training Loss: 0.1715,  Validation loss: 0.2003\n",
            "Epoch: 18, time: 6.6114, Training Loss: 0.1683,  Validation loss: 0.1985\n",
            "Epoch: 19, time: 6.9502, Training Loss: 0.1674,  Validation loss: 0.1983\n",
            "Epoch: 20, time: 7.6570, Training Loss: 0.1636,  Validation loss: 0.1990\n",
            "Epoch: 21, time: 7.2744, Training Loss: 0.1619,  Validation loss: 0.2008\n",
            "Epoch: 22, time: 6.9624, Training Loss: 0.1597,  Validation loss: 0.1975\n",
            "Epoch: 23, time: 6.8401, Training Loss: 0.1568,  Validation loss: 0.1970\n",
            "Epoch: 24, time: 6.6033, Training Loss: 0.1552,  Validation loss: 0.1965\n",
            "Epoch: 25, time: 6.5812, Training Loss: 0.1538,  Validation loss: 0.2002\n",
            "Epoch: 26, time: 6.6518, Training Loss: 0.1518,  Validation loss: 0.1967\n",
            "Epoch: 27, time: 6.6132, Training Loss: 0.1505,  Validation loss: 0.1956\n",
            "Epoch: 28, time: 6.7875, Training Loss: 0.1483,  Validation loss: 0.1965\n",
            "Epoch: 29, time: 6.6169, Training Loss: 0.1462,  Validation loss: 0.2008\n",
            "Epoch: 30, time: 6.6321, Training Loss: 0.1456,  Validation loss: 0.1970\n",
            "Epoch: 31, time: 6.6109, Training Loss: 0.1444,  Validation loss: 0.1976\n",
            "Epoch: 32, time: 6.6406, Training Loss: 0.1415,  Validation loss: 0.1948\n",
            "Epoch: 33, time: 6.6319, Training Loss: 0.1409,  Validation loss: 0.1960\n",
            "Epoch: 34, time: 6.6003, Training Loss: 0.1403,  Validation loss: 0.1975\n",
            "Epoch: 35, time: 6.8588, Training Loss: 0.1384,  Validation loss: 0.1966\n",
            "Epoch: 36, time: 6.5891, Training Loss: 0.1375,  Validation loss: 0.1982\n",
            "Epoch: 37, time: 6.6357, Training Loss: 0.1361,  Validation loss: 0.1970\n",
            "Epoch: 38, time: 6.6054, Training Loss: 0.1364,  Validation loss: 0.2003\n",
            "Epoch: 39, time: 6.6738, Training Loss: 0.1357,  Validation loss: 0.2004\n",
            "Epoch: 40, time: 6.5875, Training Loss: 0.1330,  Validation loss: 0.1973\n",
            "Training time: 278.763436794281 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_concat_LSTM_GCN_attention_WOG(44,44,44)\n",
        "\n",
        "mm_concat_lstm_gcn_attention_wog = train_mm_2D_vel_acc(train_loader, lr,40,model,path+encoder+'_concat_2D_vel_acc_LSTM_GCN_attention_WOG.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqoO4V56jZiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67fbc75d-ce05-46d0-ef92-1adfcb658c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.662129938602448\n",
            "4.433944821357727\n",
            "4.447487369179726\n",
            "4.5229721814394\n",
            "6.059538573026657\n",
            "\n",
            "\n",
            "0.8400505376311476\n",
            "0.9245378263361261\n",
            "0.9589199990401379\n",
            "0.99068948961634\n",
            "0.9616176552518619\n",
            "Mean: 5.625 +/- 1.833\n",
            "Mean: 0.935 +/- 0.058\n"
          ]
        }
      ],
      "source": [
        "mm_concat_lstm_gcn_attention_wog= MM_concat_LSTM_GCN_attention_WOG(44,44,44)\n",
        "mm_concat_lstm_gcn_attention_wog.load_state_dict(torch.load(path+encoder+'_concat_2D_vel_acc_LSTM_GCN_attention_WOG.pth'))\n",
        "mm_concat_lstm_gcn_attention_wog.to(device)\n",
        "\n",
        "mm_concat_lstm_gcn_attention_wog.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_concat_lstm_gcn_attention_wog(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_7=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Feature Concatenation -- Bi-LSTM + GCN + attention + Gated"
      ],
      "metadata": {
        "id": "PQBLMBi1rmcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "        support = torch.matmul(x, self.weight)\n",
        "        output = torch.matmul(adjacency_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features):\n",
        "        super(GraphConvolutionalNetwork, self).__init__()\n",
        "        self.gc1 = GraphConvolution(in_features, hidden_features)\n",
        "        self.dropout=nn.Dropout(p=0.10)\n",
        "        self.attention = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "\n",
        "        attention_weights = self.attention(x)\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "        # Apply the attention weights to the input features.\n",
        "        weighted_features = attention_weights * x\n",
        "\n",
        "\n",
        "        x = F.relu(self.gc1(weighted_features, adjacency_matrix))\n",
        "        x=self.dropout(x)\n",
        "        # x = F.relu(self.gc2(x, adjacency_matrix))\n",
        "        # x=self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ogHsW337rmcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "6tMsaocLrmcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-MLh5hTrmcD"
      },
      "outputs": [],
      "source": [
        "class MM_concat_LSTM_GCN_attention_WG(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_concat_LSTM_GCN_attention_WG, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        embedd_dim=128\n",
        "\n",
        "        self.fc = nn.Linear(3*embedd_dim,5)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.gate=GatingModule(128*3)\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "        # x=x+x_gc\n",
        "        out=self.fc(x)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e287b9-5896-476c-89b0-35a88a4e7f53",
        "id": "7BwDD53PrmcD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 7.2550, Training Loss: 0.3781,  Validation loss: 0.2801\n",
            "Epoch: 2, time: 7.3290, Training Loss: 0.2760,  Validation loss: 0.2562\n",
            "Epoch: 3, time: 7.4795, Training Loss: 0.2509,  Validation loss: 0.2314\n",
            "Epoch: 4, time: 7.3404, Training Loss: 0.2347,  Validation loss: 0.2274\n",
            "Epoch: 5, time: 7.3647, Training Loss: 0.2256,  Validation loss: 0.2215\n",
            "Epoch: 6, time: 7.2456, Training Loss: 0.2182,  Validation loss: 0.2254\n",
            "Epoch: 7, time: 7.1731, Training Loss: 0.2114,  Validation loss: 0.2151\n",
            "Epoch: 8, time: 7.1836, Training Loss: 0.2019,  Validation loss: 0.2040\n",
            "Epoch: 9, time: 7.1056, Training Loss: 0.1962,  Validation loss: 0.2058\n",
            "Epoch: 10, time: 7.1120, Training Loss: 0.1918,  Validation loss: 0.1998\n",
            "Epoch: 11, time: 7.0959, Training Loss: 0.1875,  Validation loss: 0.2004\n",
            "Epoch: 12, time: 7.1163, Training Loss: 0.1830,  Validation loss: 0.2053\n",
            "Epoch: 13, time: 7.1092, Training Loss: 0.1792,  Validation loss: 0.1956\n",
            "Epoch: 14, time: 7.1085, Training Loss: 0.1740,  Validation loss: 0.1962\n",
            "Epoch: 15, time: 7.2143, Training Loss: 0.1699,  Validation loss: 0.1939\n",
            "Epoch: 16, time: 7.1465, Training Loss: 0.1676,  Validation loss: 0.2000\n",
            "Epoch: 17, time: 7.1724, Training Loss: 0.1642,  Validation loss: 0.1981\n",
            "Epoch: 18, time: 7.0966, Training Loss: 0.1609,  Validation loss: 0.1936\n",
            "Epoch: 19, time: 7.1553, Training Loss: 0.1602,  Validation loss: 0.1924\n",
            "Epoch: 20, time: 7.1191, Training Loss: 0.1573,  Validation loss: 0.1934\n",
            "Epoch: 21, time: 7.0662, Training Loss: 0.1546,  Validation loss: 0.1953\n",
            "Epoch: 22, time: 7.1663, Training Loss: 0.1521,  Validation loss: 0.1930\n",
            "Epoch: 23, time: 7.0918, Training Loss: 0.1500,  Validation loss: 0.1937\n",
            "Epoch: 24, time: 7.2279, Training Loss: 0.1473,  Validation loss: 0.1934\n",
            "Epoch: 25, time: 7.1380, Training Loss: 0.1449,  Validation loss: 0.1901\n",
            "Epoch: 26, time: 7.1662, Training Loss: 0.1423,  Validation loss: 0.1983\n",
            "Epoch: 27, time: 7.2057, Training Loss: 0.1418,  Validation loss: 0.1934\n",
            "Epoch: 28, time: 7.1412, Training Loss: 0.1403,  Validation loss: 0.1926\n",
            "Epoch: 29, time: 7.1420, Training Loss: 0.1383,  Validation loss: 0.1933\n",
            "Epoch: 30, time: 7.1355, Training Loss: 0.1366,  Validation loss: 0.1921\n",
            "Epoch: 31, time: 7.1592, Training Loss: 0.1349,  Validation loss: 0.1926\n",
            "Epoch: 32, time: 7.2137, Training Loss: 0.1329,  Validation loss: 0.1922\n",
            "Epoch: 33, time: 7.0632, Training Loss: 0.1318,  Validation loss: 0.1928\n",
            "Epoch: 34, time: 7.1345, Training Loss: 0.1302,  Validation loss: 0.1927\n",
            "Epoch: 35, time: 7.0810, Training Loss: 0.1296,  Validation loss: 0.1930\n",
            "Stopping early after 35 epochs\n",
            "Training time: 251.2716133594513 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_concat_LSTM_GCN_attention_WG(44,44,44)\n",
        "\n",
        "mm_concat_lstm_gcn_attention_wg = train_mm_2D_vel_acc(train_loader, lr,40,model,path+encoder+'_concat_2D_vel_acc_LSTM_GCN_attention_WG.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFFru8QirmcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "905964ac-f178-47af-caa7-a523aa26b7ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.659110218286514\n",
            "4.508740082383156\n",
            "4.196418821811676\n",
            "4.032282531261444\n",
            "6.237122416496277\n",
            "\n",
            "\n",
            "0.82920059505719\n",
            "0.9214971823269\n",
            "0.9623712286536901\n",
            "0.9919304429329749\n",
            "0.9600810344021868\n",
            "Mean: 5.527 +/- 1.959\n",
            "Mean: 0.933 +/- 0.063\n"
          ]
        }
      ],
      "source": [
        "mm_concat_lstm_gcn_attention_wg= MM_concat_LSTM_GCN_attention_WG(44,44,44)\n",
        "mm_concat_lstm_gcn_attention_wg.load_state_dict(torch.load(path+encoder+'_concat_2D_vel_acc_LSTM_GCN_attention_WG.pth'))\n",
        "mm_concat_lstm_gcn_attention_wg.to(device)\n",
        "\n",
        "mm_concat_lstm_gcn_attention_wg.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_concat_lstm_gcn_attention_wg(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_8=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Modal Fusion"
      ],
      "metadata": {
        "id": "XGiQ1YC3hb1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "BDJU_nsc_0cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])"
      ],
      "metadata": {
        "id": "uzHfKA2uAJon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "        support = torch.matmul(x, self.weight)\n",
        "        output = torch.matmul(adjacency_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features):\n",
        "        super(GraphConvolutionalNetwork, self).__init__()\n",
        "        self.gc1 = GraphConvolution(in_features, hidden_features)\n",
        "        self.dropout=nn.Dropout(p=0.10)\n",
        "        self.attention = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "\n",
        "        attention_weights = self.attention(x)\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "        # Apply the attention weights to the input features.\n",
        "        weighted_features = attention_weights * x\n",
        "\n",
        "        x = F.relu(self.gc1(weighted_features, adjacency_matrix))\n",
        "        x=self.dropout(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZJKiCZXeAJop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "5FPMYRC1GBor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Low rank multi-modal fusion"
      ],
      "metadata": {
        "id": "t5ExgCH53Lb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LMF(nn.Module):\n",
        "\n",
        "    def __init__(self, rank, input_modality_1, input_modality_2, input_modality_3, output_dim):\n",
        "\n",
        "        super(LMF, self).__init__()\n",
        "\n",
        "        self.modality_1=input_modality_1\n",
        "        self.modality_2=input_modality_2\n",
        "        self.modality_3=input_modality_3\n",
        "        self.output_dim=output_dim\n",
        "        self.rank=rank\n",
        "        data_type = torch.cuda.FloatTensor\n",
        "\n",
        "        self.modality_1_factor = Parameter(torch.Tensor(self.rank,1, self.modality_1 + 1, self.output_dim)).to(device)\n",
        "        self.modality_2_factor = Parameter(torch.Tensor(self.rank,1, self.modality_2 + 1, self.output_dim)).to(device)\n",
        "        self.modality_3_factor = Parameter(torch.Tensor(self.rank,1, self.modality_3 + 1, self.output_dim)).to(device)\n",
        "\n",
        "        self.fusion_weights = Parameter(torch.Tensor(1, self.rank)).to(device)\n",
        "        self.fusion_bias = Parameter(torch.Tensor(1, self.output_dim)).to(device)\n",
        "\n",
        "        init.xavier_normal_(self.modality_1_factor,self.rank)\n",
        "        init.xavier_normal_(self.modality_2_factor,self.rank)\n",
        "        init.xavier_normal_(self.modality_3_factor,self.rank)\n",
        "\n",
        "        init.xavier_normal_(self.fusion_weights)\n",
        "        self.fusion_bias.data.fill_(0)\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2d):\n",
        "\n",
        "        batch_size = x_acc.shape[0]\n",
        "\n",
        "        data_type = torch.cuda.FloatTensor\n",
        "\n",
        "        # ones = torch.ones(batch_size, 50, 1, device=device)\n",
        "\n",
        "        x_acc = torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_acc), dim=2)\n",
        "        x_gyr= torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_gyr), dim=2)\n",
        "        x_2d = torch.cat((torch.autograd.Variable(torch.ones(batch_size,50, 1).type(data_type), requires_grad=False),x_2d), dim=2)\n",
        "\n",
        "\n",
        "        fusion_modality_1 = torch.matmul(x_acc, self.modality_1_factor)\n",
        "        fusion_modality_2 = torch.matmul(x_gyr, self.modality_2_factor)\n",
        "        fusion_modality_3 = torch.matmul(x_2d, self.modality_3_factor)\n",
        "\n",
        "        output = fusion_modality_1 * fusion_modality_2 * fusion_modality_3\n",
        "\n",
        "        # permute to make batch first\n",
        "        output = torch.matmul(self.fusion_weights, output .permute(1, 2, 0, 3)).squeeze(dim=2) + self.fusion_bias\n",
        "\n",
        "\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "gAr6mZ5kadKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLEV2UBA3OYt"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_LMF(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_LMF, self).__init__()\n",
        "\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(3*128,5)\n",
        "\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate=GatingModule(128*3)\n",
        "\n",
        "        self.lmf=LMF(10,32,32,32,5)\n",
        "        self.l1 = nn.Linear(128,32)\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        x_acc=self.l1(x[:,:,0:128])\n",
        "        x_gyr=self.l1(x[:,:,128:2*128])\n",
        "        x_2d=self.l1(x[:,:,2*128:3*128])\n",
        "\n",
        "        out=self.lmf(x_acc, x_gyr,x_2d)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b796da7-a19a-47a1-a78f-86a96632e06f",
        "id": "uGLxiaMG3OYu"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 8.2361, Training Loss: 0.3902,  Validation loss: 0.2997\n",
            "Epoch: 2, time: 8.8624, Training Loss: 0.2804,  Validation loss: 0.2484\n",
            "Epoch: 3, time: 9.3742, Training Loss: 0.2528,  Validation loss: 0.2388\n",
            "Epoch: 4, time: 9.8991, Training Loss: 0.2394,  Validation loss: 0.2206\n",
            "Epoch: 5, time: 9.2519, Training Loss: 0.2264,  Validation loss: 0.2350\n",
            "Epoch: 6, time: 9.5076, Training Loss: 0.2191,  Validation loss: 0.2069\n",
            "Epoch: 7, time: 9.3278, Training Loss: 0.2113,  Validation loss: 0.2134\n",
            "Epoch: 8, time: 9.2626, Training Loss: 0.2052,  Validation loss: 0.2096\n",
            "Epoch: 9, time: 9.0478, Training Loss: 0.1997,  Validation loss: 0.2006\n",
            "Epoch: 10, time: 9.3024, Training Loss: 0.1941,  Validation loss: 0.1996\n",
            "Epoch: 11, time: 9.5443, Training Loss: 0.1891,  Validation loss: 0.2092\n",
            "Epoch: 12, time: 9.5375, Training Loss: 0.1858,  Validation loss: 0.2122\n",
            "Epoch: 13, time: 9.6148, Training Loss: 0.1821,  Validation loss: 0.1967\n",
            "Epoch: 14, time: 9.0306, Training Loss: 0.1768,  Validation loss: 0.2088\n",
            "Epoch: 15, time: 9.2670, Training Loss: 0.1736,  Validation loss: 0.1949\n",
            "Epoch: 16, time: 9.3604, Training Loss: 0.1714,  Validation loss: 0.1929\n",
            "Epoch: 17, time: 9.0401, Training Loss: 0.1664,  Validation loss: 0.2072\n",
            "Epoch: 18, time: 8.7232, Training Loss: 0.1652,  Validation loss: 0.1917\n",
            "Epoch: 19, time: 8.6090, Training Loss: 0.1598,  Validation loss: 0.1916\n",
            "Epoch: 20, time: 9.1196, Training Loss: 0.1584,  Validation loss: 0.1932\n",
            "Epoch: 21, time: 9.9918, Training Loss: 0.1557,  Validation loss: 0.1940\n",
            "Epoch: 22, time: 9.0708, Training Loss: 0.1533,  Validation loss: 0.1951\n",
            "Epoch: 23, time: 10.1722, Training Loss: 0.1492,  Validation loss: 0.1965\n",
            "Epoch: 24, time: 9.5270, Training Loss: 0.1489,  Validation loss: 0.1925\n",
            "Epoch: 25, time: 9.5579, Training Loss: 0.1485,  Validation loss: 0.1975\n",
            "Epoch: 26, time: 9.5406, Training Loss: 0.1443,  Validation loss: 0.1901\n",
            "Epoch: 27, time: 9.2852, Training Loss: 0.1427,  Validation loss: 0.1949\n",
            "Epoch: 28, time: 9.6453, Training Loss: 0.1428,  Validation loss: 0.1903\n",
            "Epoch: 29, time: 9.1673, Training Loss: 0.1383,  Validation loss: 0.1933\n",
            "Epoch: 30, time: 9.7091, Training Loss: 0.1381,  Validation loss: 0.2068\n",
            "Epoch: 31, time: 9.5999, Training Loss: 0.1376,  Validation loss: 0.1896\n",
            "Epoch: 32, time: 8.6013, Training Loss: 0.1354,  Validation loss: 0.1928\n",
            "Epoch: 33, time: 9.2685, Training Loss: 0.1326,  Validation loss: 0.1969\n",
            "Epoch: 34, time: 8.8831, Training Loss: 0.1318,  Validation loss: 0.1924\n",
            "Epoch: 35, time: 8.6355, Training Loss: 0.1310,  Validation loss: 0.1899\n",
            "Epoch: 36, time: 9.2410, Training Loss: 0.1295,  Validation loss: 0.1903\n",
            "Epoch: 37, time: 9.0539, Training Loss: 0.1285,  Validation loss: 0.1930\n",
            "Epoch: 38, time: 9.1789, Training Loss: 0.1290,  Validation loss: 0.1933\n",
            "Epoch: 39, time: 9.3015, Training Loss: 0.1262,  Validation loss: 0.1920\n",
            "Epoch: 40, time: 9.6698, Training Loss: 0.1250,  Validation loss: 0.1909\n",
            "Training time: 371.28268218040466 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_LMF(44,44,44)\n",
        "\n",
        "mm_vid_kinect_lmf = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_lmf.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6636acb-646f-43c7-c9a2-a496210a6f09",
        "id": "i5PPB3n33OYu"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "13.408854603767395\n",
            "11.377092450857162\n",
            "23.90245795249939\n",
            "78.49855422973633\n",
            "35.453563928604126\n",
            "\n",
            "\n",
            "0.47364456716962755\n",
            "0.5570881376020943\n",
            "0.4385916613776079\n",
            "0.29845619494709025\n",
            "-0.29581341282451\n",
            "Mean: 32.528 +/- 27.428\n",
            "Mean: 0.294 +/- 0.343\n"
          ]
        }
      ],
      "source": [
        "# mm_vid_kinect_lmf= MM_VID_Kinect_LMF(44,44,44)\n",
        "# mm_vid_kinect_lmf.load_state_dict(torch.load(path+'_mm_vid_kinect_lmf.pth'))\n",
        "# mm_vid_kinect_lmf.to(device)\n",
        "\n",
        "mm_vid_kinect_lmf.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_lmf(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_9=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Tensor Fusion with Multiplication"
      ],
      "metadata": {
        "id": "vUbNhLvoeBjZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45QUGX5MeBjf"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_TMF(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_TMF, self).__init__()\n",
        "\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(128,5)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate=GatingModule(128*3)\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        out=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "        out = self.fc(out)\n",
        "\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37dfb6a6-9066-402a-ff11-fb25c7e10e74",
        "id": "QBACIzkxeBjf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 7.7728, Training Loss: 0.4657,  Validation loss: 0.3257\n",
            "Epoch: 2, time: 7.6240, Training Loss: 0.3186,  Validation loss: 0.2594\n",
            "Epoch: 3, time: 7.7268, Training Loss: 0.2865,  Validation loss: 0.2555\n",
            "Epoch: 4, time: 7.7485, Training Loss: 0.2654,  Validation loss: 0.2283\n",
            "Epoch: 5, time: 7.7323, Training Loss: 0.2515,  Validation loss: 0.2209\n",
            "Epoch: 6, time: 7.5908, Training Loss: 0.2403,  Validation loss: 0.2175\n",
            "Epoch: 7, time: 7.5684, Training Loss: 0.2314,  Validation loss: 0.2257\n",
            "Epoch: 8, time: 7.5600, Training Loss: 0.2250,  Validation loss: 0.2080\n",
            "Epoch: 9, time: 7.4921, Training Loss: 0.2169,  Validation loss: 0.2104\n",
            "Epoch: 10, time: 7.5128, Training Loss: 0.2118,  Validation loss: 0.2012\n",
            "Epoch: 11, time: 7.4792, Training Loss: 0.2055,  Validation loss: 0.2032\n",
            "Epoch: 12, time: 7.5121, Training Loss: 0.2013,  Validation loss: 0.2006\n",
            "Epoch: 13, time: 7.5304, Training Loss: 0.1965,  Validation loss: 0.1992\n",
            "Epoch: 14, time: 7.5345, Training Loss: 0.1927,  Validation loss: 0.2039\n",
            "Epoch: 15, time: 7.5462, Training Loss: 0.1883,  Validation loss: 0.1977\n",
            "Epoch: 16, time: 7.5529, Training Loss: 0.1850,  Validation loss: 0.1991\n",
            "Epoch: 17, time: 7.6067, Training Loss: 0.1819,  Validation loss: 0.1978\n",
            "Epoch: 18, time: 7.5952, Training Loss: 0.1787,  Validation loss: 0.1976\n",
            "Epoch: 19, time: 7.5383, Training Loss: 0.1754,  Validation loss: 0.2140\n",
            "Epoch: 20, time: 7.5606, Training Loss: 0.1733,  Validation loss: 0.1957\n",
            "Epoch: 21, time: 7.5488, Training Loss: 0.1704,  Validation loss: 0.1954\n",
            "Epoch: 22, time: 7.4975, Training Loss: 0.1667,  Validation loss: 0.1962\n",
            "Epoch: 23, time: 7.5445, Training Loss: 0.1656,  Validation loss: 0.1931\n",
            "Epoch: 24, time: 7.5426, Training Loss: 0.1658,  Validation loss: 0.1980\n",
            "Epoch: 25, time: 7.5603, Training Loss: 0.1626,  Validation loss: 0.2013\n",
            "Epoch: 26, time: 7.5416, Training Loss: 0.1606,  Validation loss: 0.1944\n",
            "Epoch: 27, time: 7.5109, Training Loss: 0.1572,  Validation loss: 0.1939\n",
            "Epoch: 28, time: 7.5371, Training Loss: 0.1551,  Validation loss: 0.1961\n",
            "Epoch: 29, time: 7.5445, Training Loss: 0.1543,  Validation loss: 0.1971\n",
            "Epoch: 30, time: 7.5126, Training Loss: 0.1514,  Validation loss: 0.1924\n",
            "Epoch: 31, time: 7.5427, Training Loss: 0.1508,  Validation loss: 0.1963\n",
            "Epoch: 32, time: 7.5089, Training Loss: 0.1478,  Validation loss: 0.1955\n",
            "Epoch: 33, time: 7.6851, Training Loss: 0.1461,  Validation loss: 0.1918\n",
            "Epoch: 34, time: 7.5230, Training Loss: 0.1461,  Validation loss: 0.1975\n",
            "Epoch: 35, time: 7.5344, Training Loss: 0.1434,  Validation loss: 0.1955\n",
            "Epoch: 36, time: 7.5723, Training Loss: 0.1422,  Validation loss: 0.1933\n",
            "Epoch: 37, time: 7.5360, Training Loss: 0.1421,  Validation loss: 0.2069\n",
            "Epoch: 38, time: 7.5316, Training Loss: 0.1419,  Validation loss: 0.1980\n",
            "Epoch: 39, time: 7.5136, Training Loss: 0.1394,  Validation loss: 0.1925\n",
            "Epoch: 40, time: 7.4950, Training Loss: 0.1398,  Validation loss: 0.1952\n",
            "Training time: 302.84586477279663 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_TMF(44,44,44)\n",
        "\n",
        "mm_vid_kinect_tmf = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_tmf.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be938d5-9fbc-4118-8346-5d490e4508d4",
        "id": "swGQ5gaNeBjf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "9.710802137851715\n",
            "4.620647802948952\n",
            "5.426208674907684\n",
            "4.327112436294556\n",
            "5.967482924461365\n",
            "\n",
            "\n",
            "0.8169251439968284\n",
            "0.9149359201282826\n",
            "0.9420737933048791\n",
            "0.9907308523808458\n",
            "0.955774123509396\n",
            "Mean: 6.010 +/- 2.168\n",
            "Mean: 0.924 +/- 0.066\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_tmf= MM_VID_Kinect_TMF(44,44,44)\n",
        "mm_vid_kinect_tmf.load_state_dict(torch.load(path+'_mm_vid_kinect_tmf.pth'))\n",
        "mm_vid_kinect_tmf.to(device)\n",
        "\n",
        "mm_vid_kinect_tmf.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_tmf(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_10=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Weighted Feature Fusion"
      ],
      "metadata": {
        "id": "Zs09ULcJguqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jKbyMmrguqq"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_WFF(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_WFF, self).__init__()\n",
        "\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(3*128,5)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate=GatingModule(128*3)\n",
        "\n",
        "        # Define the gating network\n",
        "        self.gating_net = nn.Sequential(\n",
        "            nn.Linear(128 * 3, 3*128),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out=gating_weights*x\n",
        "        out = self.fc(out)\n",
        "\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5137e82-ab89-4ac9-dcc8-6ef8c3944b1e",
        "id": "a6IkJLUiguqr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 7.7085, Training Loss: 0.3958,  Validation loss: 0.2754\n",
            "Epoch: 2, time: 7.6797, Training Loss: 0.2777,  Validation loss: 0.2436\n",
            "Epoch: 3, time: 7.6443, Training Loss: 0.2519,  Validation loss: 0.2409\n",
            "Epoch: 4, time: 7.6971, Training Loss: 0.2372,  Validation loss: 0.2232\n",
            "Epoch: 5, time: 7.7012, Training Loss: 0.2267,  Validation loss: 0.2219\n",
            "Epoch: 6, time: 7.6915, Training Loss: 0.2175,  Validation loss: 0.2185\n",
            "Epoch: 7, time: 7.6951, Training Loss: 0.2096,  Validation loss: 0.2201\n",
            "Epoch: 8, time: 7.6695, Training Loss: 0.2031,  Validation loss: 0.2082\n",
            "Epoch: 9, time: 7.7044, Training Loss: 0.1973,  Validation loss: 0.2091\n",
            "Epoch: 10, time: 7.7198, Training Loss: 0.1911,  Validation loss: 0.1986\n",
            "Epoch: 11, time: 7.7006, Training Loss: 0.1872,  Validation loss: 0.1962\n",
            "Epoch: 12, time: 7.7675, Training Loss: 0.1818,  Validation loss: 0.1949\n",
            "Epoch: 13, time: 7.8072, Training Loss: 0.1785,  Validation loss: 0.2020\n",
            "Epoch: 14, time: 7.6996, Training Loss: 0.1750,  Validation loss: 0.1962\n",
            "Epoch: 15, time: 7.8651, Training Loss: 0.1701,  Validation loss: 0.1939\n",
            "Epoch: 16, time: 7.7555, Training Loss: 0.1675,  Validation loss: 0.1918\n",
            "Epoch: 17, time: 7.7505, Training Loss: 0.1648,  Validation loss: 0.1946\n",
            "Epoch: 18, time: 7.7021, Training Loss: 0.1609,  Validation loss: 0.1966\n",
            "Epoch: 19, time: 7.6780, Training Loss: 0.1579,  Validation loss: 0.1909\n",
            "Epoch: 20, time: 7.7188, Training Loss: 0.1557,  Validation loss: 0.1901\n",
            "Epoch: 21, time: 7.7212, Training Loss: 0.1533,  Validation loss: 0.1943\n",
            "Epoch: 22, time: 7.7085, Training Loss: 0.1497,  Validation loss: 0.1910\n",
            "Epoch: 23, time: 7.7090, Training Loss: 0.1487,  Validation loss: 0.1965\n",
            "Epoch: 24, time: 7.6985, Training Loss: 0.1463,  Validation loss: 0.1918\n",
            "Epoch: 25, time: 7.7483, Training Loss: 0.1445,  Validation loss: 0.1965\n",
            "Epoch: 26, time: 7.7401, Training Loss: 0.1422,  Validation loss: 0.1930\n",
            "Epoch: 27, time: 7.7031, Training Loss: 0.1405,  Validation loss: 0.1949\n",
            "Epoch: 28, time: 7.7088, Training Loss: 0.1393,  Validation loss: 0.1911\n",
            "Epoch: 29, time: 7.7301, Training Loss: 0.1370,  Validation loss: 0.1951\n",
            "Epoch: 30, time: 7.7115, Training Loss: 0.1343,  Validation loss: 0.1932\n",
            "Stopping early after 30 epochs\n",
            "Training time: 231.77186131477356 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_WFF(44,44,44)\n",
        "\n",
        "mm_vid_kinect_wff = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_wff.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e65c83-c836-4b82-b10d-84700fb666e2",
        "id": "V00xEGp7guqs"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.84641781449318\n",
            "4.611756280064583\n",
            "4.44442480802536\n",
            "4.170500114560127\n",
            "7.1038298308849335\n",
            "\n",
            "\n",
            "0.8338686973326273\n",
            "0.9178416164477062\n",
            "0.9581643026362656\n",
            "0.9915120712469093\n",
            "0.9598178166915602\n",
            "Mean: 5.835 +/- 2.054\n",
            "Mean: 0.932 +/- 0.061\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_wff= MM_VID_Kinect_WFF(44,44,44)\n",
        "mm_vid_kinect_wff.load_state_dict(torch.load(path+'_mm_vid_kinect_wff.pth'))\n",
        "mm_vid_kinect_wff.to(device)\n",
        "\n",
        "mm_vid_kinect_wff.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_wff(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_11=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Multi-Head self Attention Module"
      ],
      "metadata": {
        "id": "L59Ln4Axi0K9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKEc2mx9i0LC"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_MHA(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_MHA, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(3*128,5)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate=GatingModule(128*3)\n",
        "\n",
        "        # Define the gating network\n",
        "        self.attention=nn.MultiheadAttention(3*128, 4, batch_first=True)\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        out, attn_output_weights=self.attention(x,x,x)\n",
        "        out = self.fc(out)\n",
        "\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a228461b-790e-48de-bb85-7f53e83e0e73",
        "id": "ZAiEuPG0i0LC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 9.1820, Training Loss: 0.4360,  Validation loss: 0.2957\n",
            "Epoch: 2, time: 9.1715, Training Loss: 0.2902,  Validation loss: 0.2671\n",
            "Epoch: 3, time: 9.1745, Training Loss: 0.2619,  Validation loss: 0.2583\n",
            "Epoch: 4, time: 9.1510, Training Loss: 0.2442,  Validation loss: 0.2376\n",
            "Epoch: 5, time: 9.1625, Training Loss: 0.2340,  Validation loss: 0.2336\n",
            "Epoch: 6, time: 9.1726, Training Loss: 0.2239,  Validation loss: 0.2177\n",
            "Epoch: 7, time: 9.1708, Training Loss: 0.2152,  Validation loss: 0.2231\n",
            "Epoch: 8, time: 9.1475, Training Loss: 0.2090,  Validation loss: 0.2123\n",
            "Epoch: 9, time: 9.1688, Training Loss: 0.2032,  Validation loss: 0.2084\n",
            "Epoch: 10, time: 9.1556, Training Loss: 0.1965,  Validation loss: 0.2038\n",
            "Epoch: 11, time: 9.1751, Training Loss: 0.1917,  Validation loss: 0.2022\n",
            "Epoch: 12, time: 9.1582, Training Loss: 0.1871,  Validation loss: 0.2131\n",
            "Epoch: 13, time: 9.1622, Training Loss: 0.1854,  Validation loss: 0.2005\n",
            "Epoch: 14, time: 9.1862, Training Loss: 0.1782,  Validation loss: 0.2039\n",
            "Epoch: 15, time: 9.2196, Training Loss: 0.1755,  Validation loss: 0.2027\n",
            "Epoch: 16, time: 9.1609, Training Loss: 0.1719,  Validation loss: 0.1954\n",
            "Epoch: 17, time: 9.2153, Training Loss: 0.1685,  Validation loss: 0.1971\n",
            "Epoch: 18, time: 9.2304, Training Loss: 0.1654,  Validation loss: 0.1959\n",
            "Epoch: 19, time: 9.3805, Training Loss: 0.1640,  Validation loss: 0.1955\n",
            "Epoch: 20, time: 9.2415, Training Loss: 0.1587,  Validation loss: 0.1927\n",
            "Epoch: 21, time: 9.2554, Training Loss: 0.1579,  Validation loss: 0.2065\n",
            "Epoch: 22, time: 9.2668, Training Loss: 0.1544,  Validation loss: 0.2001\n",
            "Epoch: 23, time: 9.3120, Training Loss: 0.1525,  Validation loss: 0.1932\n",
            "Epoch: 24, time: 9.3027, Training Loss: 0.1521,  Validation loss: 0.1992\n",
            "Epoch: 25, time: 9.3204, Training Loss: 0.1490,  Validation loss: 0.1948\n",
            "Epoch: 26, time: 9.3628, Training Loss: 0.1457,  Validation loss: 0.1937\n",
            "Epoch: 27, time: 9.4385, Training Loss: 0.1437,  Validation loss: 0.1911\n",
            "Epoch: 28, time: 9.2499, Training Loss: 0.1418,  Validation loss: 0.1946\n",
            "Epoch: 29, time: 9.2794, Training Loss: 0.1390,  Validation loss: 0.1919\n",
            "Epoch: 30, time: 9.2863, Training Loss: 0.1379,  Validation loss: 0.1901\n",
            "Epoch: 31, time: 9.2892, Training Loss: 0.1364,  Validation loss: 0.1943\n",
            "Epoch: 32, time: 9.2316, Training Loss: 0.1342,  Validation loss: 0.1944\n",
            "Epoch: 33, time: 9.2274, Training Loss: 0.1335,  Validation loss: 0.1915\n",
            "Epoch: 34, time: 9.3027, Training Loss: 0.1310,  Validation loss: 0.1920\n",
            "Epoch: 35, time: 9.3091, Training Loss: 0.1323,  Validation loss: 0.1900\n",
            "Epoch: 36, time: 9.1799, Training Loss: 0.1300,  Validation loss: 0.1924\n",
            "Epoch: 37, time: 9.2406, Training Loss: 0.1281,  Validation loss: 0.1937\n",
            "Epoch: 38, time: 9.2497, Training Loss: 0.1284,  Validation loss: 0.1917\n",
            "Epoch: 39, time: 9.2614, Training Loss: 0.1251,  Validation loss: 0.1931\n",
            "Epoch: 40, time: 9.2666, Training Loss: 0.1251,  Validation loss: 0.1925\n",
            "Training time: 369.74024510383606 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_MHA(44,44,44)\n",
        "\n",
        "mm_vid_kinect_mha = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_mha.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed3490e-c324-4b84-99a2-ebf568ee8c3c",
        "id": "LSs9E-Rci0LC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "9.726044535636902\n",
            "4.7308821231126785\n",
            "4.439271241426468\n",
            "4.285142570734024\n",
            "6.166763603687286\n",
            "\n",
            "\n",
            "0.8364230399984053\n",
            "0.9138686223916018\n",
            "0.9584234904457378\n",
            "0.9912374143022599\n",
            "0.9597050535437203\n",
            "Mean: 5.870 +/- 2.281\n",
            "Mean: 0.932 +/- 0.060\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_mha= MM_VID_Kinect_MHA(44,44,44)\n",
        "mm_vid_kinect_mha.load_state_dict(torch.load(path+'_mm_vid_kinect_mha.pth'))\n",
        "mm_vid_kinect_mha.to(device)\n",
        "\n",
        "mm_vid_kinect_mha.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_mha(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_12=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 13. MHA+Weighted Feature"
      ],
      "metadata": {
        "id": "41pLtR42ZlSX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVQN048rZlSc"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_mha_wf(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_wf, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(2*3*128,5)\n",
        "\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128, 2*3*128), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2),dim=-1)\n",
        "\n",
        "        # gating_weights_1 = self.gating_net_1(out)\n",
        "        # out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e86b47-e73b-4931-9cf6-20e6c043205f",
        "id": "P3o6dasbZlSd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 9.7658, Training Loss: 0.3871,  Validation loss: 0.2891\n",
            "Epoch: 2, time: 9.8432, Training Loss: 0.2760,  Validation loss: 0.2444\n",
            "Epoch: 3, time: 9.7939, Training Loss: 0.2502,  Validation loss: 0.2325\n",
            "Epoch: 4, time: 9.7548, Training Loss: 0.2331,  Validation loss: 0.2199\n",
            "Epoch: 5, time: 9.7009, Training Loss: 0.2223,  Validation loss: 0.2178\n",
            "Epoch: 6, time: 9.7023, Training Loss: 0.2136,  Validation loss: 0.2088\n",
            "Epoch: 7, time: 9.7179, Training Loss: 0.2076,  Validation loss: 0.2070\n",
            "Epoch: 8, time: 9.7144, Training Loss: 0.1995,  Validation loss: 0.2063\n",
            "Epoch: 9, time: 9.8348, Training Loss: 0.1923,  Validation loss: 0.2016\n",
            "Epoch: 10, time: 9.7546, Training Loss: 0.1887,  Validation loss: 0.2079\n",
            "Epoch: 11, time: 9.7171, Training Loss: 0.1837,  Validation loss: 0.2149\n",
            "Epoch: 12, time: 9.7260, Training Loss: 0.1804,  Validation loss: 0.1967\n",
            "Epoch: 13, time: 9.7054, Training Loss: 0.1744,  Validation loss: 0.2019\n",
            "Epoch: 14, time: 9.9252, Training Loss: 0.1703,  Validation loss: 0.1938\n",
            "Epoch: 15, time: 9.8139, Training Loss: 0.1668,  Validation loss: 0.1964\n",
            "Epoch: 16, time: 9.6773, Training Loss: 0.1643,  Validation loss: 0.1953\n",
            "Epoch: 17, time: 9.7068, Training Loss: 0.1601,  Validation loss: 0.1969\n",
            "Epoch: 18, time: 9.7410, Training Loss: 0.1586,  Validation loss: 0.1944\n",
            "Epoch: 19, time: 9.7098, Training Loss: 0.1558,  Validation loss: 0.1894\n",
            "Epoch: 20, time: 9.7193, Training Loss: 0.1512,  Validation loss: 0.1948\n",
            "Epoch: 21, time: 9.7395, Training Loss: 0.1505,  Validation loss: 0.1922\n",
            "Epoch: 22, time: 9.7246, Training Loss: 0.1478,  Validation loss: 0.1911\n",
            "Epoch: 23, time: 9.7969, Training Loss: 0.1451,  Validation loss: 0.1937\n",
            "Epoch: 24, time: 9.7205, Training Loss: 0.1439,  Validation loss: 0.1884\n",
            "Epoch: 25, time: 9.7164, Training Loss: 0.1404,  Validation loss: 0.1936\n",
            "Epoch: 26, time: 9.7163, Training Loss: 0.1391,  Validation loss: 0.1917\n",
            "Epoch: 27, time: 9.7197, Training Loss: 0.1366,  Validation loss: 0.1914\n",
            "Epoch: 28, time: 9.6936, Training Loss: 0.1361,  Validation loss: 0.1919\n",
            "Epoch: 29, time: 9.6788, Training Loss: 0.1340,  Validation loss: 0.1925\n",
            "Epoch: 30, time: 9.7065, Training Loss: 0.1317,  Validation loss: 0.1903\n",
            "Epoch: 31, time: 9.7016, Training Loss: 0.1305,  Validation loss: 0.1967\n",
            "Epoch: 32, time: 9.6933, Training Loss: 0.1287,  Validation loss: 0.1921\n",
            "Epoch: 33, time: 9.7094, Training Loss: 0.1270,  Validation loss: 0.1912\n",
            "Epoch: 34, time: 9.7111, Training Loss: 0.1254,  Validation loss: 0.1922\n",
            "Stopping early after 34 epochs\n",
            "Training time: 331.44378876686096 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_mha_wf(44,44,44)\n",
        "\n",
        "mm_vid_kinect_mha_wf = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_mha_wf.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anOU6g8FZlSd",
        "outputId": "b26bc4e3-74d7-4630-e5cf-8b81b01a8f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.5945725440979\n",
            "4.577179253101349\n",
            "4.301173612475395\n",
            "4.393631964921951\n",
            "5.432922393083572\n",
            "\n",
            "\n",
            "0.8373940025835596\n",
            "0.9178158439404914\n",
            "0.9629122786221899\n",
            "0.9908655371677644\n",
            "0.9622531210665268\n",
            "Mean: 5.460 +/- 1.809\n",
            "Mean: 0.934 +/- 0.060\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_mha_wf= MM_VID_Kinect_mha_wf(44,44,44)\n",
        "mm_vid_kinect_mha_wf.load_state_dict(torch.load(path+'_mm_vid_kinect_mha_wf.pth'))\n",
        "mm_vid_kinect_mha_wf.to(device)\n",
        "\n",
        "mm_vid_kinect_mha_wf.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_mha_wf(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_13=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 14. MHA+Weighted Feature"
      ],
      "metadata": {
        "id": "hdCqI4d_atC6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spti8EkYatC_"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_mha_wf_fusion(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_wf_fusion, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(2*3*128,5)\n",
        "\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128, 2*3*128), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out=torch.cat((out_1,out_2),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-0bN8KxatC_",
        "outputId": "701dcba4-172b-4714-9098-dff2f0681fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 11.0131, Training Loss: 0.3944,  Validation loss: 0.2838\n",
            "Epoch: 2, time: 10.9982, Training Loss: 0.2761,  Validation loss: 0.2371\n",
            "Epoch: 3, time: 11.0357, Training Loss: 0.2510,  Validation loss: 0.2296\n",
            "Epoch: 4, time: 11.0559, Training Loss: 0.2345,  Validation loss: 0.2251\n",
            "Epoch: 5, time: 11.0282, Training Loss: 0.2226,  Validation loss: 0.2127\n",
            "Epoch: 6, time: 11.0347, Training Loss: 0.2129,  Validation loss: 0.2115\n",
            "Epoch: 7, time: 11.0614, Training Loss: 0.2063,  Validation loss: 0.2088\n",
            "Epoch: 8, time: 11.0350, Training Loss: 0.1999,  Validation loss: 0.2149\n",
            "Epoch: 9, time: 11.0098, Training Loss: 0.1933,  Validation loss: 0.2057\n",
            "Epoch: 10, time: 11.0193, Training Loss: 0.1866,  Validation loss: 0.1982\n",
            "Epoch: 11, time: 11.0314, Training Loss: 0.1824,  Validation loss: 0.2033\n",
            "Epoch: 12, time: 11.0411, Training Loss: 0.1799,  Validation loss: 0.1950\n",
            "Epoch: 13, time: 11.0199, Training Loss: 0.1725,  Validation loss: 0.1938\n",
            "Epoch: 14, time: 11.0116, Training Loss: 0.1700,  Validation loss: 0.1931\n",
            "Epoch: 15, time: 10.9938, Training Loss: 0.1665,  Validation loss: 0.1927\n",
            "Epoch: 16, time: 11.0230, Training Loss: 0.1623,  Validation loss: 0.1916\n",
            "Epoch: 17, time: 11.0255, Training Loss: 0.1604,  Validation loss: 0.1926\n",
            "Epoch: 18, time: 10.9889, Training Loss: 0.1564,  Validation loss: 0.1915\n",
            "Epoch: 19, time: 10.9782, Training Loss: 0.1545,  Validation loss: 0.1914\n",
            "Epoch: 20, time: 10.9577, Training Loss: 0.1513,  Validation loss: 0.1908\n",
            "Epoch: 21, time: 10.9717, Training Loss: 0.1489,  Validation loss: 0.1921\n",
            "Epoch: 22, time: 10.9909, Training Loss: 0.1458,  Validation loss: 0.1906\n",
            "Epoch: 23, time: 10.9908, Training Loss: 0.1437,  Validation loss: 0.1890\n",
            "Epoch: 24, time: 10.9871, Training Loss: 0.1414,  Validation loss: 0.1926\n",
            "Epoch: 25, time: 10.9820, Training Loss: 0.1381,  Validation loss: 0.1869\n",
            "Epoch: 26, time: 10.9895, Training Loss: 0.1363,  Validation loss: 0.1898\n",
            "Epoch: 27, time: 11.0323, Training Loss: 0.1347,  Validation loss: 0.1890\n",
            "Epoch: 28, time: 11.0952, Training Loss: 0.1333,  Validation loss: 0.1890\n",
            "Epoch: 29, time: 11.1212, Training Loss: 0.1323,  Validation loss: 0.1884\n",
            "Epoch: 30, time: 11.0405, Training Loss: 0.1300,  Validation loss: 0.1892\n",
            "Epoch: 31, time: 11.0269, Training Loss: 0.1280,  Validation loss: 0.1898\n",
            "Epoch: 32, time: 11.0012, Training Loss: 0.1262,  Validation loss: 0.1886\n",
            "Epoch: 33, time: 11.0349, Training Loss: 0.1244,  Validation loss: 0.1911\n",
            "Epoch: 34, time: 10.9871, Training Loss: 0.1233,  Validation loss: 0.1911\n",
            "Epoch: 35, time: 11.0138, Training Loss: 0.1230,  Validation loss: 0.1897\n",
            "Stopping early after 35 epochs\n",
            "Training time: 386.1582291126251 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_mha_wf_fusion(44,44,44)\n",
        "\n",
        "mm_vid_kinect_mha_wf_fusion = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_mha_wf_fusion.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiacZqYgatC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c30c1bb-dd2f-41b8-f554-d44f2b5a1ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "9.320904314517975\n",
            "4.392504319548607\n",
            "4.0618646889925\n",
            "4.391077160835266\n",
            "5.411230772733688\n",
            "\n",
            "\n",
            "0.8278305189982623\n",
            "0.9246204163469921\n",
            "0.967547282992581\n",
            "0.9904430201263333\n",
            "0.9686553450204085\n",
            "Mean: 5.516 +/- 2.187\n",
            "Mean: 0.936 +/- 0.065\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_mha_wf_fusion= MM_VID_Kinect_mha_wf_fusion(44,44,44)\n",
        "mm_vid_kinect_mha_wf_fusion.load_state_dict(torch.load(path+'_mm_vid_kinect_mha_wf_fusion.pth'))\n",
        "mm_vid_kinect_mha_wf_fusion.to(device)\n",
        "\n",
        "mm_vid_kinect_mha_wf_fusion.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_mha_wf_fusion(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_14=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 15. Weighted Feature+ Tensor Multiplication Fusion"
      ],
      "metadata": {
        "id": "2FpdLD8gbPcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddKw1iSVbPcM"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_wf_tm(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_wf_tm, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(3*128+128,5)\n",
        "\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(3*128+128, 3*128+128), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        out=torch.cat((out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n2dgzg3bPcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7365c846-f997-4273-c772-4fc8f074bbff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 8.7586, Training Loss: 0.4052,  Validation loss: 0.2779\n",
            "Epoch: 2, time: 8.7648, Training Loss: 0.2824,  Validation loss: 0.2663\n",
            "Epoch: 3, time: 8.7713, Training Loss: 0.2551,  Validation loss: 0.2337\n",
            "Epoch: 4, time: 8.7919, Training Loss: 0.2391,  Validation loss: 0.2215\n",
            "Epoch: 5, time: 8.7470, Training Loss: 0.2281,  Validation loss: 0.2165\n",
            "Epoch: 6, time: 8.7966, Training Loss: 0.2182,  Validation loss: 0.2217\n",
            "Epoch: 7, time: 8.8396, Training Loss: 0.2097,  Validation loss: 0.2092\n",
            "Epoch: 8, time: 8.9253, Training Loss: 0.2063,  Validation loss: 0.2093\n",
            "Epoch: 9, time: 8.9062, Training Loss: 0.1977,  Validation loss: 0.1999\n",
            "Epoch: 10, time: 8.8257, Training Loss: 0.1931,  Validation loss: 0.1973\n",
            "Epoch: 11, time: 8.7985, Training Loss: 0.1878,  Validation loss: 0.1968\n",
            "Epoch: 12, time: 8.7801, Training Loss: 0.1824,  Validation loss: 0.1977\n",
            "Epoch: 13, time: 8.8045, Training Loss: 0.1790,  Validation loss: 0.2034\n",
            "Epoch: 14, time: 8.8700, Training Loss: 0.1745,  Validation loss: 0.1925\n",
            "Epoch: 15, time: 8.8618, Training Loss: 0.1712,  Validation loss: 0.1942\n",
            "Epoch: 16, time: 8.8632, Training Loss: 0.1670,  Validation loss: 0.1964\n",
            "Epoch: 17, time: 8.8298, Training Loss: 0.1649,  Validation loss: 0.1906\n",
            "Epoch: 18, time: 8.8540, Training Loss: 0.1618,  Validation loss: 0.2008\n",
            "Epoch: 19, time: 8.8512, Training Loss: 0.1591,  Validation loss: 0.1923\n",
            "Epoch: 20, time: 8.8651, Training Loss: 0.1560,  Validation loss: 0.1897\n",
            "Epoch: 21, time: 8.8406, Training Loss: 0.1538,  Validation loss: 0.1891\n",
            "Epoch: 22, time: 8.7953, Training Loss: 0.1510,  Validation loss: 0.1906\n",
            "Epoch: 23, time: 8.8299, Training Loss: 0.1496,  Validation loss: 0.1905\n",
            "Epoch: 24, time: 8.8647, Training Loss: 0.1459,  Validation loss: 0.1970\n",
            "Epoch: 25, time: 8.9353, Training Loss: 0.1439,  Validation loss: 0.1938\n",
            "Epoch: 26, time: 8.8966, Training Loss: 0.1428,  Validation loss: 0.1935\n",
            "Epoch: 27, time: 8.9347, Training Loss: 0.1415,  Validation loss: 0.1909\n",
            "Epoch: 28, time: 8.9056, Training Loss: 0.1402,  Validation loss: 0.1922\n",
            "Epoch: 29, time: 8.9441, Training Loss: 0.1377,  Validation loss: 0.1929\n",
            "Epoch: 30, time: 8.9021, Training Loss: 0.1346,  Validation loss: 0.1932\n",
            "Epoch: 31, time: 8.9294, Training Loss: 0.1338,  Validation loss: 0.1905\n",
            "Stopping early after 31 epochs\n",
            "Training time: 274.6186149120331 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_wf_tm(44,44,44)\n",
        "\n",
        "mm_vid_kinect_wf_tm = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_wf_tm.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaoe9wVPbPcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a23a861-1f3c-4240-bef0-526be5997840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.672147244215012\n",
            "4.672251641750336\n",
            "4.018235579133034\n",
            "4.293014109134674\n",
            "5.732771381735802\n",
            "\n",
            "\n",
            "0.8325978752651868\n",
            "0.9134717148082979\n",
            "0.9655444379982279\n",
            "0.9911803908399778\n",
            "0.9648165989290389\n",
            "Mean: 5.478 +/- 1.901\n",
            "Mean: 0.934 +/- 0.063\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_wf_tm= MM_VID_Kinect_wf_tm(44,44,44)\n",
        "mm_vid_kinect_wf_tm.load_state_dict(torch.load(path+'_mm_vid_kinect_wf_tm.pth'))\n",
        "mm_vid_kinect_wf_tm.to(device)\n",
        "\n",
        "mm_vid_kinect_wf_tm.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_wf_tm(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_15=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 16. Weighted Feature+ Tensor Multiplication Fusion"
      ],
      "metadata": {
        "id": "Ki6ZZS_-b9Ak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnJVSVWXb9Ap"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_wf_tm_fusion(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_wf_tm_fusion, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(3*128+128,5)\n",
        "\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(3*128+128, 3*128+128), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        out=torch.cat((out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIdb8bQeb9Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af103ef1-2623-42c9-bca4-c6470ffb82ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 8.8749, Training Loss: 0.4086,  Validation loss: 0.2935\n",
            "Epoch: 2, time: 8.8256, Training Loss: 0.2822,  Validation loss: 0.2474\n",
            "Epoch: 3, time: 8.8165, Training Loss: 0.2538,  Validation loss: 0.2294\n",
            "Epoch: 4, time: 8.8346, Training Loss: 0.2392,  Validation loss: 0.2237\n",
            "Epoch: 5, time: 8.8013, Training Loss: 0.2279,  Validation loss: 0.2143\n",
            "Epoch: 6, time: 8.7752, Training Loss: 0.2182,  Validation loss: 0.2096\n",
            "Epoch: 7, time: 8.8355, Training Loss: 0.2087,  Validation loss: 0.2176\n",
            "Epoch: 8, time: 8.8421, Training Loss: 0.2033,  Validation loss: 0.2104\n",
            "Epoch: 9, time: 8.8568, Training Loss: 0.1976,  Validation loss: 0.2036\n",
            "Epoch: 10, time: 8.7655, Training Loss: 0.1917,  Validation loss: 0.2011\n",
            "Epoch: 11, time: 8.7954, Training Loss: 0.1865,  Validation loss: 0.1949\n",
            "Epoch: 12, time: 8.7915, Training Loss: 0.1825,  Validation loss: 0.2043\n",
            "Epoch: 13, time: 8.7716, Training Loss: 0.1787,  Validation loss: 0.2016\n",
            "Epoch: 14, time: 8.8312, Training Loss: 0.1751,  Validation loss: 0.1953\n",
            "Epoch: 15, time: 8.8109, Training Loss: 0.1710,  Validation loss: 0.1916\n",
            "Epoch: 16, time: 8.7889, Training Loss: 0.1673,  Validation loss: 0.1910\n",
            "Epoch: 17, time: 8.8130, Training Loss: 0.1642,  Validation loss: 0.1925\n",
            "Epoch: 18, time: 8.8334, Training Loss: 0.1623,  Validation loss: 0.1937\n",
            "Epoch: 19, time: 8.8121, Training Loss: 0.1592,  Validation loss: 0.1909\n",
            "Epoch: 20, time: 8.7968, Training Loss: 0.1557,  Validation loss: 0.1938\n",
            "Epoch: 21, time: 8.8210, Training Loss: 0.1543,  Validation loss: 0.1901\n",
            "Epoch: 22, time: 8.8486, Training Loss: 0.1506,  Validation loss: 0.1931\n",
            "Epoch: 23, time: 8.8539, Training Loss: 0.1489,  Validation loss: 0.1919\n",
            "Epoch: 24, time: 8.8213, Training Loss: 0.1462,  Validation loss: 0.1925\n",
            "Epoch: 25, time: 8.8373, Training Loss: 0.1454,  Validation loss: 0.1942\n",
            "Epoch: 26, time: 8.8270, Training Loss: 0.1425,  Validation loss: 0.1916\n",
            "Epoch: 27, time: 8.7685, Training Loss: 0.1411,  Validation loss: 0.1906\n",
            "Epoch: 28, time: 8.9010, Training Loss: 0.1379,  Validation loss: 0.1919\n",
            "Epoch: 29, time: 8.8848, Training Loss: 0.1361,  Validation loss: 0.1967\n",
            "Epoch: 30, time: 8.9215, Training Loss: 0.1358,  Validation loss: 0.1932\n",
            "Epoch: 31, time: 8.8535, Training Loss: 0.1338,  Validation loss: 0.1924\n",
            "Stopping early after 31 epochs\n",
            "Training time: 273.95480489730835 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_wf_tm_fusion(44,44,44)\n",
        "\n",
        "mm_vid_kinect_wf_tm_fusion = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_wf_tm_fusion.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWShuQQjb9Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da4d718-3fa7-46cc-c513-838f9cb37182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.245138823986053\n",
            "4.864665120840073\n",
            "4.271528124809265\n",
            "3.863566741347313\n",
            "6.230974569916725\n",
            "\n",
            "\n",
            "0.8465985134143887\n",
            "0.9092700839684049\n",
            "0.9611375865410884\n",
            "0.9924358467508047\n",
            "0.962344102887244\n",
            "Mean: 5.495 +/- 1.779\n",
            "Mean: 0.934 +/- 0.057\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_wf_tm_fusion= MM_VID_Kinect_wf_tm_fusion(44,44,44)\n",
        "mm_vid_kinect_wf_tm_fusion.load_state_dict(torch.load(path+'_mm_vid_kinect_wf_tm_fusion.pth'))\n",
        "mm_vid_kinect_wf_tm_fusion.to(device)\n",
        "\n",
        "mm_vid_kinect_wf_tm_fusion.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_wf_tm_fusion(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_16=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 17.  MHA+Tensor Multiplication Fusion"
      ],
      "metadata": {
        "id": "h1eVUqyjch3B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ6tTlj3ch3P"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_mha_tm(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_tm, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(3*128+128,5)\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(3*128+128, 3*128+128), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        out=torch.cat((out_1,out_3),dim=-1)\n",
        "\n",
        "        # gating_weights_1 = self.gating_net_1(out)\n",
        "        # out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp3X9WMYch3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2863abe9-b66d-4271-b8df-fb1b4b066bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 9.6070, Training Loss: 0.4286,  Validation loss: 0.2842\n",
            "Epoch: 2, time: 9.5872, Training Loss: 0.2878,  Validation loss: 0.2752\n",
            "Epoch: 3, time: 9.5441, Training Loss: 0.2619,  Validation loss: 0.2428\n",
            "Epoch: 4, time: 9.5229, Training Loss: 0.2448,  Validation loss: 0.2434\n",
            "Epoch: 5, time: 9.5060, Training Loss: 0.2325,  Validation loss: 0.2235\n",
            "Epoch: 6, time: 9.5333, Training Loss: 0.2224,  Validation loss: 0.2118\n",
            "Epoch: 7, time: 9.5545, Training Loss: 0.2163,  Validation loss: 0.2298\n",
            "Epoch: 8, time: 9.5839, Training Loss: 0.2114,  Validation loss: 0.2093\n",
            "Epoch: 9, time: 9.5020, Training Loss: 0.2021,  Validation loss: 0.2122\n",
            "Epoch: 10, time: 9.5290, Training Loss: 0.1972,  Validation loss: 0.2069\n",
            "Epoch: 11, time: 9.5838, Training Loss: 0.1925,  Validation loss: 0.2017\n",
            "Epoch: 12, time: 9.5634, Training Loss: 0.1881,  Validation loss: 0.2017\n",
            "Epoch: 13, time: 9.5675, Training Loss: 0.1828,  Validation loss: 0.2001\n",
            "Epoch: 14, time: 9.4892, Training Loss: 0.1797,  Validation loss: 0.1987\n",
            "Epoch: 15, time: 9.5264, Training Loss: 0.1765,  Validation loss: 0.2014\n",
            "Epoch: 16, time: 9.4931, Training Loss: 0.1740,  Validation loss: 0.1999\n",
            "Epoch: 17, time: 9.5638, Training Loss: 0.1682,  Validation loss: 0.2018\n",
            "Epoch: 18, time: 9.4994, Training Loss: 0.1673,  Validation loss: 0.1977\n",
            "Epoch: 19, time: 9.5602, Training Loss: 0.1624,  Validation loss: 0.2120\n",
            "Epoch: 20, time: 9.5735, Training Loss: 0.1610,  Validation loss: 0.1902\n",
            "Epoch: 21, time: 9.5938, Training Loss: 0.1582,  Validation loss: 0.1933\n",
            "Epoch: 22, time: 9.5647, Training Loss: 0.1551,  Validation loss: 0.2038\n",
            "Epoch: 23, time: 9.5959, Training Loss: 0.1550,  Validation loss: 0.1914\n",
            "Epoch: 24, time: 9.5670, Training Loss: 0.1501,  Validation loss: 0.2038\n",
            "Epoch: 25, time: 9.6000, Training Loss: 0.1479,  Validation loss: 0.2000\n",
            "Epoch: 26, time: 9.5817, Training Loss: 0.1466,  Validation loss: 0.1926\n",
            "Epoch: 27, time: 9.5241, Training Loss: 0.1447,  Validation loss: 0.1925\n",
            "Epoch: 28, time: 9.5402, Training Loss: 0.1419,  Validation loss: 0.1947\n",
            "Epoch: 29, time: 9.5739, Training Loss: 0.1390,  Validation loss: 0.1916\n",
            "Epoch: 30, time: 9.5405, Training Loss: 0.1396,  Validation loss: 0.1897\n",
            "Epoch: 31, time: 9.5615, Training Loss: 0.1367,  Validation loss: 0.1939\n",
            "Epoch: 32, time: 9.5401, Training Loss: 0.1357,  Validation loss: 0.1933\n",
            "Epoch: 33, time: 9.5402, Training Loss: 0.1352,  Validation loss: 0.1945\n",
            "Epoch: 34, time: 9.5187, Training Loss: 0.1317,  Validation loss: 0.1924\n",
            "Epoch: 35, time: 9.6421, Training Loss: 0.1312,  Validation loss: 0.1986\n",
            "Epoch: 36, time: 9.5547, Training Loss: 0.1307,  Validation loss: 0.1910\n",
            "Epoch: 37, time: 9.5615, Training Loss: 0.1287,  Validation loss: 0.1937\n",
            "Epoch: 38, time: 9.5117, Training Loss: 0.1280,  Validation loss: 0.1964\n",
            "Epoch: 39, time: 9.5264, Training Loss: 0.1273,  Validation loss: 0.1902\n",
            "Epoch: 40, time: 9.5092, Training Loss: 0.1247,  Validation loss: 0.1965\n",
            "Stopping early after 40 epochs\n",
            "Training time: 382.377400636673 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_mha_tm(44,44,44)\n",
        "\n",
        "mm_vid_kinect_mha_tm= train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_mha_tm.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jQ5xV_Tch3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0faa62-10bf-443c-be7c-74c897d4fd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.715292811393738\n",
            "4.788359627127647\n",
            "4.286958649754524\n",
            "4.3616339564323425\n",
            "5.443362519145012\n",
            "\n",
            "\n",
            "0.8356676757985283\n",
            "0.910722150220424\n",
            "0.961378677921794\n",
            "0.9904517473161482\n",
            "0.9643489262754685\n",
            "Mean: 5.519 +/- 1.845\n",
            "Mean: 0.933 +/- 0.061\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_mha_tm= MM_VID_Kinect_mha_tm(44,44,44)\n",
        "mm_vid_kinect_mha_tm.load_state_dict(torch.load(path+'_mm_vid_kinect_mha_tm.pth'))\n",
        "mm_vid_kinect_mha_tm.to(device)\n",
        "\n",
        "mm_vid_kinect_mha_tm.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_mha_tm(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_17=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 18. Fusion of MHA+Tensor Multiplication Fusion"
      ],
      "metadata": {
        "id": "lu1YiUDKeOeK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGejTgt-eOeP"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_mha_tm_fusion(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_tm_fusion, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(3*128+128,5)\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(3*128+128, 3*128+128), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        out=torch.cat((out_1,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY1zaEDreOeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f413558f-bc9f-48e6-fa9e-4cc2fe331204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 10.1493, Training Loss: 0.4417,  Validation loss: 0.3090\n",
            "Epoch: 2, time: 10.1951, Training Loss: 0.2880,  Validation loss: 0.2624\n",
            "Epoch: 3, time: 10.1586, Training Loss: 0.2626,  Validation loss: 0.2366\n",
            "Epoch: 4, time: 10.1821, Training Loss: 0.2467,  Validation loss: 0.2366\n",
            "Epoch: 5, time: 10.1619, Training Loss: 0.2316,  Validation loss: 0.2316\n",
            "Epoch: 6, time: 10.1417, Training Loss: 0.2221,  Validation loss: 0.2258\n",
            "Epoch: 7, time: 10.1269, Training Loss: 0.2125,  Validation loss: 0.2214\n",
            "Epoch: 8, time: 10.1533, Training Loss: 0.2068,  Validation loss: 0.2119\n",
            "Epoch: 9, time: 10.1963, Training Loss: 0.2014,  Validation loss: 0.2082\n",
            "Epoch: 10, time: 10.2119, Training Loss: 0.1948,  Validation loss: 0.1989\n",
            "Epoch: 11, time: 10.1858, Training Loss: 0.1895,  Validation loss: 0.2061\n",
            "Epoch: 12, time: 10.1441, Training Loss: 0.1845,  Validation loss: 0.2062\n",
            "Epoch: 13, time: 10.1678, Training Loss: 0.1800,  Validation loss: 0.2044\n",
            "Epoch: 14, time: 10.1719, Training Loss: 0.1777,  Validation loss: 0.1951\n",
            "Epoch: 15, time: 10.3333, Training Loss: 0.1734,  Validation loss: 0.1964\n",
            "Epoch: 16, time: 10.1771, Training Loss: 0.1702,  Validation loss: 0.1965\n",
            "Epoch: 17, time: 10.2008, Training Loss: 0.1665,  Validation loss: 0.1940\n",
            "Epoch: 18, time: 10.3687, Training Loss: 0.1627,  Validation loss: 0.1927\n",
            "Epoch: 19, time: 10.8277, Training Loss: 0.1598,  Validation loss: 0.2049\n",
            "Epoch: 20, time: 10.2618, Training Loss: 0.1572,  Validation loss: 0.1975\n",
            "Epoch: 21, time: 10.4117, Training Loss: 0.1549,  Validation loss: 0.1983\n",
            "Epoch: 22, time: 10.8940, Training Loss: 0.1531,  Validation loss: 0.1909\n",
            "Epoch: 23, time: 11.0619, Training Loss: 0.1516,  Validation loss: 0.1908\n",
            "Epoch: 24, time: 10.4836, Training Loss: 0.1476,  Validation loss: 0.1933\n",
            "Epoch: 25, time: 10.1678, Training Loss: 0.1442,  Validation loss: 0.2035\n",
            "Epoch: 26, time: 10.2142, Training Loss: 0.1438,  Validation loss: 0.1917\n",
            "Epoch: 27, time: 10.1499, Training Loss: 0.1413,  Validation loss: 0.1915\n",
            "Epoch: 28, time: 10.1936, Training Loss: 0.1412,  Validation loss: 0.1881\n",
            "Epoch: 29, time: 10.1884, Training Loss: 0.1376,  Validation loss: 0.1901\n",
            "Epoch: 30, time: 10.1572, Training Loss: 0.1343,  Validation loss: 0.1925\n",
            "Epoch: 31, time: 10.1671, Training Loss: 0.1335,  Validation loss: 0.1902\n",
            "Epoch: 32, time: 10.1550, Training Loss: 0.1325,  Validation loss: 0.1913\n",
            "Epoch: 33, time: 10.1784, Training Loss: 0.1306,  Validation loss: 0.1906\n",
            "Epoch: 34, time: 10.1831, Training Loss: 0.1303,  Validation loss: 0.1919\n",
            "Epoch: 35, time: 10.2039, Training Loss: 0.1281,  Validation loss: 0.1925\n",
            "Epoch: 36, time: 10.1790, Training Loss: 0.1273,  Validation loss: 0.1910\n",
            "Epoch: 37, time: 10.1893, Training Loss: 0.1275,  Validation loss: 0.1960\n",
            "Epoch: 38, time: 10.1499, Training Loss: 0.1257,  Validation loss: 0.1952\n",
            "Stopping early after 38 epochs\n",
            "Training time: 390.28579235076904 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_mha_tm_fusion(44,44,44)\n",
        "\n",
        "mm_vid_kinect_mha_tm_fusion= train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_mha_tm_fusion.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7-syicheOeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad21f9f-8550-4aa1-ef13-8a93e21c108c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.726964890956879\n",
            "4.274912923574448\n",
            "4.107118770480156\n",
            "4.392122849822044\n",
            "5.423568561673164\n",
            "\n",
            "\n",
            "0.8396133709904404\n",
            "0.9279843231067009\n",
            "0.9679448290750322\n",
            "0.9908422187224102\n",
            "0.9668876218141117\n",
            "Mean: 5.385 +/- 1.938\n",
            "Mean: 0.939 +/- 0.060\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_mha_tm_fusion= MM_VID_Kinect_mha_tm_fusion(44,44,44)\n",
        "mm_vid_kinect_mha_tm_fusion.load_state_dict(torch.load(path+'_mm_vid_kinect_mha_tm_fusion.pth'))\n",
        "mm_vid_kinect_mha_tm_fusion.to(device)\n",
        "\n",
        "mm_vid_kinect_mha_tm_fusion.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_mha_tm_fusion(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_18=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 19. MHA+Weighted Feature+ Tensor Multiplication Fusion"
      ],
      "metadata": {
        "id": "0CM6QeeUZSvq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsoHwI6kZSv0"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_mha_wf_tm(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_wf_tm, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(2*3*128+128,5)\n",
        "\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        # gating_weights_1 = self.gating_net_1(out)\n",
        "        # out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_zo-CakZSv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c29e25a-f2ec-4b95-a33e-ea0d9b2fbab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 9.9973, Training Loss: 0.3901,  Validation loss: 0.2962\n",
            "Epoch: 2, time: 10.0133, Training Loss: 0.2761,  Validation loss: 0.2464\n",
            "Epoch: 3, time: 9.9871, Training Loss: 0.2522,  Validation loss: 0.2443\n",
            "Epoch: 4, time: 9.9675, Training Loss: 0.2362,  Validation loss: 0.2171\n",
            "Epoch: 5, time: 9.9846, Training Loss: 0.2254,  Validation loss: 0.2211\n",
            "Epoch: 6, time: 9.9954, Training Loss: 0.2136,  Validation loss: 0.2137\n",
            "Epoch: 7, time: 9.9946, Training Loss: 0.2071,  Validation loss: 0.2124\n",
            "Epoch: 8, time: 10.0023, Training Loss: 0.2029,  Validation loss: 0.2026\n",
            "Epoch: 9, time: 9.9866, Training Loss: 0.1965,  Validation loss: 0.2022\n",
            "Epoch: 10, time: 10.0194, Training Loss: 0.1894,  Validation loss: 0.2054\n",
            "Epoch: 11, time: 10.0379, Training Loss: 0.1856,  Validation loss: 0.1972\n",
            "Epoch: 12, time: 10.0081, Training Loss: 0.1800,  Validation loss: 0.1962\n",
            "Epoch: 13, time: 9.9845, Training Loss: 0.1781,  Validation loss: 0.1994\n",
            "Epoch: 14, time: 9.9956, Training Loss: 0.1737,  Validation loss: 0.1932\n",
            "Epoch: 15, time: 10.0321, Training Loss: 0.1692,  Validation loss: 0.1964\n",
            "Epoch: 16, time: 10.2177, Training Loss: 0.1656,  Validation loss: 0.1905\n",
            "Epoch: 17, time: 10.0318, Training Loss: 0.1637,  Validation loss: 0.1966\n",
            "Epoch: 18, time: 10.0542, Training Loss: 0.1591,  Validation loss: 0.1920\n",
            "Epoch: 19, time: 10.0629, Training Loss: 0.1572,  Validation loss: 0.1922\n",
            "Epoch: 20, time: 9.9795, Training Loss: 0.1539,  Validation loss: 0.1917\n",
            "Epoch: 21, time: 10.0114, Training Loss: 0.1515,  Validation loss: 0.1951\n",
            "Epoch: 22, time: 9.9795, Training Loss: 0.1499,  Validation loss: 0.1895\n",
            "Epoch: 23, time: 10.1690, Training Loss: 0.1461,  Validation loss: 0.1931\n",
            "Epoch: 24, time: 10.0701, Training Loss: 0.1447,  Validation loss: 0.1896\n",
            "Epoch: 25, time: 10.0333, Training Loss: 0.1428,  Validation loss: 0.1911\n",
            "Epoch: 26, time: 9.9776, Training Loss: 0.1405,  Validation loss: 0.1942\n",
            "Epoch: 27, time: 10.0164, Training Loss: 0.1387,  Validation loss: 0.1910\n",
            "Epoch: 28, time: 9.9593, Training Loss: 0.1363,  Validation loss: 0.1911\n",
            "Epoch: 29, time: 9.9758, Training Loss: 0.1347,  Validation loss: 0.1918\n",
            "Epoch: 30, time: 9.9644, Training Loss: 0.1328,  Validation loss: 0.1919\n",
            "Epoch: 31, time: 10.0131, Training Loss: 0.1318,  Validation loss: 0.1926\n",
            "Epoch: 32, time: 10.1619, Training Loss: 0.1305,  Validation loss: 0.1906\n",
            "Stopping early after 32 epochs\n",
            "Training time: 321.06633615493774 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_mha_wf_tm(44,44,44)\n",
        "\n",
        "mm_vid_kinect_mha_wf_tm = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_mha_wf_tm.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAVWgNQrZSv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563f36dc-94b7-4695-fb04-f4c21390a296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 50, 5)\n",
            "8.340880274772644\n",
            "4.646036401391029\n",
            "4.255438968539238\n",
            "4.278041794896126\n",
            "5.927637964487076\n",
            "\n",
            "\n",
            "0.8462332407189764\n",
            "0.9170319590139404\n",
            "0.9634916360811786\n",
            "0.9912283655798835\n",
            "0.9622574570411735\n",
            "Mean: 5.490 +/- 1.734\n",
            "Mean: 0.936 +/- 0.057\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_mha_wf_tm= MM_VID_Kinect_mha_wf_tm(44,44,44)\n",
        "mm_vid_kinect_mha_wf_tm.load_state_dict(torch.load(path+'_mm_vid_kinect_mha_wf_tm.pth'))\n",
        "mm_vid_kinect_mha_wf_tm.to(device)\n",
        "\n",
        "mm_vid_kinect_mha_wf_tm.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_mha_wf_tm(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_19=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 20. Weighted Fusion of MHA+Weighted Feature+ Tensor Multiplication Fusion"
      ],
      "metadata": {
        "id": "YWACO0Dv6ZOU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot1o_CiD6dOp"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_mha_wf_tm_fusion(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_wf_tm_fusion, self).__init__()\n",
        "\n",
        "        self.gcn_1=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_2=GraphConvolutionalNetwork(4,4)\n",
        "        self.gcn_3=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc_1 = nn.Linear(44, 128)\n",
        "        self.fc_gc_2 = nn.Linear(44, 128)\n",
        "        self.fc_gc_3 = nn.Linear(44, 128)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(2*3*128+128,5)\n",
        "\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn_1(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn_2(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn_3(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc_1(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc_2(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc_3(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF4FRk0F6dOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0695bc5b-494e-471b-c2e3-0b13e6e377ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 11.1719, Training Loss: 0.3965,  Validation loss: 0.2920\n",
            "Epoch: 2, time: 11.1568, Training Loss: 0.2761,  Validation loss: 0.2593\n",
            "Epoch: 3, time: 11.2015, Training Loss: 0.2494,  Validation loss: 0.2332\n",
            "Epoch: 4, time: 11.4799, Training Loss: 0.2351,  Validation loss: 0.2212\n",
            "Epoch: 5, time: 11.4203, Training Loss: 0.2212,  Validation loss: 0.2130\n",
            "Epoch: 6, time: 11.3546, Training Loss: 0.2150,  Validation loss: 0.2194\n",
            "Epoch: 7, time: 11.4293, Training Loss: 0.2066,  Validation loss: 0.2074\n",
            "Epoch: 8, time: 11.4838, Training Loss: 0.2006,  Validation loss: 0.2037\n",
            "Epoch: 9, time: 11.5146, Training Loss: 0.1940,  Validation loss: 0.1994\n",
            "Epoch: 10, time: 11.5546, Training Loss: 0.1885,  Validation loss: 0.1961\n",
            "Epoch: 11, time: 11.5794, Training Loss: 0.1843,  Validation loss: 0.1985\n",
            "Epoch: 12, time: 11.5622, Training Loss: 0.1790,  Validation loss: 0.1968\n",
            "Epoch: 13, time: 11.7598, Training Loss: 0.1747,  Validation loss: 0.1965\n",
            "Epoch: 14, time: 11.6354, Training Loss: 0.1712,  Validation loss: 0.1917\n",
            "Epoch: 15, time: 11.6820, Training Loss: 0.1665,  Validation loss: 0.1928\n",
            "Epoch: 16, time: 11.7455, Training Loss: 0.1638,  Validation loss: 0.1935\n",
            "Epoch: 17, time: 11.7375, Training Loss: 0.1596,  Validation loss: 0.1976\n",
            "Epoch: 18, time: 11.7552, Training Loss: 0.1560,  Validation loss: 0.1934\n",
            "Epoch: 19, time: 11.7394, Training Loss: 0.1544,  Validation loss: 0.1884\n",
            "Epoch: 20, time: 11.7496, Training Loss: 0.1507,  Validation loss: 0.1927\n",
            "Epoch: 21, time: 11.7941, Training Loss: 0.1484,  Validation loss: 0.1888\n",
            "Epoch: 22, time: 11.8021, Training Loss: 0.1447,  Validation loss: 0.1898\n",
            "Epoch: 23, time: 11.8288, Training Loss: 0.1430,  Validation loss: 0.1935\n",
            "Epoch: 24, time: 11.8094, Training Loss: 0.1406,  Validation loss: 0.1892\n",
            "Epoch: 25, time: 11.8184, Training Loss: 0.1397,  Validation loss: 0.1910\n",
            "Epoch: 26, time: 11.8489, Training Loss: 0.1371,  Validation loss: 0.1916\n",
            "Epoch: 27, time: 11.8415, Training Loss: 0.1348,  Validation loss: 0.1919\n",
            "Epoch: 28, time: 11.8345, Training Loss: 0.1314,  Validation loss: 0.1918\n",
            "Epoch: 29, time: 11.9598, Training Loss: 0.1311,  Validation loss: 0.1916\n",
            "Stopping early after 29 epochs\n",
            "Training time: 337.58218240737915 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = MM_VID_Kinect_mha_wf_tm_fusion(44,44,44)\n",
        "\n",
        "mm_vid_kinect_mha_wf_tm_fusion = train_mm_2D_vel_acc(train_loader, lr,40,model,path+'_mm_vid_kinect_mha_wf_tm_fusion.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdCExhhL6dOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48698d54-0fdf-4230-c75a-440164c3fb24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1447, 50, 5)\n",
            "6.937180459499359\n",
            "7.745284587144852\n",
            "5.831065773963928\n",
            "5.728035792708397\n",
            "4.8063598573207855\n",
            "\n",
            "\n",
            "0.7849637388700369\n",
            "0.8816054521979472\n",
            "0.9209600646780922\n",
            "0.9804493287420135\n",
            "0.9480632595104066\n",
            "Mean: 6.210 +/- 1.144\n",
            "Mean: 0.903 +/- 0.075\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_mha_wf_tm_fusion= MM_VID_Kinect_mha_wf_tm_fusion(44,44,44)\n",
        "mm_vid_kinect_mha_wf_tm_fusion.load_state_dict(torch.load(path+'_mm_vid_kinect_mha_wf_tm_fusion.pth'))\n",
        "mm_vid_kinect_mha_wf_tm_fusion.to(device)\n",
        "\n",
        "mm_vid_kinect_mha_wf_tm_fusion.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x = mm_vid_kinect_mha_wf_tm_fusion(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_20=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Distillation+ Pre-trained Fine Tuning"
      ],
      "metadata": {
        "id": "3cUkKd7nOHCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "sapji0Z_KAPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "him947Hq_1oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])"
      ],
      "metadata": {
        "id": "vkfoiFyxAv7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "        support = torch.matmul(x, self.weight)\n",
        "        output = torch.matmul(adjacency_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features):\n",
        "        super(GraphConvolutionalNetwork, self).__init__()\n",
        "        self.gc1 = GraphConvolution(in_features, hidden_features)\n",
        "        self.dropout=nn.Dropout(p=0.10)\n",
        "        self.attention = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "\n",
        "        attention_weights = self.attention(x)\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "\n",
        "        print(attention_weights)\n",
        "        # Apply the attention weights to the input features.\n",
        "        weighted_features = attention_weights * x\n",
        "\n",
        "\n",
        "        x = F.relu(self.gc1(weighted_features, adjacency_matrix))\n",
        "        x=self.dropout(x)\n",
        "        # x = F.relu(self.gc2(x, adjacency_matrix))\n",
        "        # x=self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "AVnjNbklAv7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teacher Model"
      ],
      "metadata": {
        "id": "OpJ7Y4yoOHCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Teacher Model\n",
        "\n",
        "def train_mm_m(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    # criterion =nn.MSELoss()\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "\n",
        "    # criterion=PearsonCorrLoss()\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output,x= model(data_acc.to(device).float(),data_gyr.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output,x= model(data_acc.to(device).float(),data_gyr.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "j8ulAgA56WfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Weighted Fusion of MHA+Weighted Feature+ Tensor Multiplication Fusion\n",
        "\n",
        "class MM_mha_wf_tm_fusion(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr,input_2D, drop_prob=0.25):\n",
        "        super(MM_mha_wf_tm_fusion, self).__init__()\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2d=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2d= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.gcn=GraphConvolutionalNetwork(4,4)\n",
        "        self.gate=GatingModule(128)\n",
        "\n",
        "        self.fc = nn.Linear(2*3*128+128,5)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.fc_gc = nn.Linear(44, 128)\n",
        "\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "        self.fc_kd = nn.Linear(3*128, 3*128)\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2d):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2d_1=x_2d.view(x_2d.size(0)*x_2d.size(1),x_2d.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2d_1=self.BN_2d(x_2d_1)\n",
        "\n",
        "        # x_2D_3=x_2d_1.view(-1, 11, 4)\n",
        "        # x_2D_3=self.gcn(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        # x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "        # x_2D_3=self.fc_gc(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, 50, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, 50, x_gyr_1.size(-1))\n",
        "        x_2d_2=x_2d_1.view(-1, 50, x_2d_1.size(-1))\n",
        "\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2d=self.encoder_2d(x_2d_2)\n",
        "\n",
        "        # x_2d=self.gate(x_2d,x_2D_3)\n",
        "        x=torch.cat((x_acc,x_gyr,x_2d),dim=-1)\n",
        "\n",
        "        x_1=self.fc_kd(x)\n",
        "\n",
        "        # x_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out_3=x_acc*x_gyr*x_2d\n",
        "\n",
        "        out_c=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out_c)\n",
        "        out_f=gating_weights_1*out_c\n",
        "\n",
        "        out=self.fc(out_f)\n",
        "\n",
        "        return out, x_1"
      ],
      "metadata": {
        "id": "XYQ-IK0eOHCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = MM_mha_wf_tm_fusion(24,24,44)\n",
        "\n",
        "mm_mha_wf_tm_fusion = train_mm_m(train_loader, lr,40,model,path+'_teacher_IMU8_2D.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "fd6feb4c-a391-43b1-dd72-81c79ae4a89c",
        "id": "4TBPwOQ6OHCh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 9.8652, Training Loss: 0.3208,  Validation loss: 0.2007\n",
            "Epoch: 2, time: 8.8412, Training Loss: 0.2052,  Validation loss: 0.1725\n",
            "Epoch: 3, time: 8.9204, Training Loss: 0.1814,  Validation loss: 0.1599\n",
            "Epoch: 4, time: 8.9658, Training Loss: 0.1685,  Validation loss: 0.1533\n",
            "Epoch: 5, time: 8.9074, Training Loss: 0.1592,  Validation loss: 0.1506\n",
            "Epoch: 6, time: 8.9535, Training Loss: 0.1514,  Validation loss: 0.1464\n",
            "Epoch: 7, time: 9.0066, Training Loss: 0.1452,  Validation loss: 0.1358\n",
            "Epoch: 8, time: 9.0723, Training Loss: 0.1418,  Validation loss: 0.1427\n",
            "Epoch: 9, time: 9.1658, Training Loss: 0.1387,  Validation loss: 0.1361\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-25dab27b6983>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMM_mha_wf_tm_fusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmm_mha_wf_tm_fusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mm_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_teacher_IMU8_2D.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-0e8f4569cb7b>\u001b[0m in \u001b[0;36mtrain_mm_m\u001b[0;34m(train_loader, learn_rate, EPOCHS, model, filename)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_gyr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_velocity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_acceleration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_gyr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-1efc781d5574>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_acc, x_gyr, x_2d)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mout_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mgating_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgating_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mout_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgating_weights\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_buffers'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_mha_wf_tm_fusion= MM_mha_wf_tm_fusion(24,24,44)\n",
        "mm_mha_wf_tm_fusion.load_state_dict(torch.load(path+'_teacher_IMU8_2D.pth'))\n",
        "mm_mha_wf_tm_fusion.to(device)\n",
        "\n",
        "mm_mha_wf_tm_fusion.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x= mm_mha_wf_tm_fusion(data_acc.to(device).float(),data_gyr.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_21=np.hstack([rmse,p])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac76edc-76f6-4d32-92eb-00d66a5d86c7",
        "id": "C7AMpqJzOHCh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1447, 50, 5)\n",
            "5.653554201126099\n",
            "5.8398135006427765\n",
            "3.877450153231621\n",
            "3.889244422316551\n",
            "3.8509447127580643\n",
            "\n",
            "\n",
            "0.8577964324282655\n",
            "0.9482902795283445\n",
            "0.9677606455900711\n",
            "0.9917336891774472\n",
            "0.9676777905687463\n",
            "Mean: 4.622 +/- 1.029\n",
            "Mean: 0.947 +/- 0.052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Student+Pre-training"
      ],
      "metadata": {
        "id": "0uyvUraYOHCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainmm_encoder(train_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.L1Loss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "    # criterion_2=contrastive_loss()\n",
        "    # criterion_2 = nn.KLDivLoss()\n",
        "    # Instantiate the AttentionLayerLoss module\n",
        "    attention_loss = AttentionLayerLoss()\n",
        "    attention_loss = attention_loss.to(device)\n",
        "\n",
        "    criterion_KD=AttentionLayerLoss().to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            x_student, x_student_1= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss=criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            total_loss= loss\n",
        "\n",
        "            total_running_loss += total_loss.item()\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        a=total_running_loss/len(train_loader)\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f}\")\n",
        "        torch.save(model.state_dict(), filename)\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "9Lq6uCi66WfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MM_VID_Kinect_mha_wf_tm_fusion_encoder(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_wf_tm_fusion_encoder, self).__init__()\n",
        "\n",
        "        self.gcn=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc = nn.Linear(44, 128)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(2*3*128+128,5)\n",
        "\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "        self.fc_kd = nn.Linear(3*128, 3*128)\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        x_1=self.fc_kd(x)\n",
        "\n",
        "        # x_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        # out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        # gating_weights = self.gating_net(x)\n",
        "        # out_2=gating_weights*x\n",
        "\n",
        "        # out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        # out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        # gating_weights_1 = self.gating_net_1(out)\n",
        "        # out=gating_weights_1*out\n",
        "\n",
        "        # out=self.fc(out)\n",
        "\n",
        "        return x, x_1\n"
      ],
      "metadata": {
        "id": "EJielY927HEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "student = MM_VID_Kinect_mha_wf_tm_fusion_encoder(44,44,44)\n",
        "\n",
        "teacher= MM_mha_wf_tm_fusion(24,24,44)\n",
        "teacher.load_state_dict(torch.load(path+'_teacher_IMU8_2D.pth'))\n",
        "teacher.to(device)\n",
        "\n",
        "student_KD= trainmm_encoder(train_loader, lr,100, student,path+'best_model_student_encoder_KD.pth', teacher)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "2b80a819-7403-4ad8-9046-9371cd919068",
        "id": "VeZh5DcW6WfE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 9.6034, Training Loss: 0.1421\n",
            "Epoch: 2, time: 9.5950, Training Loss: 0.1304\n",
            "Epoch: 3, time: 9.6244, Training Loss: 0.1281\n",
            "Epoch: 4, time: 9.5777, Training Loss: 0.1269\n",
            "Epoch: 5, time: 9.5428, Training Loss: 0.1261\n",
            "Epoch: 6, time: 9.5035, Training Loss: 0.1256\n",
            "Epoch: 7, time: 9.4900, Training Loss: 0.1250\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-d6f5d7c1c748>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstudent_KD\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrainmm_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'best_model_student_encoder_KD.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-9c22fd8fdcdc>\u001b[0m in \u001b[0;36mtrainmm_encoder\u001b[0;34m(train_loader, learn_rate, EPOCHS, model, filename, teacher)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_running_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Student--Fine Tuning"
      ],
      "metadata": {
        "id": "2sKs5a7WOHCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INgjB7BVOHCi"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_mm_2D_vel_acc_fine_tuning(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    # criterion =nn.MSELoss()\n",
        "    criterion =RMSELoss()\n",
        "    # criterion =PearsonCorrCoefLoss()\n",
        "\n",
        "    # criterion=PearsonCorrLoss()\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyKyQHE6OHCi"
      },
      "outputs": [],
      "source": [
        "class MM_VID_Kinect_mha_wf_tm_fusion_KD(nn.Module):\n",
        "    def __init__(self, model1, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_wf_tm_fusion_KD, self).__init__()\n",
        "\n",
        "        self.model1 = model1\n",
        "\n",
        "        self.fc = nn.Linear(2*3*128+128,5)\n",
        "\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x,x_1 = self.model1(x_acc, x_gyr, x_2D)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out_f=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out_f)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZyUb5e5OHCi"
      },
      "outputs": [],
      "source": [
        "student_encoder= MM_VID_Kinect_mha_wf_tm_fusion_encoder(44,44,44)\n",
        "student_encoder.load_state_dict(torch.load(path+'best_model_student_encoder_KD.pth'))\n",
        "student_encoder.to(device)\n",
        "\n",
        "# Freeze the weights of model1\n",
        "for param in student_encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "lr = 0.001\n",
        "model = MM_VID_Kinect_mha_wf_tm_fusion_KD(student_encoder,44,44,44)\n",
        "\n",
        "mm_vid_kinect_mha_wf_tm_fusion_KD= train_mm_2D_vel_acc_fine_tuning(train_loader, lr,40,model,path+'best_model_student_KD.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGZGD9MQOHCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14080437-c4c7-4b0f-bd1d-891c9886a143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1447, 50, 5)\n",
            "7.12725967168808\n",
            "7.4216872453689575\n",
            "4.880169779062271\n",
            "5.224016308784485\n",
            "4.429162293672562\n",
            "\n",
            "\n",
            "0.7871932631519224\n",
            "0.9012680136351384\n",
            "0.9388218261448965\n",
            "0.9835867494228535\n",
            "0.9500937111079217\n",
            "Mean: 5.816 +/- 1.364\n",
            "Mean: 0.912 +/- 0.076\n"
          ]
        }
      ],
      "source": [
        "mm_vid_kinect_mha_wf_tm_fusion_KD= MM_VID_Kinect_mha_wf_tm_fusion_KD(student_encoder,44,44,44)\n",
        "mm_vid_kinect_mha_wf_tm_fusion_KD.load_state_dict(torch.load(path+'best_model_student_KD.pth'))\n",
        "mm_vid_kinect_mha_wf_tm_fusion_KD.to(device)\n",
        "\n",
        "mm_vid_kinect_mha_wf_tm_fusion_KD.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output= mm_vid_kinect_mha_wf_tm_fusion_KD(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_22=np.hstack([rmse,p])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vanilla Knowledge Distillation"
      ],
      "metadata": {
        "id": "amKU93YS9_z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "pvxNPnSP9_z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n"
      ],
      "metadata": {
        "id": "Tu-jMUNX9_z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "                            [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "                            [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])"
      ],
      "metadata": {
        "id": "vo_ve_9B9_z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "        support = torch.matmul(x, self.weight)\n",
        "        output = torch.matmul(adjacency_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features):\n",
        "        super(GraphConvolutionalNetwork, self).__init__()\n",
        "        self.gc1 = GraphConvolution(in_features, hidden_features)\n",
        "        self.dropout=nn.Dropout(p=0.10)\n",
        "        self.attention = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x, adjacency_matrix):\n",
        "\n",
        "        attention_weights = self.attention(x)\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "        # Apply the attention weights to the input features.\n",
        "        weighted_features = attention_weights * x\n",
        "\n",
        "\n",
        "        x = F.relu(self.gc1(weighted_features, adjacency_matrix))\n",
        "        x=self.dropout(x)\n",
        "        # x = F.relu(self.gc2(x, adjacency_matrix))\n",
        "        # x=self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mf5BzmV99_z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teacher Model"
      ],
      "metadata": {
        "id": "GfYJCOTl9_z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Teacher Model\n",
        "\n",
        "def train_mm_m(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    # criterion =nn.MSELoss()\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "\n",
        "    # criterion=PearsonCorrLoss()\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output,x= model(data_acc.to(device).float(),data_gyr.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output,x= model(data_acc.to(device).float(),data_gyr.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "dD64w2T79_z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Weighted Fusion of MHA+Weighted Feature+ Tensor Multiplication Fusion\n",
        "\n",
        "class MM_mha_wf_tm_fusion(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr,input_2D, drop_prob=0.25):\n",
        "        super(MM_mha_wf_tm_fusion, self).__init__()\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2d=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2d= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.gcn=GraphConvolutionalNetwork(4,4)\n",
        "        self.gate=GatingModule(128)\n",
        "\n",
        "        self.fc = nn.Linear(2*3*128+128,5)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.fc_gc = nn.Linear(44, 128)\n",
        "\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "        self.fc_kd = nn.Linear(3*128, 3*128)\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2d):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2d_1=x_2d.view(x_2d.size(0)*x_2d.size(1),x_2d.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2d_1=self.BN_2d(x_2d_1)\n",
        "\n",
        "        # x_2D_3=x_2d_1.view(-1, 11, 4)\n",
        "        # x_2D_3=self.gcn(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        # x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "        # x_2D_3=self.fc_gc(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, 50, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, 50, x_gyr_1.size(-1))\n",
        "        x_2d_2=x_2d_1.view(-1, 50, x_2d_1.size(-1))\n",
        "\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2d=self.encoder_2d(x_2d_2)\n",
        "\n",
        "        # x_2d=self.gate(x_2d,x_2D_3)\n",
        "        x=torch.cat((x_acc,x_gyr,x_2d),dim=-1)\n",
        "\n",
        "        x_1=self.fc_kd(x)\n",
        "\n",
        "        # x_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out_3=x_acc*x_gyr*x_2d\n",
        "\n",
        "        out_c=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out_c)\n",
        "        out_f=gating_weights_1*out_c\n",
        "\n",
        "        out=self.fc(out_f)\n",
        "\n",
        "        return out, x_1"
      ],
      "metadata": {
        "id": "JqDJAEON9_z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "model = MM_mha_wf_tm_fusion(24,24,44)\n",
        "\n",
        "mm_mha_wf_tm_fusion = train_mm_m(train_loader, lr,40,model,path+'_teacher_IMU8_2D.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f443eeb-2db2-4537-f287-774d7feb296f",
        "id": "STm5diwr9_z8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 10.2683, Training Loss: 0.3205,  Validation loss: 0.2088\n",
            "Epoch: 2, time: 9.0514, Training Loss: 0.2051,  Validation loss: 0.1742\n",
            "Epoch: 3, time: 9.1087, Training Loss: 0.1809,  Validation loss: 0.1766\n",
            "Epoch: 4, time: 9.2101, Training Loss: 0.1691,  Validation loss: 0.1538\n",
            "Epoch: 5, time: 9.2906, Training Loss: 0.1583,  Validation loss: 0.1535\n",
            "Epoch: 6, time: 9.3946, Training Loss: 0.1530,  Validation loss: 0.1389\n",
            "Epoch: 7, time: 9.5276, Training Loss: 0.1480,  Validation loss: 0.1369\n",
            "Epoch: 8, time: 9.6711, Training Loss: 0.1428,  Validation loss: 0.1320\n",
            "Epoch: 9, time: 9.7794, Training Loss: 0.1377,  Validation loss: 0.1301\n",
            "Epoch: 10, time: 9.9096, Training Loss: 0.1340,  Validation loss: 0.1251\n",
            "Epoch: 11, time: 10.0170, Training Loss: 0.1326,  Validation loss: 0.1240\n",
            "Epoch: 12, time: 9.9603, Training Loss: 0.1269,  Validation loss: 0.1242\n",
            "Epoch: 13, time: 9.8531, Training Loss: 0.1244,  Validation loss: 0.1326\n",
            "Epoch: 14, time: 9.8011, Training Loss: 0.1233,  Validation loss: 0.1259\n",
            "Epoch: 15, time: 9.7726, Training Loss: 0.1203,  Validation loss: 0.1228\n",
            "Epoch: 16, time: 9.7794, Training Loss: 0.1186,  Validation loss: 0.1175\n",
            "Epoch: 17, time: 9.7930, Training Loss: 0.1159,  Validation loss: 0.1178\n",
            "Epoch: 18, time: 9.8500, Training Loss: 0.1147,  Validation loss: 0.1204\n",
            "Epoch: 19, time: 9.8826, Training Loss: 0.1124,  Validation loss: 0.1161\n",
            "Epoch: 20, time: 9.8825, Training Loss: 0.1105,  Validation loss: 0.1156\n",
            "Epoch: 21, time: 9.8529, Training Loss: 0.1088,  Validation loss: 0.1167\n",
            "Epoch: 22, time: 9.8442, Training Loss: 0.1073,  Validation loss: 0.1141\n",
            "Epoch: 23, time: 9.8190, Training Loss: 0.1065,  Validation loss: 0.1160\n",
            "Epoch: 24, time: 9.8272, Training Loss: 0.1050,  Validation loss: 0.1138\n",
            "Epoch: 25, time: 9.8357, Training Loss: 0.1047,  Validation loss: 0.1124\n",
            "Epoch: 26, time: 9.8243, Training Loss: 0.1032,  Validation loss: 0.1183\n",
            "Epoch: 27, time: 9.8693, Training Loss: 0.1019,  Validation loss: 0.1127\n",
            "Epoch: 28, time: 9.8628, Training Loss: 0.1000,  Validation loss: 0.1132\n",
            "Epoch: 29, time: 9.8674, Training Loss: 0.1009,  Validation loss: 0.1114\n",
            "Epoch: 30, time: 9.8492, Training Loss: 0.0969,  Validation loss: 0.1138\n",
            "Epoch: 31, time: 9.8550, Training Loss: 0.0972,  Validation loss: 0.1156\n",
            "Epoch: 32, time: 9.8411, Training Loss: 0.0951,  Validation loss: 0.1140\n",
            "Epoch: 33, time: 9.8453, Training Loss: 0.0948,  Validation loss: 0.1108\n",
            "Epoch: 34, time: 9.8325, Training Loss: 0.0948,  Validation loss: 0.1162\n",
            "Epoch: 35, time: 9.8473, Training Loss: 0.0931,  Validation loss: 0.1163\n",
            "Epoch: 36, time: 9.8334, Training Loss: 0.0918,  Validation loss: 0.1235\n",
            "Epoch: 37, time: 9.8270, Training Loss: 0.0922,  Validation loss: 0.1103\n",
            "Epoch: 38, time: 9.8439, Training Loss: 0.0906,  Validation loss: 0.1123\n",
            "Epoch: 39, time: 9.8571, Training Loss: 0.0899,  Validation loss: 0.1142\n",
            "Epoch: 40, time: 9.8421, Training Loss: 0.0901,  Validation loss: 0.1114\n",
            "Training time: 391.1712341308594 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_mha_wf_tm_fusion= MM_mha_wf_tm_fusion(24,24,44)\n",
        "mm_mha_wf_tm_fusion.load_state_dict(torch.load(path+'_teacher_IMU8_2D.pth'))\n",
        "mm_mha_wf_tm_fusion.to(device)\n",
        "\n",
        "mm_mha_wf_tm_fusion.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,x= mm_mha_wf_tm_fusion(data_acc.to(device).float(),data_gyr.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_21=np.hstack([rmse,p])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada04c83-6d51-483d-d3ee-ed3cc094eb6e",
        "id": "A0lmajJh9_z8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1447, 50, 5)\n",
            "5.156425759196281\n",
            "5.920851975679398\n",
            "3.530924767255783\n",
            "2.708090655505657\n",
            "3.5538475960493088\n",
            "\n",
            "\n",
            "0.882960582481488\n",
            "0.950340749565716\n",
            "0.9779350861384609\n",
            "0.99541418543557\n",
            "0.9730930205045107\n",
            "Mean: 4.174 +/- 1.319\n",
            "Mean: 0.956 +/- 0.044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Distillation"
      ],
      "metadata": {
        "id": "RRAVkT7A9_z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainmm_KD(train_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            student_output, x_student_1= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(),data_2D.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+0.50*criterion_2(student_output,teacher_output)+0.50*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target in val_loader:\n",
        "                output, x_student_1= model(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_rmrg89l9_z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MM_VID_Kinect_mha_wf_tm_fusion_encoder(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_2D, drop_prob=0.25):\n",
        "        super(MM_VID_Kinect_mha_wf_tm_fusion_encoder, self).__init__()\n",
        "\n",
        "        self.gcn=GraphConvolutionalNetwork(4,4)\n",
        "\n",
        "        self.encoder_acc=Encoder(input_acc, drop_prob)\n",
        "        self.encoder_gyr=Encoder(input_gyr, drop_prob)\n",
        "        self.encoder_2D=Encoder(input_2D, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_2D= nn.BatchNorm1d(input_2D, affine=False)\n",
        "\n",
        "        self.fc_gc = nn.Linear(44, 128)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "        self.gate=GatingModule(128*3)\n",
        "        self.fc = nn.Linear(2*3*128+128,5)\n",
        "\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "        self.fc_kd = nn.Linear(3*128, 3*128)\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_2D):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_2D_1=x_2D.view(x_2D.size(0)*x_2D.size(1),x_2D.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_2D_1=self.BN_2D(x_2D_1)\n",
        "\n",
        "        x_acc_3=x_acc_1.view(-1, 11, 4)\n",
        "        x_gyr_3=x_gyr_1.view(-1, 11, 4)\n",
        "        x_2D_3=x_2D_1.view(-1, 11, 4)\n",
        "\n",
        "        ## Graph Convlutional Network\n",
        "\n",
        "        x_acc_3=self.gcn(x_acc_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_gyr_3=self.gcn(x_gyr_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "        x_2D_3=self.gcn(x_2D_3, torch.from_numpy(adjacency_matrix.astype(np.float32)).to(device))\n",
        "\n",
        "        x_acc_3=x_acc_3.view(x_acc.size(0),w,44)\n",
        "        x_gyr_3=x_gyr_3.view(x_acc.size(0),w,44)\n",
        "        x_2D_3=x_2D_3.view(x_acc.size(0),w,44)\n",
        "\n",
        "        x_acc_3=self.fc_gc(x_acc_3)\n",
        "        x_gyr_3=self.fc_gc(x_gyr_3)\n",
        "        x_2D_3=self.fc_gc(x_2D_3)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(x_acc.size(0),w,44)\n",
        "        x_gyr_2=x_gyr_1.view(x_acc.size(0),w,44)\n",
        "        x_2D_2=x_2D_1.view(x_acc.size(0),w,44)\n",
        "\n",
        "        #### Bi-LSTM Encoder\n",
        "        x_acc=self.encoder_acc(x_acc_2)\n",
        "        x_gyr=self.encoder_gyr(x_gyr_2)\n",
        "        x_2D=self.encoder_2D(x_2D_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_2D),dim=-1)\n",
        "        x_gc=torch.cat((x_acc_3,x_gyr_3,x_2D_3),dim=-1)\n",
        "        x=self.gate(x,x_gc)\n",
        "\n",
        "        x_1=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        out_3=x[:,:,0:128]*x[:,:,128:2*128]*x[:,:,2*128:3*128]\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out_f=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out_f)\n",
        "\n",
        "        return out, x_1\n"
      ],
      "metadata": {
        "id": "lpEvEXrK9_z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "student = MM_VID_Kinect_mha_wf_tm_fusion_encoder(44,44,44)\n",
        "\n",
        "teacher= MM_mha_wf_tm_fusion(24,24,44)\n",
        "teacher.load_state_dict(torch.load(path+'_teacher_IMU8_2D.pth'))\n",
        "teacher.to(device)\n",
        "\n",
        "student_KD= trainmm_KD(train_loader, lr,40, student,path+'model_student_KD.pth', teacher)"
      ],
      "metadata": {
        "id": "20xPOux29_z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mm_vid_kinect_mha_wf_tm_fusion_KD= MM_VID_Kinect_mha_wf_tm_fusion_encoder(44,44,44)\n",
        "mm_vid_kinect_mha_wf_tm_fusion_KD.load_state_dict(torch.load(path+'model_student_KD.pth'))\n",
        "mm_vid_kinect_mha_wf_tm_fusion_KD.to(device)\n",
        "\n",
        "mm_vid_kinect_mha_wf_tm_fusion_KD.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_2D, data_velocity, data_acceleration, target) in enumerate(test_loader):\n",
        "        output,student= mm_vid_kinect_mha_wf_tm_fusion_KD(data_velocity.to(device).float(),data_acceleration.to(device).float(),data_2D.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_22=np.hstack([rmse,p])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUXeNUCc-mvk",
        "outputId": "58316402-d737-4ef1-a593-5bf9f032c252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1447, 50, 5)\n",
            "6.675872206687927\n",
            "7.242700457572937\n",
            "5.175862088799477\n",
            "4.899866506457329\n",
            "4.378128796815872\n",
            "\n",
            "\n",
            "0.8130256838776342\n",
            "0.8984493463720742\n",
            "0.9305828868548544\n",
            "0.9852425818137998\n",
            "0.9562257868824107\n",
            "Mean: 5.674 +/- 1.224\n",
            "Mean: 0.917 +/- 0.066\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TrXnoV0Js5CO",
        "iP_eDnJwrKCC",
        "2HtJVDh1mEB-",
        "m2_enhIBjamV",
        "TbKi4_MDkS0W",
        "z040uGvvk0be",
        "djhcNLtif6mI",
        "GqerNT98Xk6X",
        "GUXZmam7e9vb",
        "TZ7MtrTtVOQ3",
        "PQBLMBi1rmcC",
        "XGiQ1YC3hb1v",
        "t5ExgCH53Lb_",
        "vUbNhLvoeBjZ",
        "Zs09ULcJguqa",
        "L59Ln4Axi0K9",
        "41pLtR42ZlSX",
        "hdCqI4d_atC6",
        "2FpdLD8gbPcG",
        "Ki6ZZS_-b9Ak",
        "h1eVUqyjch3B",
        "lu1YiUDKeOeK",
        "0CM6QeeUZSvq",
        "YWACO0Dv6ZOU",
        "OpJ7Y4yoOHCg",
        "2sKs5a7WOHCi",
        "GfYJCOTl9_z7"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}